{"config":{"lang":["en","ko"],"separator":"[\\s\\-\\.]+","pipeline":[" "]},"docs":[{"location":"","title":"pyhub-llm","text":""},{"location":"#llm-python","title":"\uc5ec\ub7ec LLM \ud504\ub85c\ubc14\uc774\ub354\ub97c \ud1b5\ud569\ud558\ub294 Python \ub77c\uc774\ube0c\ub7ec\ub9ac","text":"<p>pyhub-llm\uc740 OpenAI, Anthropic, Google, Ollama \ub4f1 \ub2e4\uc591\ud55c LLM \ud504\ub85c\ubc14\uc774\ub354\ub97c \ud558\ub098\uc758 \ud1b5\ud569\ub41c \uc778\ud130\ud398\uc774\uc2a4\ub85c \uc0ac\uc6a9\ud560 \uc218 \uc788\uac8c \ud574\uc8fc\ub294 Python \ub77c\uc774\ube0c\ub7ec\ub9ac\uc785\ub2c8\ub2e4.</p> <p>\uc8fc\uc694 \ud2b9\uc9d5</p> <ul> <li>\ud83d\udd04 \ud1b5\ud569 \uc778\ud130\ud398\uc774\uc2a4: \ubaa8\ub4e0 LLM\uc744 \ub3d9\uc77c\ud55c \ubc29\uc2dd\uc73c\ub85c \uc0ac\uc6a9</li> <li>\ud83d\ude80 \uac04\ud3b8\ud55c \uc804\ud658: \ud55c \uc904\uc758 \ucf54\ub4dc\ub85c \ud504\ub85c\ubc14\uc774\ub354 \ubcc0\uacbd</li> <li>\u26a1 \ube44\ub3d9\uae30 \uc9c0\uc6d0: \ub3d9\uae30/\ube44\ub3d9\uae30 \ubaa8\ub450 \uc9c0\uc6d0</li> <li>\ud83d\udd27 \ud655\uc7a5 \uac00\ub2a5: \uc26c\uc6b4 \ucee4\uc2a4\ud130\ub9c8\uc774\uc9d5\uacfc \ud655\uc7a5</li> <li>\ud83d\udcdd \ud0c0\uc785 \uc548\uc804: \uc644\uc804\ud55c \ud0c0\uc785 \ud78c\ud2b8 \uc9c0\uc6d0</li> </ul>"},{"location":"#_1","title":"\ube60\ub978 \uc2dc\uc791","text":"\uae30\ubcf8 \uc0ac\uc6a9\ubc95\ud504\ub85c\ubc14\uc774\ub354\ubcc4 \uc0ac\uc6a9 <pre><code>from pyhub.llm import LLM\n\n# \ubaa8\ub378\uba85\uc73c\ub85c \uc790\ub3d9 \ud504\ub85c\ubc14\uc774\ub354 \uac10\uc9c0\nllm = LLM.create(\"gpt-4o-mini\")\n\n# \uac04\ub2e8\ud55c \uc9c8\ubb38\nreply = llm.ask(\"\ud30c\uc774\uc36c\uc758 \uc7a5\uc810\uc744 \uc124\uba85\ud574\uc8fc\uc138\uc694\")\nprint(reply.text)\n</code></pre> <pre><code>from pyhub.llm import OpenAILLM, AnthropicLLM, GoogleLLM\n\n# OpenAI\nopenai_llm = OpenAILLM(model=\"gpt-4o-mini\")\n\n# Anthropic  \nanthropic_llm = AnthropicLLM(model=\"claude-3-5-haiku-latest\")\n\n# Google\ngoogle_llm = GoogleLLM(model=\"gemini-2.0-flash-exp\")\n\n# \ubaa8\ub450 \ub3d9\uc77c\ud55c \uc778\ud130\ud398\uc774\uc2a4 \uc0ac\uc6a9\nfor llm in [openai_llm, anthropic_llm, google_llm]:\n    reply = llm.ask(\"\uc548\ub155\ud558\uc138\uc694!\")\n    print(f\"{llm.__class__.__name__}: {reply.text}\")\n</code></pre>"},{"location":"#_2","title":"\uc8fc\uc694 \uae30\ub2a5","text":"<ul> <li> <p> \ud1b5\ud569 \uc778\ud130\ud398\uc774\uc2a4</p> <p>\ubaa8\ub4e0 LLM \ud504\ub85c\ubc14\uc774\ub354\ub97c \ub3d9\uc77c\ud55c \ubc29\uc2dd\uc73c\ub85c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p> \ud504\ub85c\ubc14\uc774\ub354 \uac00\uc774\ub4dc</p> </li> <li> <p> \ub300\ud654 \uad00\ub9ac</p> <p>\uc790\ub3d9 \ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac \uad00\ub9ac\uc640 Stateless \ubaa8\ub4dc\ub97c \uc9c0\uc6d0\ud569\ub2c8\ub2e4.</p> <p> \ub300\ud654 \uad00\ub9ac \uac00\uc774\ub4dc</p> </li> <li> <p> \uad6c\uc870\ud654\ub41c \ucd9c\ub825</p> <p>Pydantic \uc2a4\ud0a4\ub9c8\ub97c \uc0ac\uc6a9\ud55c \ud0c0\uc785 \uc548\uc804\ud55c \uc751\ub2f5\uc744 \ubc1b\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p> \uad6c\uc870\ud654\ub41c \ucd9c\ub825</p> </li> <li> <p> \uc131\ub2a5 \ucd5c\uc801\ud654</p> <p>\uce90\uc2f1, \uc2a4\ud2b8\ub9ac\ubc0d, \ube44\ub3d9\uae30 \ucc98\ub9ac\ub85c \ucd5c\uc801\uc758 \uc131\ub2a5\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.</p> <p> \uace0\uae09 \uae30\ub2a5</p> </li> </ul>"},{"location":"#_3","title":"\uc124\uce58","text":"\uae30\ubcf8 \uc124\uce58\ud2b9\uc815 \ud504\ub85c\ubc14\uc774\ub354\uc804\uccb4 \uc124\uce58 <pre><code>pip install pyhub-llm\n</code></pre> <pre><code># OpenAI\ub9cc \uc124\uce58\npip install pyhub-llm[openai]\n\n# \uc5ec\ub7ec \ud504\ub85c\ubc14\uc774\ub354 \uc124\uce58\npip install pyhub-llm[openai,anthropic,google]\n</code></pre> <pre><code># \ubaa8\ub4e0 \ud504\ub85c\ubc14\uc774\ub354\uc640 \ucd94\uac00 \uae30\ub2a5 \uc124\uce58\npip install pyhub-llm[all]\n</code></pre>"},{"location":"#_4","title":"\ub2e4\uc74c \ub2e8\uacc4","text":"<ul> <li>\uc124\uce58 \uac00\uc774\ub4dc\ub97c \ud1b5\ud574 \uc0c1\uc138\ud55c \uc124\uce58 \ubc29\ubc95\uc744 \ud655\uc778\ud558\uc138\uc694</li> <li>\ube60\ub978 \uc2dc\uc791 \uac00\uc774\ub4dc\ub85c \uae30\ubcf8 \uc0ac\uc6a9\ubc95\uc744 \uc775\ud600\ubcf4\uc138\uc694</li> <li>\uc608\uc81c \ucf54\ub4dc\ub97c \ud1b5\ud574 \uc2e4\uc81c \uc0ac\uc6a9 \uc0ac\ub840\ub97c \ud655\uc778\ud558\uc138\uc694</li> </ul>"},{"location":"#_5","title":"\ub3c4\uc6c0\uc774 \ud544\uc694\ud558\uc2e0\uac00\uc694?","text":"<ul> <li>\ud83d\udce7 \ubb38\uc758: me@pyhub.kr</li> <li>\ud83d\udc1b \ubc84\uadf8 \ub9ac\ud3ec\ud2b8: GitHub Issues</li> <li>\ud83d\udcac \ud1a0\ub860: GitHub Discussions</li> </ul>"},{"location":"cache-injection/","title":"Cache Injection in pyhub-llm","text":""},{"location":"cache-injection/#overview","title":"Overview","text":"<p>pyhub-llm implements a flexible caching system that allows users to inject their own cache backends at the LLM instance level. This approach provides maximum control over caching behavior without requiring complex configuration files.</p>"},{"location":"cache-injection/#cache-key-generation","title":"Cache Key Generation","text":""},{"location":"cache-injection/#algorithm","title":"Algorithm","text":"<ul> <li>Hash Function: SHA-256 (cryptographically secure)</li> <li>Key Length: 16 characters from the hexadecimal digest</li> <li>Format: <code>{namespace}:{hash_suffix}</code></li> <li>Example: <code>openai:a1b2c3d4e5f6g7h8</code></li> </ul>"},{"location":"cache-injection/#why-16-characters","title":"Why 16 Characters?","text":"<p>The 16-character hash provides an excellent balance between collision resistance and practical key length:</p> <ul> <li>Collision Probability: ~1 in 10^19 for 16 hex characters</li> <li>Storage Efficiency: Shorter keys are more efficient for cache storage</li> <li>Readability: Keys remain manageable for debugging and logging</li> </ul> <p>For most applications handling millions of cached responses, the probability of collision remains negligible.</p>"},{"location":"cache-injection/#cache-injection-pattern","title":"Cache Injection Pattern","text":""},{"location":"cache-injection/#basic-usage","title":"Basic Usage","text":"<pre><code>from pyhub.llm import LLM\nfrom pyhub.llm.cache import MemoryCache, FileCache\n\n# Create cache instance\ncache = MemoryCache()\n\n# Inject cache at LLM creation\nllm = LLM.create(\"gpt-4o\", cache=cache)\n\n# Use with caching enabled\nresponse = llm.ask(\"Hello\", enable_cache=True)\n</code></pre>"},{"location":"cache-injection/#multiple-llms-with-different-caches","title":"Multiple LLMs with Different Caches","text":"<pre><code># Memory cache for fast, temporary storage\nmemory_cache = MemoryCache()\nllm1 = LLM.create(\"gpt-4o\", cache=memory_cache)\n\n# File cache for persistent storage\nfile_cache = FileCache(\"/path/to/cache\")\nllm2 = LLM.create(\"claude-3-5-sonnet-latest\", cache=file_cache)\n</code></pre>"},{"location":"cache-injection/#shared-cache-between-llms","title":"Shared Cache Between LLMs","text":"<pre><code># Share cache across multiple LLMs\nshared_cache = MemoryCache()\nllm1 = LLM.create(\"gpt-4o\", cache=shared_cache)\nllm2 = LLM.create(\"gpt-4o-mini\", cache=shared_cache)\n</code></pre>"},{"location":"cache-injection/#custom-cache-implementation","title":"Custom Cache Implementation","text":"<p>You can implement your own cache backend by inheriting from <code>BaseCache</code>:</p> <pre><code>from pyhub.llm.cache.base import BaseCache\n\nclass RedisCache(BaseCache):\n    def __init__(self, redis_client):\n        self.redis = redis_client\n\n    def get(self, key: str, default=None):\n        value = self.redis.get(key)\n        return value if value is not None else default\n\n    def set(self, key: str, value, ttl=None):\n        self.redis.set(key, value, ex=ttl)\n\n    def delete(self, key: str):\n        self.redis.delete(key)\n\n    def clear(self):\n        # Implement based on your needs\n        pass\n\n# Use custom cache\nredis_cache = RedisCache(redis_client)\nllm = LLM.create(\"gpt-4o\", cache=redis_cache)\n</code></pre>"},{"location":"cache-injection/#cache-behavior","title":"Cache Behavior","text":""},{"location":"cache-injection/#what-gets-cached","title":"What Gets Cached","text":"<ul> <li>LLM text responses</li> <li>Token usage information (set to 0 for cached responses)</li> <li>Embedding results</li> </ul>"},{"location":"cache-injection/#what-doesnt-get-cached","title":"What Doesn't Get Cached","text":"<ul> <li>Streaming responses (planned for future)</li> <li>Tool/function calling intermediate results</li> </ul>"},{"location":"cache-injection/#cache-key-components","title":"Cache Key Components","text":"<p>The cache key includes all parameters that affect the response: - Model name - Messages/prompt - Temperature - Max tokens - System prompt - Any other model-specific parameters</p>"},{"location":"cache-injection/#best-practices","title":"Best Practices","text":"<ol> <li>Explicit Caching: Always explicitly enable caching with <code>enable_cache=True</code> for each call</li> <li>Cache Isolation: Use different cache instances for different use cases</li> <li>TTL Management: Implement TTL in your cache backend for automatic expiration</li> <li>Error Handling: Cache errors should not affect LLM functionality</li> </ol>"},{"location":"cache-injection/#migration-from-settings-based-cache","title":"Migration from Settings-Based Cache","text":"<p>If you were using the old settings-based cache configuration:</p> <pre><code># Old approach (no longer supported)\nllm_settings.use_default_cache = True\nllm_settings.cache_backend = \"file\"\n\n# New approach\nfrom pyhub.llm.cache import FileCache\ncache = FileCache()\nllm = LLM.create(\"gpt-4o\", cache=cache)\n</code></pre> <p>This new approach provides better control and flexibility without the complexity of global settings.</p>"},{"location":"cache-strategy/","title":"\uc784\ubca0\ub529 \uce90\uc2f1 \uc804\ub7b5 \ud3ec\uad04\uc801 \uc5f0\uad6c \ubcf4\uace0\uc11c","text":""},{"location":"cache-strategy/#_2","title":"\uce90\uc2f1\uc774 \uc784\ubca0\ub529 \uc2dc\uc2a4\ud15c \uc131\ub2a5\uc744 \uadf9\uc801\uc73c\ub85c \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ubc29\ubc95","text":"<p>\uc784\ubca0\ub529 \uce90\uc2f1\uc740 \uba38\uc2e0\ub7ec\ub2dd \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc5d0\uc11c **40-50%\uc758 \ube44\uc6a9 \uc808\uac10**\uacfc **80%\uc758 \uc9c0\uc5f0 \uc2dc\uac04 \uac1c\uc120**\uc744 \ub2ec\uc131\ud560 \uc218 \uc788\ub294 \ud575\uc2ec \ucd5c\uc801\ud654 \uc804\ub7b5\uc785\ub2c8\ub2e4. \ubcf8 \ubcf4\uace0\uc11c\ub294 LangChain, \ubd84\uc0b0 \uc2dc\uc2a4\ud15c \uc544\ud0a4\ud14d\ucc98, Upstage Console\uc758 \uc811\uadfc \ubc29\uc2dd\uc744 \ud3ec\ud568\ud55c \ub2e4\uc591\ud55c \uce90\uc2f1 \uc804\ub7b5\uc744 \uc2ec\uce35 \ubd84\uc11d\ud558\uc5ec \uc2e4\ubb34\uc5d0 \uc989\uc2dc \uc801\uc6a9 \uac00\ub2a5\ud55c \uad6c\ud604 \uac00\uc774\ub4dc\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.</p>"},{"location":"cache-strategy/#_3","title":"\ud575\uc2ec \uce90\uc2f1 \uc804\ub7b5\uc758 \ube44\uad50 \ubd84\uc11d","text":""},{"location":"cache-strategy/#langchain","title":"LangChain\uc758 \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \uc911\uc2ec \uc811\uadfc\ubc95","text":"<p>LangChain\uc740 **CacheBackedEmbeddings**\ub97c \ud1b5\ud574 \uac1c\ubc1c\uc790 \uce5c\ud654\uc801\uc778 \uce90\uc2f1 \ub808\uc774\uc5b4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774 \uc811\uadfc\ubc95\uc758 \ud575\uc2ec\uc740 \ud574\uc2dc \uae30\ubc18 \ud0a4 \uc0dd\uc131\uacfc \ub124\uc784\uc2a4\ud398\uc774\uc2a4 \ubd84\ub9ac\uc785\ub2c8\ub2e4:</p> <pre><code>const cacheBackedEmbeddings = CacheBackedEmbeddings.fromBytesStore(\n  underlyingEmbeddings,\n  redisStore,\n  { namespace: underlyingEmbeddings.model }\n);\n</code></pre> <p>\ud0a4 \uc0dd\uc131 \uba54\ucee4\ub2c8\uc998: \ud14d\uc2a4\ud2b8\ub97c SHA-256\uc73c\ub85c \ud574\uc2f1\ud558\uc5ec \uace0\uc720 \ud0a4\ub97c \uc0dd\uc131\ud558\uba70, \ubaa8\ub378\ubcc4 \ub124\uc784\uc2a4\ud398\uc774\uc2a4\ub97c \ud1b5\ud574 \ucda9\ub3cc\uc744 \ubc29\uc9c0\ud569\ub2c8\ub2e4. \uc774\ub294 <code>namespace + hash(text)</code> \ud615\ud0dc\ub85c \uad6c\uc131\ub418\uc5b4 \uc11c\ub85c \ub2e4\ub978 \uc784\ubca0\ub529 \ubaa8\ub378 \uac04\uc758 \uce90\uc2dc \ucda9\ub3cc\uc744 \uc6d0\ucc9c\uc801\uc73c\ub85c \ucc28\ub2e8\ud569\ub2c8\ub2e4.</p> <p>\uc131\ub2a5 \ud5a5\uc0c1: \ucd08\uae30 \ubca1\ud130 \uc800\uc7a5\uc18c \uc0dd\uc131 \uc2dc\uac04\uc774 1808ms\uc5d0\uc11c \uce90\uc2f1 \ud6c4 \ud604\uc800\ud788 \uac10\uc18c\ud558\uc5ec, \ubc18\ubcf5\uc801\uc778 \uc784\ubca0\ub529 \uacc4\uc0b0\uc5d0\uc11c \ud0c1\uc6d4\ud55c \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.</p>"},{"location":"cache-strategy/#_4","title":"\uc2e4\uc804 \uad6c\ud604: \uce90\uc2f1 \ud0a4 \uc0dd\uc131 \ubc29\ubc95\ub860","text":""},{"location":"cache-strategy/#_5","title":"\ucf58\ud150\uce20 \uae30\ubc18 \ud574\uc2f1 \uc804\ub7b5","text":"<pre><code>import hashlib\nimport hmac\n\ndef generate_secure_cache_key(text: str, model: str, user_id: str = None) -&gt; str:\n    \"\"\"\ubcf4\uc548\uc744 \uace0\ub824\ud55c \uce90\uc2dc \ud0a4 \uc0dd\uc131\"\"\"\n    secret = os.environ.get('CACHE_SECRET_KEY', 'default-secret')\n\n    message = f\"{text}:{model}\"\n    if user_id:\n        message += f\":{user_id}\"\n\n    return hmac.new(\n        secret.encode(),\n        message.encode(),\n        hashlib.sha256\n    ).hexdigest()\n</code></pre> <p>\uc7a5\uc810: \ub3d9\uc77c\ud55c \uc785\ub825\uc5d0 \ub300\ud574 \ud56d\uc0c1 \uac19\uc740 \ud0a4\uac00 \uc0dd\uc131\ub418\uc5b4 \uce90\uc2dc \ud788\ud2b8\uc728\uc744 \uadf9\ub300\ud654\ud558\uace0, HMAC\uc744 \uc0ac\uc6a9\ud558\uc5ec \uce90\uc2dc \ud3ec\uc774\uc988\ub2dd \uacf5\uaca9\uc744 \ubc29\uc9c0\ud569\ub2c8\ub2e4.</p>"},{"location":"cache-strategy/#_6","title":"\uacc4\uce35\uc801 \ub124\uc774\ubc0d \uaddc\uce59","text":"<pre><code># \ubb38\uc11c \uc784\ubca0\ub529\n\"embed:doc:{model_name}:{doc_id}\"\n# \ucffc\ub9ac \uc784\ubca0\ub529  \n\"embed:query:{model_name}:{hash(query_text)}\"\n# \uc0ac\uc6a9\uc790\ubcc4 \uc784\ubca0\ub529\n\"embed:user:{user_id}:{type}:{id}\"\n</code></pre> <p>\uc774\ub7ec\ud55c \uad6c\uc870\ud654\ub41c \ud0a4\ub294 \uce90\uc2dc \uad00\ub9ac\uc640 \ub514\ubc84\uae45\uc744 \uc6a9\uc774\ud558\uac8c \ud558\uba70, \ud2b9\uc815 \ud328\ud134\uc758 \ud0a4\ub4e4\uc744 \uc77c\uad04 \uc0ad\uc81c\ud558\uac70\ub098 \ubaa8\ub2c8\ud130\ub9c1\ud560 \ub54c \uc720\uc6a9\ud569\ub2c8\ub2e4.</p>"},{"location":"cache-strategy/#_7","title":"\uace0\uc131\ub2a5 \uce90\uc2f1 \uad6c\ud604 \uc0ac\ub840","text":""},{"location":"cache-strategy/#redis","title":"Redis \uae30\ubc18 \ud504\ub85c\ub355\uc158 \uad6c\ud604","text":"<pre><code>class RedisEmbeddingCache:\n    def __init__(self, host='localhost', port=6379, db=0):\n        self.client = redis.Redis(host=host, port=port, db=db, decode_responses=True)\n        self.model = SentenceTransformer('all-mpnet-base-v2')\n\n    def batch_get_embeddings(self, texts, ttl=3600):\n        keys = [self._generate_key(text) for text in texts]\n\n        # \uce90\uc2dc\ub41c \uc784\ubca0\ub529 \uc77c\uad04 \uc870\ud68c\n        cached_embeddings = self.client.mget(keys)\n        results = []\n        to_compute = []\n\n        for i, cached in enumerate(cached_embeddings):\n            if cached:\n                results.append(json.loads(cached))\n            else:\n                to_compute.append((i, texts[i]))\n                results.append(None)\n\n        # \ub204\ub77d\ub41c \uc784\ubca0\ub529 \uacc4\uc0b0\n        if to_compute:\n            new_embeddings = self.model.encode([text for _, text in to_compute])\n\n            # \ud30c\uc774\ud504\ub77c\uc778\uc744 \ud1b5\ud55c \uc77c\uad04 \uce90\uc2f1\n            pipeline = self.client.pipeline()\n            for j, (i, text) in enumerate(to_compute):\n                embedding = new_embeddings[j].tolist()\n                results[i] = embedding\n                key = self._generate_key(text)\n                pipeline.setex(key, ttl, json.dumps(embedding))\n            pipeline.execute()\n\n        return results\n</code></pre> <p>\uc131\ub2a5 \ucd5c\uc801\ud654 \ud3ec\uc778\ud2b8: - \uc77c\uad04 \ucc98\ub9ac: \ub124\ud2b8\uc6cc\ud06c \uc655\ubcf5\uc744 \ucd5c\uc18c\ud654\ud558\uc5ec \ucc98\ub9ac\ub7c9 \ud5a5\uc0c1 - \ud30c\uc774\ud504\ub77c\uc778 \uc0ac\uc6a9: Redis \uba85\ub839\uc744 \ubb36\uc5b4\uc11c \uc2e4\ud589\ud558\uc5ec \uc131\ub2a5 \uac1c\uc120 - JSON \uc9c1\ub82c\ud654: \ubc94\uc6a9\uc131\uacfc \ub514\ubc84\uae45 \uc6a9\uc774\uc131 \uc81c\uacf5</p>"},{"location":"cache-strategy/#_8","title":"\ubca1\ud130 \ub370\uc774\ud130\ubca0\uc774\uc2a4 \ud1b5\ud569 \uc804\ub7b5","text":""},{"location":"cache-strategy/#pinecone","title":"Pinecone\uc758 \ub3d9\uc801 \uce90\uc2f1","text":"<p>Pinecone\uc740 Rust\ub85c \uc7ac\uc791\uc131\ub41c \ucf54\uc5b4 \uc5d4\uc9c4\uc5d0\uc11c **\ub3d9\uc801 \uce90\uc2f1**\uc744 \uad6c\ud604\ud569\ub2c8\ub2e4:</p> <pre><code>index = pinecone.Index(\"semantic-search\")\n\nresults = index.query(\n    namespace=\"breaking-news\",\n    vector=[0.13, 0.45, 1.34, ...],\n    top_k=10,\n    include_metadata=True,\n    filter={\"category\": \"technology\"}\n)\n</code></pre> <p>\uc131\ub2a5 \uba54\ud2b8\ub9ad:  - 1\uc5b5 \uac1c \ubca1\ud130\uc5d0\uc11c \uc774\uc804 \ubc84\uc804 \ub300\ube44 3.4\ubc30 \ube60\ub978 \uc131\ub2a5 - \uc131\ub2a5 \ucd5c\uc801\ud654 \ud31f(p1)\uc5d0\uc11c 120ms \ubbf8\ub9cc\uc758 p95 \uc9c0\uc5f0 \uc2dc\uac04</p>"},{"location":"cache-strategy/#weaviate","title":"Weaviate\uc758 \uba54\ubaa8\ub9ac \ub0b4 \uce90\uc2f1","text":"<pre><code>collection_config = {\n    \"class\": \"Article\",\n    \"vectorIndexConfig\": {\n        \"vectorCacheMaxObjects\": 100000,  # \ucd5c\ub300 10\ub9cc \uac1c \ubca1\ud130 \uce90\uc2f1\n        \"efConstruction\": 128,\n        \"maxConnections\": 32\n    }\n}\n</code></pre> <p>\ucd5c\uc801\ud654 \uc804\ub7b5: HNSW\uc758 \ucd5c\uc0c1\uc704 \ub808\uc774\uc5b4\ub9cc \uba54\ubaa8\ub9ac\uc5d0 \uce90\uc2f1\ud558\uc5ec \uba54\ubaa8\ub9ac \ud6a8\uc728\uc131\uacfc \uc131\ub2a5\uc758 \uade0\ud615\uc744 \ub9de\ucda5\ub2c8\ub2e4.</p>"},{"location":"cache-strategy/#chroma-lru","title":"Chroma\uc758 LRU \uce90\uc2f1","text":"<pre><code>settings = Settings(\n    chroma_segment_cache_policy=\"LRU\",\n    chroma_memory_limit_bytes=10000000000  # ~10GB\n)\n\nclient = chromadb.PersistentClient(\n    path=\"./chroma_db\",\n    settings=settings\n)\n</code></pre>"},{"location":"cache-strategy/#_9","title":"\uba40\ud2f0\ub808\ubca8 \uce90\uc2f1 \uc544\ud0a4\ud14d\ucc98","text":""},{"location":"cache-strategy/#_10","title":"\uacc4\uce35\ud654\ub41c \uce90\uc2f1 \uc804\ub7b5","text":"<pre><code>class TieredVectorCache:\n    def __init__(self):\n        self.l1_cache = {}  # \uc778\uba54\ubaa8\ub9ac Python \ub515\uc154\ub108\ub9ac\n        self.l2_cache = redis.Redis()  # Redis \uce90\uc2dc\n        self.l3_storage = pinecone.Index(\"main-index\")  # \ubca1\ud130 DB\n\n    def query(self, query_vector, k=10):\n        query_hash = self._hash_vector(query_vector)\n\n        # L1 \uce90\uc2dc \ud655\uc778\n        if query_hash in self.l1_cache:\n            return self.l1_cache[query_hash]\n\n        # L2 \uce90\uc2dc \ud655\uc778\n        l2_result = self.l2_cache.get(f\"vector:{query_hash}\")\n        if l2_result:\n            result = json.loads(l2_result)\n            self.l1_cache[query_hash] = result  # L1\ub85c \uc2b9\uaca9\n            return result\n\n        # L3 \ubca1\ud130 \ub370\uc774\ud130\ubca0\uc774\uc2a4 \ucffc\ub9ac\n        result = self.l3_storage.query(\n            vector=query_vector,\n            top_k=k\n        )\n\n        # L1\uacfc L2\uc5d0 \ubaa8\ub450 \uce90\uc2f1\n        self.l1_cache[query_hash] = result\n        self.l2_cache.setex(f\"vector:{query_hash}\", 3600, json.dumps(result))\n\n        return result\n</code></pre> <p>\uc131\ub2a5 \uc774\uc810: - L1 \uce90\uc2dc: \ub9c8\uc774\ud06c\ub85c\ucd08 \ub2e8\uc704 \uc751\ub2f5 \uc2dc\uac04 - L2 \uce90\uc2dc: \ubc00\ub9ac\ucd08 \ub2e8\uc704 \uc751\ub2f5 \uc2dc\uac04 - L3 \uc800\uc7a5\uc18c: \uc218\uc2ed-\uc218\ubc31 \ubc00\ub9ac\ucd08 \uc751\ub2f5 \uc2dc\uac04</p> <p>\uac01 \ub808\ubca8\uc740 \uc774\uc804 \ub808\ubca8\ubcf4\ub2e4 10-50\ubc30 \ub290\ub9ac\uc9c0\ub9cc, \ub354 \ub9ce\uc740 \ub370\uc774\ud130\ub97c \uc800\uc7a5\ud560 \uc218 \uc788\uc5b4 \uc804\uccb4\uc801\uc778 \ud788\ud2b8\uc728\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.</p>"},{"location":"cache-strategy/#_11","title":"\ub300\uc6a9\ub7c9 \uc784\ubca0\ub529 \ucc98\ub9ac\ub97c \uc704\ud55c \ucd5c\uc801\ud654","text":""},{"location":"cache-strategy/#_12","title":"\uba54\ubaa8\ub9ac \ud6a8\uc728\uc801\uc778 \uccad\ud0b9 \uc804\ub7b5","text":"<pre><code>def process_large_embedding_matrix(embeddings, chunk_size=1000):\n    \"\"\"\ub300\uc6a9\ub7c9 \uc784\ubca0\ub529 \ub9e4\ud2b8\ub9ad\uc2a4\ub97c \uccad\ud06c \ub2e8\uc704\ub85c \ucc98\ub9ac\"\"\"\n    n_samples = embeddings.shape[0]\n    results = []\n\n    for i in range(0, n_samples, chunk_size):\n        chunk = embeddings[i:i+chunk_size]\n        processed_chunk = process_embedding_chunk(chunk)\n        results.append(processed_chunk)\n\n        # \uba54\ubaa8\ub9ac \uc815\ub9ac\n        del chunk\n        gc.collect()\n\n    return np.vstack(results)\n</code></pre>"},{"location":"cache-strategy/#_13","title":"\uc555\ucd95 \uae30\ubc95 \uc801\uc6a9","text":"<pre><code>class EmbeddingCompressor:\n    def compress_and_store(self, embeddings, cache_key):\n        # PCA\ub97c \ud1b5\ud55c \ucc28\uc6d0 \ucd95\uc18c\n        compressed = self.pca.transform(embeddings)\n\n        # zlib \uc555\ucd95\n        serialized = pickle.dumps(compressed)\n        compressed_data = zlib.compress(serialized, level=6)\n\n        # \uba54\ud0c0\ub370\uc774\ud130\uc640 \ud568\uaed8 \uc800\uc7a5\n        cache_data = {\n            'data': compressed_data,\n            'shape': compressed.shape,\n            'compression_ratio': self.compression_ratio\n        }\n\n        cache.set(cache_key, cache_data, timeout=3600)\n        return compressed\n</code></pre> <p>\uc555\ucd95 \ud6a8\uacfc:  - \uc6d0\ubcf8 \ud06c\uae30: 768\ucc28\uc6d0 \u00d7 4\ubc14\uc774\ud2b8 = 3KB/\uc784\ubca0\ub529 - \uc555\ucd95 \ud6c4: ~1.5KB/\uc784\ubca0\ub529 (50% \uc808\uac10) - 100\ub9cc \uac1c \uc784\ubca0\ub529: 3.2GB \u2192 1.7GB</p>"},{"location":"cache-strategy/#_14","title":"\uce90\uc2dc \ubb34\ud6a8\ud654 \uc815\ucc45 \ubc0f \uc77c\uad00\uc131 \uad00\ub9ac","text":""},{"location":"cache-strategy/#_15","title":"\uc2dc\uac04 \uae30\ubc18 \ub9cc\ub8cc \uc804\ub7b5","text":"<pre><code># \ucffc\ub9ac \uc784\ubca0\ub529: 1-24\uc2dc\uac04 (\ube48\ubc88\ud55c \ubcc0\uacbd)\nclient.setex(\"embed:query:123\", 86400, embedding_data)\n\n# \ubb38\uc11c \uc784\ubca0\ub529: 7-30\uc77c (\uc548\uc815\uc801\uc778 \ucf58\ud150\uce20)\nclient.expire(\"embed:doc:456\", 604800)\n\n# \uc0ac\uc6a9\uc790 \ud504\ub85c\ud544 \uc784\ubca0\ub529: 30-90\uc77c (\ubc18\uc601\uad6c\uc801)\nclient.expire(\"embed:user:789\", 7776000)\n</code></pre>"},{"location":"cache-strategy/#_16","title":"\uc774\ubca4\ud2b8 \uae30\ubc18 \ubb34\ud6a8\ud654","text":"<pre><code>class Document(models.Model):\n    def save(self, *args, **kwargs):\n        super().save(*args, **kwargs)\n        # \ubb38\uc11c \uc5c5\ub370\uc774\ud2b8 \uc2dc \uad00\ub828 \uce90\uc2dc \ubb34\ud6a8\ud654\n        self.invalidate_embedding_cache()\n\n    def invalidate_embedding_cache(self):\n        cache_pattern = f\"doc_embedding_{self.id}_*\"\n        cache.delete_pattern(cache_pattern)\n</code></pre>"},{"location":"cache-strategy/#_17","title":"\uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1 \ubc0f \ucd5c\uc801\ud654","text":""},{"location":"cache-strategy/#_18","title":"\ud575\uc2ec \uc131\ub2a5 \uc9c0\ud45c","text":"<pre><code>class CacheMetrics:\n    def log_stats(self):\n        logging.info(f\"\"\"\n        \uce90\uc2dc \ud1b5\uacc4:\n        - \ud788\ud2b8\uc728: {self.hit_rate:.2%}\n        - \ucd1d \uc694\uccad: {self.hits + self.misses}\n        - \ud3c9\uade0 \uc751\ub2f5 \uc2dc\uac04: {self.avg_response_time:.3f}\ucd08\n        - \uc808\uc57d\ub41c \uacc4\uc0b0 \uc2dc\uac04: {self.computation_time_saved:.2f}\ucd08\n        \"\"\")\n</code></pre> <p>\ubaa9\ud45c \uc9c0\ud45c: - \uce90\uc2dc \ud788\ud2b8\uc728: 90% \uc774\uc0c1 - P95 \uc9c0\uc5f0 \uc2dc\uac04: 100ms \ubbf8\ub9cc - \uc5d0\ub7ec\uc728: 1% \ubbf8\ub9cc</p>"},{"location":"cache-strategy/#_19","title":"\uc2e4\uc81c \uc131\ub2a5 \uac1c\uc120 \uc0ac\ub840","text":"<p>\uc774\ucee4\uba38\uc2a4 \ud50c\ub7ab\ud3fc \ucd5c\uc801\ud654 \uacb0\uacfc: - \uc774\uc804: 45% \uce90\uc2dc \ud788\ud2b8\uc728, 800ms \ud3c9\uade0 \uc751\ub2f5 \uc2dc\uac04 - \uc774\ud6c4: 92% \uce90\uc2dc \ud788\ud2b8\uc728, 150ms \ud3c9\uade0 \uc751\ub2f5 \uc2dc\uac04 - \uad6c\ud604: \uba40\ud2f0\ub808\ubca8 \uce90\uc2f1 + \ube14\ub8f8 \ud544\ud130 + \uc608\uce21 \ud504\ub9ac\ud398\uce6d - ROI: 70% \ube44\uc6a9 \uc808\uac10, 400% \uc131\ub2a5 \ud5a5\uc0c1</p>"},{"location":"cache-strategy/#_20","title":"\ube44\uc6a9 \ucd5c\uc801\ud654 \uc804\ub7b5","text":""},{"location":"cache-strategy/#api","title":"API \ud638\ucd9c \uc808\uac10","text":"<p>OpenAI \ud504\ub86c\ud504\ud2b8 \uce90\uc2f1: 1024 \ud1a0\ud070 \uc774\uc0c1\uc758 \ubc18\ubcf5\uc801\uc778 \ud504\ub86c\ud504\ud2b8\uc5d0 \ub300\ud574 ~50% \ube44\uc6a9 \uc808\uac10</p> <pre><code>@redis_cache(ttl=3600, namespace=\"openai_embeddings\")\ndef get_openai_embedding(text, model=\"text-embedding-3-small\"):\n    return client.embeddings.create(input=text, model=model)\n</code></pre>"},{"location":"cache-strategy/#_21","title":"\uacc4\uce35\ud654\ub41c \uc800\uc7a5\uc18c \uc804\ub7b5","text":"<ul> <li>\ud56b \ub370\uc774\ud130: Redis/Memcached (\ube48\ubc88\ud55c \uc561\uc138\uc2a4)</li> <li>\uc6dc \ub370\uc774\ud130: SSD \uae30\ubc18 \uc800\uc7a5\uc18c (\uac04\ud5d0\uc801 \uc561\uc138\uc2a4)</li> <li>\ucf5c\ub4dc \ub370\uc774\ud130: \uc544\uce74\uc774\ube0c \uc800\uc7a5\uc18c (\ucd5c\uc800 \ube44\uc6a9)</li> </ul> <p>\ube44\uc6a9 \uc808\uac10 \ud6a8\uacfc: \uc801\uc808\ud55c \uacc4\uce35\ud654\ub85c 40-70% \uc800\uc7a5\uc18c \ube44\uc6a9 \uc808\uac10</p>"},{"location":"cache-strategy/#_22","title":"\ubcf4\uc548 \ubc0f \uaddc\uc815 \uc900\uc218 \uace0\ub824\uc0ac\ud56d","text":""},{"location":"cache-strategy/#gdpr","title":"GDPR \uc900\uc218 \uce90\uc2f1","text":"<pre><code>def handle_user_deletion(user_id):\n    \"\"\"GDPR \uc0ad\uc81c \uad8c\ub9ac \ucc98\ub9ac\"\"\"\n    # \uc0ac\uc6a9\uc790 \uad00\ub828 \ubaa8\ub4e0 \uc784\ubca0\ub529 \uce90\uc2dc \uc0ad\uc81c\n    cache_patterns = [\n        f\"embed:user:{user_id}:*\",\n        f\"embed:query:*:{user_id}:*\"\n    ]\n    for pattern in cache_patterns:\n        cache.delete_pattern(pattern)\n</code></pre>"},{"location":"cache-strategy/#_23","title":"\uc554\ud638\ud654 \ubc0f \uc811\uadfc \uc81c\uc5b4","text":"<pre><code># \uc800\uc7a5 \uc2dc \uc554\ud638\ud654\nencrypted_embedding = encrypt(embedding_data, key=ENCRYPTION_KEY)\ncache.set(cache_key, encrypted_embedding)\n\n# \uc870\ud68c \uc2dc \ubcf5\ud638\ud654\nencrypted_data = cache.get(cache_key)\nembedding = decrypt(encrypted_data, key=ENCRYPTION_KEY)\n</code></pre>"},{"location":"cache-strategy/#_24","title":"\uad6c\ud604 \uad8c\uc7a5\uc0ac\ud56d \ubc0f \ubca0\uc2a4\ud2b8 \ud504\ub799\ud2f0\uc2a4","text":""},{"location":"cache-strategy/#_25","title":"\uc989\uc2dc \uc801\uc6a9 \uac00\ub2a5\ud55c \ucd5c\uc801\ud654","text":"<ol> <li>\uae30\ubcf8 \uce90\uc2f1 \uad6c\ud604: 80% \uc774\uc0c1\uc758 \ud788\ud2b8\uc728 \ubaa9\ud45c\ub85c \uc2dc\uc791</li> <li>\uba40\ud2f0\ub808\ubca8 \uc544\ud0a4\ud14d\ucc98: L1(\uba54\ubaa8\ub9ac) + L2(Redis) + L3(\ubca1\ud130 DB)</li> <li>\uc77c\uad04 \ucc98\ub9ac: \ub124\ud2b8\uc6cc\ud06c \uc624\ubc84\ud5e4\ub4dc \ucd5c\uc18c\ud654</li> <li>\uc555\ucd95 \uc801\uc6a9: \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9 50% \uc808\uac10</li> </ol>"},{"location":"cache-strategy/#_26","title":"\uc911\uc7a5\uae30 \ucd5c\uc801\ud654 \uc804\ub7b5","text":"<ol> <li>\uc9c0\ub2a5\ud615 \ud504\ub9ac\ud398\uce6d: \uc561\uc138\uc2a4 \ud328\ud134 \ubd84\uc11d \uae30\ubc18 \uc120\uc81c\uc801 \ub85c\ub529</li> <li>\uc801\uc751\ud615 \uce90\uc2dc \uc815\ucc45: \uc6cc\ud06c\ub85c\ub4dc\uc5d0 \ub530\ub978 \ub3d9\uc801 \uc815\ucc45 \uc870\uc815</li> <li>\ubd84\uc0b0 \uce90\uc2f1: \uace0\uac00\uc6a9\uc131\uacfc \ud655\uc7a5\uc131\uc744 \uc704\ud55c \ud074\ub7ec\uc2a4\ud130 \uad6c\uc131</li> <li>\uc2e4\uc2dc\uac04 \ubaa8\ub2c8\ud130\ub9c1: \uc131\ub2a5 \uc9c0\ud45c \uae30\ubc18 \uc790\ub3d9 \ucd5c\uc801\ud654</li> </ol>"},{"location":"cache-strategy/#_27","title":"\ud22c\uc790 \ub300\ube44 \uc218\uc775","text":"<p>\ud544\uc694 \ud22c\uc790: - \uac1c\ubc1c \uc2dc\uac04: \uae30\ubcf8 \uad6c\ud604 2-4\uc8fc - \uc778\ud504\ub77c: 10-20% \ucd94\uac00 \ucef4\ud4e8\ud305 \ub9ac\uc18c\uc2a4 - \ubaa8\ub2c8\ud130\ub9c1: \uad00\ucc30 \uac00\ub2a5\uc131 \ub3c4\uad6c \ubc0f \ud504\ub85c\uc138\uc2a4</p> <p>\uc608\uc0c1 \uc218\uc775: - \uc131\ub2a5: 60-80% \uc9c0\uc5f0 \uc2dc\uac04 \uac10\uc18c - \ube44\uc6a9 \uc808\uac10: \ubc31\uc5d4\ub4dc \ub9ac\uc18c\uc2a4 \uc0ac\uc6a9\ub7c9 40-50% \uac10\uc18c - \uc0ac\uc6a9\uc790 \uacbd\ud5d8: \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \uc751\ub2f5\uc131 \ub300\ud3ed \uac1c\uc120 - \ud655\uc7a5\uc131: \uc2dc\uc2a4\ud15c \uc6a9\ub7c9 5-10\ubc30 \ud5a5\uc0c1</p>"},{"location":"cache-strategy/#_28","title":"\uacb0\ub860","text":"<p>\uc784\ubca0\ub529 \uce90\uc2f1\uc740 \ub2e8\uc21c\ud55c \uc131\ub2a5 \ucd5c\uc801\ud654\ub97c \ub118\uc5b4 \ud604\ub300 ML \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc758 \ud544\uc218 \uad6c\uc131 \uc694\uc18c\uc785\ub2c8\ub2e4. \uc801\uc808\ud788 \uad6c\ud604\ub41c \uce90\uc2f1 \uc804\ub7b5\uc740 \ube44\uc6a9\uc744 \uc808\ubc18\uc73c\ub85c \uc904\uc774\uba74\uc11c\ub3c4 \uc0ac\uc6a9\uc790 \uacbd\ud5d8\uc744 \ud68d\uae30\uc801\uc73c\ub85c \uac1c\uc120\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. </p> <p>\ud575\uc2ec\uc740 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc758 \ud2b9\uc131\uc5d0 \ub9de\ub294 \uce90\uc2f1 \uc804\ub7b5\uc744 \uc120\ud0dd\ud558\uace0, \uc9c0\uc18d\uc801\uc778 \ubaa8\ub2c8\ud130\ub9c1\uc744 \ud1b5\ud574 \ucd5c\uc801\ud654\ud558\ub294 \uac83\uc785\ub2c8\ub2e4. LangChain\uc758 \ub2e8\uc21c\ud568, \ubd84\uc0b0 \uc2dc\uc2a4\ud15c\uc758 \ud655\uc7a5\uc131, \uadf8\ub9ac\uace0 \ubca1\ud130 \ub370\uc774\ud130\ubca0\uc774\uc2a4\uc758 \uc804\ubb38\uc131\uc744 \uc801\uc808\ud788 \uc870\ud569\ud558\uc5ec \ucd5c\uc0c1\uc758 \uc131\ub2a5\uc744 \ub2ec\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"mcp_resource_management/","title":"MCP \ub9ac\uc18c\uc2a4 \uad00\ub9ac \uac00\uc774\ub4dc","text":"<p>\uc774 \ubb38\uc11c\ub294 pyhub-llm\uc5d0\uc11c MCP(Model Context Protocol) \uc5f0\uacb0\uc758 \ub9ac\uc18c\uc2a4 \uad00\ub9ac\uc5d0 \ub300\ud574 \uc124\uba85\ud569\ub2c8\ub2e4.</p>"},{"location":"mcp_resource_management/#_1","title":"\uac1c\uc694","text":"<p>MCP\ub97c \uc0ac\uc6a9\ud560 \ub54c \uc678\ubd80 \ud504\ub85c\uc138\uc2a4\ub098 \ub124\ud2b8\uc6cc\ud06c \uc5f0\uacb0\uc774 \uc0dd\uc131\ub429\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ub9ac\uc18c\uc2a4\ub4e4\uc740 \ud504\ub85c\uadf8\ub7a8 \uc885\ub8cc \uc2dc \uc801\uc808\ud788 \uc815\ub9ac\ub418\uc5b4\uc57c \ud569\ub2c8\ub2e4. pyhub-llm\uc740 \ub2e4\uc74c\uacfc \uac19\uc740 \uba54\ucee4\ub2c8\uc998\uc744 \ud1b5\ud574 \uc790\ub3d9 \ub9ac\uc18c\uc2a4 \uc815\ub9ac\ub97c \uc9c0\uc6d0\ud569\ub2c8\ub2e4:</p> <ol> <li>Finalizer \ud328\ud134: \uac1d\uccb4\uac00 \uac00\ube44\uc9c0 \uceec\ub809\uc158\ub420 \ub54c \uc790\ub3d9 \uc815\ub9ac</li> <li>\uc2dc\uadf8\ub110 \ud578\ub4e4\ub9c1: SIGTERM/SIGINT \uc218\uc2e0 \uc2dc graceful shutdown</li> <li>\ud0c0\uc784\uc544\uc6c3 \ucc98\ub9ac: \uc815\ub9ac \uc791\uc5c5\uc774 \ubb34\ud55c \ub300\uae30\ud558\uc9c0 \uc54a\ub3c4\ub85d \ubcf4\uc7a5</li> <li>\uc804\uc5ed \ub808\uc9c0\uc2a4\ud2b8\ub9ac: \ubaa8\ub4e0 \ud65c\uc131 \uc5f0\uacb0 \ucd94\uc801 \ubc0f \uad00\ub9ac</li> </ol>"},{"location":"mcp_resource_management/#_2","title":"\uc0ac\uc6a9 \ubc29\ubc95","text":""},{"location":"mcp_resource_management/#_3","title":"\uae30\ubcf8 \uc0ac\uc6a9\ubc95","text":"<pre><code>from pyhub.llm import LLM\n\n# MCP \uc11c\ubc84 \uc124\uc815\nmcp_config = [{\n    \"type\": \"stdio\",\n    \"name\": \"calculator\",\n    \"cmd\": [\"python\", \"-m\", \"calculator_server\"]\n}]\n\n# LLM \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131 (\uc790\ub3d9 \ub9ac\uc18c\uc2a4 \uad00\ub9ac)\nllm = LLM.create(\"gpt-4o-mini\", mcp_servers=mcp_config)\n\n# \uc0ac\uc6a9\nresponse = llm.ask(\"2 + 2\ub294?\")\n\n# \uba85\uc2dc\uc801 \uc815\ub9ac (\uc120\ud0dd\uc0ac\ud56d - \uc790\ub3d9\uc73c\ub85c\ub3c4 \ucc98\ub9ac\ub428)\nawait llm.close_mcp()\n</code></pre>"},{"location":"mcp_resource_management/#_4","title":"\ube44\ub3d9\uae30 \ucee8\ud14d\uc2a4\ud2b8 \ub9e4\ub2c8\uc800 (\uad8c\uc7a5)","text":"<pre><code>async with await LLM.create_async(\"gpt-4o-mini\", mcp_servers=mcp_config) as llm:\n    response = await llm.ask_async(\"\uacc4\uc0b0\ud574\uc918: 15 * 24\")\n    # \ucee8\ud14d\uc2a4\ud2b8 \uc885\ub8cc \uc2dc \uc790\ub3d9 \uc815\ub9ac\n</code></pre>"},{"location":"mcp_resource_management/#_5","title":"\uc218\ub3d9 \ub9ac\uc18c\uc2a4 \uad00\ub9ac","text":"<pre><code>llm = await LLM.create_async(\"gpt-4o-mini\", mcp_servers=mcp_config)\ntry:\n    # LLM \uc0ac\uc6a9\n    response = await llm.ask_async(\"...\")\nfinally:\n    # \ud0c0\uc784\uc544\uc6c3 \uc9c0\uc815 \uac00\ub2a5 (\uae30\ubcf8 5\ucd08)\n    await llm.close_mcp(timeout=10.0)\n</code></pre>"},{"location":"mcp_resource_management/#_6","title":"\ub9ac\uc18c\uc2a4 \uc815\ub9ac \uba54\ucee4\ub2c8\uc998","text":""},{"location":"mcp_resource_management/#1-finalizer","title":"1. Finalizer\ub97c \ud1b5\ud55c \uc790\ub3d9 \uc815\ub9ac","text":"<p>MCP\uac00 \uc124\uc815\ub41c LLM \uc778\uc2a4\ud134\uc2a4\ub294 \uc0dd\uc131 \uc2dc \uc790\ub3d9\uc73c\ub85c finalizer\uac00 \ub4f1\ub85d\ub429\ub2c8\ub2e4:</p> <pre><code># \ub0b4\ubd80\uc801\uc73c\ub85c \ub2e4\uc74c\uacfc \uac19\uc774 \ub3d9\uc791\nif self.mcp_servers:\n    self._finalizer = weakref.finalize(self, cleanup_function)\n</code></pre> <p>\uac1d\uccb4\uac00 \uac00\ube44\uc9c0 \uceec\ub809\uc158\ub420 \ub54c \uc790\ub3d9\uc73c\ub85c MCP \uc5f0\uacb0\uc774 \uc885\ub8cc\ub429\ub2c8\ub2e4.</p>"},{"location":"mcp_resource_management/#2","title":"2. \uc2dc\uadf8\ub110 \ud578\ub4e4\ub9c1","text":"<p>\ud504\ub85c\uadf8\ub7a8\uc774 SIGTERM\uc774\ub098 SIGINT\ub97c \ubc1b\uc73c\uba74 \ubaa8\ub4e0 MCP \uc5f0\uacb0\uc774 graceful\ud558\uac8c \uc885\ub8cc\ub429\ub2c8\ub2e4:</p> <pre><code># \uc790\ub3d9\uc73c\ub85c \ucc98\ub9ac\ub428 - \ubcc4\ub3c4 \uc124\uc815 \ubd88\ud544\uc694\n# Ctrl+C\ub97c \ub204\ub974\uac70\ub098 \ud504\ub85c\uc138\uc2a4\uac00 \uc885\ub8cc \uc2dc\uadf8\ub110\uc744 \ubc1b\uc73c\uba74\n# \ubaa8\ub4e0 \ud65c\uc131 MCP \uc5f0\uacb0\uc774 \uc815\ub9ac\ub428\n</code></pre>"},{"location":"mcp_resource_management/#3","title":"3. \ud0c0\uc784\uc544\uc6c3 \ucc98\ub9ac","text":"<p>\ub9ac\uc18c\uc2a4 \uc815\ub9ac \uc2dc \ubb34\ud55c \ub300\uae30\ub97c \ubc29\uc9c0\ud558\uae30 \uc704\ud574 \ud0c0\uc784\uc544\uc6c3\uc774 \uc801\uc6a9\ub429\ub2c8\ub2e4:</p> <pre><code># \uae30\ubcf8 5\ucd08 \ud0c0\uc784\uc544\uc6c3\nawait llm.close_mcp()\n\n# \ucee4\uc2a4\ud140 \ud0c0\uc784\uc544\uc6c3\nawait llm.close_mcp(timeout=10.0)\n</code></pre>"},{"location":"mcp_resource_management/#4","title":"4. \uc804\uc5ed \ub808\uc9c0\uc2a4\ud2b8\ub9ac","text":"<p>\ubaa8\ub4e0 MCP \uc5f0\uacb0\uc740 \uc804\uc5ed \ub808\uc9c0\uc2a4\ud2b8\ub9ac\uc5d0\uc11c \ucd94\uc801\ub429\ub2c8\ub2e4:</p> <pre><code>from pyhub.llm.resource_manager import MCPResourceRegistry\n\n# \uc2f1\uae00\ud1a4 \uc778\uc2a4\ud134\uc2a4\nregistry = MCPResourceRegistry()\n\n# \ud604\uc7ac \ud65c\uc131 \uc5f0\uacb0 \uc218 \ud655\uc778\nactive_count = len(registry._instances)\n</code></pre>"},{"location":"mcp_resource_management/#_7","title":"\uc8fc\uc758\uc0ac\ud56d","text":""},{"location":"mcp_resource_management/#1","title":"1. \uc7a5\uc2dc\uac04 \uc2e4\ud589 \uc560\ud50c\ub9ac\ucf00\uc774\uc158","text":"<p>\uc7a5\uc2dc\uac04 \uc2e4\ud589\ub418\ub294 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc5d0\uc11c\ub294 \uba85\uc2dc\uc801\uc73c\ub85c \ub9ac\uc18c\uc2a4\ub97c \uad00\ub9ac\ud558\ub294 \uac83\uc774 \uc88b\uc2b5\ub2c8\ub2e4:</p> <pre><code># \uc8fc\uae30\uc801\uc73c\ub85c \uc0ac\uc6a9\ud558\uc9c0 \uc54a\ub294 \uc5f0\uacb0 \uc815\ub9ac\nasync def periodic_cleanup():\n    for llm in inactive_llms:\n        await llm.close_mcp()\n</code></pre>"},{"location":"mcp_resource_management/#2_1","title":"2. \ud504\ub85c\uc138\uc2a4 \ud480 \uc0ac\uc6a9 \uc2dc","text":"<p>multiprocessing\uc744 \uc0ac\uc6a9\ud560 \ub54c\ub294 \uac01 \ud504\ub85c\uc138\uc2a4\uc5d0\uc11c \ub3c5\ub9bd\uc801\uc73c\ub85c LLM \uc778\uc2a4\ud134\uc2a4\ub97c \uc0dd\uc131\ud574\uc57c \ud569\ub2c8\ub2e4:</p> <pre><code>def worker_function():\n    # \uac01 \uc6cc\ucee4 \ud504\ub85c\uc138\uc2a4\uc5d0\uc11c \ubcc4\ub3c4 \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131\n    llm = LLM.create(\"gpt-4o-mini\", mcp_servers=config)\n    try:\n        # \uc791\uc5c5 \uc218\ud589\n        pass\n    finally:\n        asyncio.run(llm.close_mcp())\n</code></pre>"},{"location":"mcp_resource_management/#3_1","title":"3. \ud14c\uc2a4\ud2b8 \ud658\uacbd","text":"<p>\ud14c\uc2a4\ud2b8\uc5d0\uc11c\ub294 \uc2dc\uadf8\ub110 \ud578\ub4e4\ub7ec\uac00 \uc790\ub3d9\uc73c\ub85c \ube44\ud65c\uc131\ud654\ub429\ub2c8\ub2e4:</p> <pre><code># pytest \uc2e4\ud589 \uc2dc \uc790\ub3d9\uc73c\ub85c \uac10\uc9c0\ub418\uc5b4 \uc2dc\uadf8\ub110 \ud578\ub4e4\ub7ec \ube44\ud65c\uc131\ud654\n# \ud544\uc694\ud55c \uacbd\uc6b0 \uc218\ub3d9\uc73c\ub85c \ud65c\uc131\ud654 \uac00\ub2a5\nregistry.enable_signal_handlers()\n</code></pre>"},{"location":"mcp_resource_management/#_8","title":"\ub514\ubc84\uae45","text":"<p>\ub9ac\uc18c\uc2a4 \uc815\ub9ac \uad00\ub828 \ub85c\uadf8\ub97c \ud655\uc778\ud558\ub824\uba74:</p> <pre><code>import logging\n\n# \ub9ac\uc18c\uc2a4 \uad00\ub9ac\uc790 \ub85c\uadf8 \ud65c\uc131\ud654\nlogging.getLogger('pyhub.llm.resource_manager').setLevel(logging.DEBUG)\nlogging.getLogger('pyhub.llm.mcp').setLevel(logging.DEBUG)\n</code></pre> <p>\ub85c\uadf8 \uc608\uc2dc: <pre><code>INFO: MCP connections closed\nWARNING: MCP cleanup timed out after 5.0s\nERROR: Error closing MCP connections: Connection refused\nDEBUG: Finalizer called for instance 140234567890\n</code></pre></p>"},{"location":"mcp_resource_management/#_9","title":"\ubb38\uc81c \ud574\uacb0","text":""},{"location":"mcp_resource_management/#_10","title":"\ud504\ub85c\uc138\uc2a4\uac00 \uc885\ub8cc\ub418\uc9c0 \uc54a\ub294 \uacbd\uc6b0","text":"<ol> <li> <p>\ud0c0\uc784\uc544\uc6c3\uc744 \ub298\ub824\ubcf4\uc138\uc694:    <pre><code>await llm.close_mcp(timeout=30.0)\n</code></pre></p> </li> <li> <p>\uc218\ub3d9\uc73c\ub85c \ubaa8\ub4e0 \uc5f0\uacb0 \uc815\ub9ac:    <pre><code>registry = MCPResourceRegistry()\nawait registry._async_cleanup_all()\n</code></pre></p> </li> </ol>"},{"location":"mcp_resource_management/#there-is-no-current-event-loop","title":"\"There is no current event loop\" \uc5d0\ub7ec","text":"<p>\ube44\ub3d9\uae30 \ucee8\ud14d\uc2a4\ud2b8\uac00 \uc544\ub2cc \uacf3\uc5d0\uc11c cleanup\uc774 \ud638\ucd9c\ub420 \ub54c \ubc1c\uc0dd\ud569\ub2c8\ub2e4. \uc774\ub294 \uc815\uc0c1\uc801\uc778 \ub3d9\uc791\uc774\uba70, finalizer\uac00 \uc0c8 \uc774\ubca4\ud2b8 \ub8e8\ud504\ub97c \uc0dd\uc131\ud558\uc5ec \ucc98\ub9ac\ud569\ub2c8\ub2e4.</p>"},{"location":"mcp_resource_management/#_11","title":"\ub9ac\uc18c\uc2a4 \ub204\uc218 \uc758\uc2ec \uc2dc","text":"<ol> <li> <p>\ud65c\uc131 \uc5f0\uacb0 \ud655\uc778:    <pre><code>registry = MCPResourceRegistry()\nprint(f\"Active connections: {len(registry._instances)}\")\n</code></pre></p> </li> <li> <p>\uba85\uc2dc\uc801 \uc815\ub9ac \uac15\uc81c:    <pre><code>for instance_id in list(registry._instances.keys()):\n    await registry._cleanup_instance(instance_id)\n</code></pre></p> </li> </ol>"},{"location":"mcp_resource_management/#best-practices","title":"Best Practices","text":"<ol> <li> <p>\ud56d\uc0c1 \ucee8\ud14d\uc2a4\ud2b8 \ub9e4\ub2c8\uc800 \uc0ac\uc6a9: \uac00\ub2a5\ud558\uba74 <code>async with</code> \uad6c\ubb38\uc744 \uc0ac\uc6a9\ud558\uc138\uc694.</p> </li> <li> <p>\uc7a5\uc2dc\uac04 \uc5f0\uacb0 \ud53c\ud558\uae30: MCP \uc5f0\uacb0\uc744 \ud544\uc694\ud560 \ub54c\ub9cc \uc0dd\uc131\ud558\uace0 \uc0ac\uc6a9 \ud6c4 \uc815\ub9ac\ud558\uc138\uc694.</p> </li> <li> <p>\uc5d0\ub7ec \ud578\ub4e4\ub9c1: MCP \uc791\uc5c5 \uc2dc \ud56d\uc0c1 \uc608\uc678 \ucc98\ub9ac\ub97c \ud3ec\ud568\ud558\uc138\uc694:    <pre><code>try:\n    response = await llm.ask_async(\"...\")\nexcept Exception as e:\n    logger.error(f\"MCP operation failed: {e}\")\nfinally:\n    await llm.close_mcp()\n</code></pre></p> </li> <li> <p>\ub9ac\uc18c\uc2a4 \ubaa8\ub2c8\ud130\ub9c1: \ud504\ub85c\ub355\uc158 \ud658\uacbd\uc5d0\uc11c\ub294 \ud65c\uc131 \uc5f0\uacb0 \uc218\ub97c \ubaa8\ub2c8\ud130\ub9c1\ud558\uc138\uc694.</p> </li> </ol>"},{"location":"mcp_resource_management/#_12","title":"\uad00\ub828 \ub9c1\ud06c","text":"<ul> <li>MCP \ud504\ub85c\ud1a0\ucf5c \ubb38\uc11c</li> <li>pyhub-llm MCP \ud1b5\ud569 \uac00\uc774\ub4dc</li> <li>\ube44\ub3d9\uae30 \ud504\ub85c\uadf8\ub798\ubc0d \uac00\uc774\ub4dc</li> </ul>"},{"location":"examples/","title":"\ud83d\ude80 pyhub-llm \uc608\uc81c \uac00\uc774\ub4dc","text":"<p>AI\uc640 \ub300\ud654\ud558\ub294 \ud504\ub85c\uadf8\ub7a8\uc744 \ub9cc\ub4e4\uc5b4\ubcf4\uace0 \uc2f6\uc73c\uc2e0\uac00\uc694? \uc774 \uac00\uc774\ub4dc\ub294 Python \uae30\ucd08\ub9cc \uc54c\uace0 \uc788\ub294 \ubd84\ub4e4\uc744 \uc704\ud574 \uc900\ube44\ud588\uc2b5\ub2c8\ub2e4.</p>"},{"location":"examples/#_1","title":"\ud83d\udcda \uc774 \uac00\uc774\ub4dc\ub97c \uc77d\uae30 \uc804\uc5d0 \uc54c\uc544\uc57c \ud560 \uac83","text":"<ul> <li>Python \uae30\ucd08 (\ubcc0\uc218, \ud568\uc218, \ubc18\ubcf5\ubb38, \uc870\uac74\ubb38)</li> <li>\ud14d\uc2a4\ud2b8 \uc5d0\ub514\ud130 \uc0ac\uc6a9\ubc95 (VS Code, PyCharm \ub4f1)</li> <li>\ud130\ubbf8\ub110/\uba85\ub839 \ud504\ub86c\ud504\ud2b8 \uae30\ubcf8 \uc0ac\uc6a9\ubc95</li> </ul> <p>\ubab0\ub77c\ub3c4 \ub418\ub294 \uac83\ub4e4: - \u274c langchain, OpenAI API\uc5d0 \ub300\ud55c \uc9c0\uc2dd - \u274c \uba38\uc2e0\ub7ec\ub2dd\uc774\ub098 AI\uc5d0 \ub300\ud55c \uc804\ubb38 \uc9c0\uc2dd - \u274c \uc6f9 \uac1c\ubc1c \uacbd\ud5d8</p>"},{"location":"examples/#_2","title":"\ud83d\uddfa\ufe0f \ud559\uc2b5 \uacbd\ub85c","text":""},{"location":"examples/#1-3","title":"\ud83c\udf31 \ucd08\ubcf4\uc790 \ucf54\uc2a4 (1-3\uc77c)","text":"<ol> <li>\uc2dc\uc791\ud558\uae30 \uc804\uc5d0 - \uc900\ube44\ubb3c\uacfc \uae30\ubcf8 \uac1c\ub150</li> <li>\uccab AI \ub300\ud654 - Hello World\ubd80\ud130 \uc2dc\uc791\ud558\uae30</li> <li>\uc77c\uc0c1 \uc791\uc5c5 \uc790\ub3d9\ud654 - \ubc88\uc5ed, \uc694\uc57d \ub4f1 \uc2e4\uc6a9\uc801\uc778 \uc608\uc81c</li> </ol>"},{"location":"examples/#1","title":"\ud83c\udf3f \uc911\uae09\uc790 \ucf54\uc2a4 (1\uc8fc\uc77c)","text":"<ol> <li>\ub300\ud654 \uc774\uc5b4\uac00\uae30 - \uac04\ub2e8\ud55c \ucc57\ubd07 \ub9cc\ub4e4\uae30</li> <li>\ud30c\uc77c \ub2e4\ub8e8\uae30 - \uc774\ubbf8\uc9c0\uc640 \ubb38\uc11c \ucc98\ub9ac</li> <li>\uc815\ud615\ud654\ub41c \ub370\uc774\ud130 - \uccb4\uacc4\uc801\uc778 \uc751\ub2f5 \ubc1b\uae30</li> </ol>"},{"location":"examples/#2","title":"\ud83c\udf33 \uace0\uae09\uc790 \ucf54\uc2a4 (2\uc8fc\uc77c)","text":"<ol> <li>\ub2e4\uc591\ud55c AI \ubaa8\ub378 - OpenAI, Claude, Ollama \ud65c\uc6a9</li> <li>\ube44\uc6a9 \uc808\uc57d\ud558\uae30 - \ud6a8\uc728\uc801\uc778 AI \uc0ac\uc6a9\ubc95</li> <li>\uc2e4\uc804 \ud504\ub85c\uc81d\ud2b8 - \uc644\uc131\ub41c \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30</li> </ol>"},{"location":"examples/#_3","title":"\ud83d\udca1 \uc774 \uac00\uc774\ub4dc\uc758 \ud2b9\uc9d5","text":""},{"location":"examples/#_4","title":"\ud83d\udcdd \ubaa8\ub4e0 \ucf54\ub4dc\uc5d0 \ud55c\uae00 \uc8fc\uc11d","text":"<pre><code># AI \ub3c4\uc6b0\ubbf8\ub97c \ub9cc\ub4ed\ub2c8\ub2e4\nassistant = LLM.create(\"gpt-4o-mini\")\n\n# \uc9c8\ubb38\uc744 \ud569\ub2c8\ub2e4\nresponse = assistant.ask(\"\uc548\ub155\ud558\uc138\uc694!\")\n\n# \ub2f5\ubcc0\uc744 \ucd9c\ub825\ud569\ub2c8\ub2e4\nprint(response.text)\n</code></pre>"},{"location":"examples/#_5","title":"\ud83c\udfaf \uc2e4\ud589 \uac00\ub2a5\ud55c \uc644\uc804\ud55c \uc608\uc81c","text":"<p>\ubaa8\ub4e0 \uc608\uc81c\ub294 \ubcf5\uc0ac-\ubd99\uc5ec\ub123\uae30\ub9cc\uc73c\ub85c \ubc14\ub85c \uc2e4\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"examples/#_6","title":"\ud83d\udd0d \uc608\uc0c1 \uacb0\uacfc \ud3ec\ud568","text":"<pre><code>\uc2e4\ud589 \uacb0\uacfc:\n\uc548\ub155\ud558\uc138\uc694! \ubb34\uc5c7\uc744 \ub3c4\uc640\ub4dc\ub9b4\uae4c\uc694?\n</code></pre>"},{"location":"examples/#_7","title":"\ud83d\udcb0 \ube44\uc6a9 \uc815\ubcf4","text":"<p>\uac01 \uc608\uc81c\ub9c8\ub2e4 \ub300\ub7b5\uc801\uc778 API \uc0ac\uc6a9 \ube44\uc6a9\uc744 \ud45c\uc2dc\ud569\ub2c8\ub2e4. <pre><code>\ud83d\udcb0 \uc608\uc0c1 \ube44\uc6a9: \uc57d 0.01\uc6d0 (10\ud1a0\ud070)\n</code></pre></p>"},{"location":"examples/#_8","title":"\ud83d\udea6 \uc2dc\uc791\ud558\uae30","text":"<ol> <li>Python \uc124\uce58 \ud655\uc778\ud558\uae30</li> <li>API \ud0a4 \ubc1b\uae30</li> <li>\uccab \ubc88\uc9f8 \uc608\uc81c \uc2e4\ud589\ud558\uae30</li> </ol>"},{"location":"examples/#_9","title":"\u2753 \ub3c4\uc6c0\uc774 \ud544\uc694\ud558\uc2e0\uac00\uc694?","text":"<ul> <li>\uc790\uc8fc \ubb3b\ub294 \uc9c8\ubb38</li> <li>\uc77c\ubc18\uc801\uc778 \uc624\ub958 \ud574\uacb0</li> <li>\ucee4\ubba4\ub2c8\ud2f0 \uc9c0\uc6d0</li> </ul> <p>\ud83c\udf89 \ud658\uc601\ud569\ub2c8\ub2e4! AI \ud504\ub85c\uadf8\ub798\ubc0d\uc758 \uc138\uacc4\ub85c \uccab \ubc1c\uc744 \ub0b4\ub51b\uc73c\uc2e0 \uac83\uc744 \ucd95\ud558\ud569\ub2c8\ub2e4. \uc774\uc81c \uc2dc\uc791\ud574\ubcfc\uae4c\uc694?</p>"},{"location":"examples/00-before-you-start/","title":"\ud83c\udfaf \uc2dc\uc791\ud558\uae30 \uc804\uc5d0","text":"<p>AI \ud504\ub85c\uadf8\ub798\ubc0d\uc744 \uc2dc\uc791\ud558\uae30 \uc804\uc5d0 \uaf2d \uc54c\uc544\uc57c \ud560 \uac83\ub4e4\uc744 \uc815\ub9ac\ud588\uc2b5\ub2c8\ub2e4.</p>"},{"location":"examples/00-before-you-start/#_2","title":"\ud83d\udccb \uc900\ube44\ubb3c \uccb4\ud06c\ub9ac\uc2a4\ud2b8","text":""},{"location":"examples/00-before-you-start/#_3","title":"\u2705 \ud544\uc218 \uc900\ube44\ubb3c","text":"<ul> <li> Python 3.8 \uc774\uc0c1 \uc124\uce58</li> <li> pip (Python \ud328\ud0a4\uc9c0 \uad00\ub9ac\uc790)</li> <li> \ud14d\uc2a4\ud2b8 \uc5d0\ub514\ud130 (VS Code \ucd94\ucc9c)</li> <li> \uc778\ud130\ub137 \uc5f0\uacb0</li> </ul>"},{"location":"examples/00-before-you-start/#api","title":"\ud83d\udcb3 API \ud0a4 (\ub2e4\uc74c \uc911 \ud558\ub098)","text":"<ul> <li> OpenAI API \ud0a4 (\uc720\ub8cc)</li> <li> Anthropic API \ud0a4 (\uc720\ub8cc)</li> <li> \ub610\ub294 Ollama \uc124\uce58 (\ubb34\ub8cc, \ub85c\uceec \uc2e4\ud589)</li> </ul>"},{"location":"examples/00-before-you-start/#_4","title":"\ud83e\udd14 \uc790\uc8fc \ubb3b\ub294 \uc9c8\ubb38","text":""},{"location":"examples/00-before-you-start/#q-ai","title":"Q: AI\uac00 \ubb54\uac00\uc694?","text":"<p>A: AI(\uc778\uacf5\uc9c0\ub2a5)\ub294 \uc0ac\ub78c\ucc98\ub7fc \uc0dd\uac01\ud558\uace0 \ub300\ub2f5\ud560 \uc218 \uc788\ub294 \ucef4\ud4e8\ud130 \ud504\ub85c\uadf8\ub7a8\uc785\ub2c8\ub2e4.  \uc6b0\ub9ac\uac00 \uc0ac\uc6a9\ud560 AI\ub294 \uc9c8\ubb38\uc5d0 \ub2f5\ud558\uace0, \uae00\uc744 \uc4f0\uace0, \ubc88\uc5ed\uc744 \ud558\ub294 \ub4f1 \ub2e4\uc591\ud55c \uc77c\uc744 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"examples/00-before-you-start/#q-api","title":"Q: API\uac00 \ubb54\uac00\uc694?","text":"<p>A: API\ub294 \ud504\ub85c\uadf8\ub7a8\ub07c\ub9ac \ub300\ud654\ud558\ub294 \ubc29\ubc95\uc785\ub2c8\ub2e4.  - \uc6b0\ub9ac \ud504\ub85c\uadf8\ub7a8 \u2192 API \u2192 AI \uc11c\ube44\uc2a4 - AI \uc11c\ube44\uc2a4 \u2192 API \u2192 \uc6b0\ub9ac \ud504\ub85c\uadf8\ub7a8</p> <p>\uc774\ub807\uac8c \uc8fc\uace0\ubc1b\uc2b5\ub2c8\ub2e4.</p>"},{"location":"examples/00-before-you-start/#q-api_1","title":"Q: API \ud0a4\uac00 \ubb54\uac00\uc694?","text":"<p>A: API \ud0a4\ub294 AI \uc11c\ube44\uc2a4\ub97c \uc0ac\uc6a9\ud558\uae30 \uc704\ud55c \"\ube44\ubc00\ubc88\ud638\"\uc785\ub2c8\ub2e4. - \uc740\ud589 \uce74\ub4dc\uc758 \ube44\ubc00\ubc88\ud638\ucc98\ub7fc \ub0a8\uc5d0\uac8c \uc54c\ub824\uc8fc\uba74 \uc548 \ub429\ub2c8\ub2e4 - \uc11c\ube44\uc2a4\ub97c \uc0ac\uc6a9\ud560 \ub54c\ub9c8\ub2e4 \uc774 \ud0a4\ub85c \ubcf8\uc778 \ud655\uc778\uc744 \ud569\ub2c8\ub2e4</p>"},{"location":"examples/00-before-you-start/#q","title":"Q: \ub3c8\uc774 \ub4dc\ub098\uc694?","text":"<p>A:  - OpenAI, Anthropic: \uc0ac\uc6a9\ud55c \ub9cc\ud07c \ube44\uc6a9 \ubc1c\uc0dd (\ucc98\uc74c\uc5d0 \ubb34\ub8cc \ud06c\ub808\ub527 \uc81c\uacf5) - Ollama: \uc644\uc804 \ubb34\ub8cc (\ub0b4 \ucef4\ud4e8\ud130\uc5d0\uc11c \uc2e4\ud589)</p>"},{"location":"examples/00-before-you-start/#_5","title":"\ud83d\udcda \uc774 \uc139\uc158\uc758 \ub0b4\uc6a9","text":"<ol> <li>Python \uae30\ucd08 \ud655\uc778</li> <li>Python\uc774 \uc81c\ub300\ub85c \uc124\uce58\ub418\uc5c8\ub294\uc9c0 \ud655\uc778</li> <li> <p>\ud544\uc694\ud55c \uae30\ucd08 \ubb38\ubc95 \ubcf5\uc2b5</p> </li> <li> <p>API \ud0a4 \uc790\uc138\ud788 \uc54c\uc544\ubcf4\uae30</p> </li> <li>API \ud0a4 \ubc1b\ub294 \ubc29\ubc95</li> <li>\uc548\uc804\ud558\uac8c \ubcf4\uad00\ud558\ub294 \ubc29\ubc95</li> <li>\uccab API \ud0a4 \uc124\uc815\ud558\uae30</li> </ol>"},{"location":"examples/00-before-you-start/#_6","title":"\ud83d\udca1 \ud301","text":"<p>\ucd08\ubcf4\uc790\ub97c \uc704\ud55c \uc870\uc5b8: \ucc98\uc74c\uc5d4 Ollama(\ubb34\ub8cc)\ub85c \uc2dc\uc791\ud574\ubcf4\uace0, \uc775\uc219\ud574\uc9c0\uba74 OpenAI\ub098 Anthropic\uc744 \uc0ac\uc6a9\ud574\ubcf4\uc138\uc694.</p>"},{"location":"examples/00-before-you-start/#_7","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>\ubaa8\ub4e0 \uc900\ube44\uac00 \ub05d\ub0ac\ub2e4\uba74, \uccab AI \ub300\ud654\ub85c \ub118\uc5b4\uac00\uc138\uc694!</p>"},{"location":"examples/00-before-you-start/api-keys-explained/","title":"\ud83d\udd11 API \ud0a4 \uc644\ubcbd \uac00\uc774\ub4dc","text":"<p>API \ud0a4\ub294 AI \uc11c\ube44\uc2a4\ub97c \uc0ac\uc6a9\ud558\uae30 \uc704\ud55c \"\uc785\uc7a5\uad8c\"\uc785\ub2c8\ub2e4. \uc790\uc138\ud788 \uc54c\uc544\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/00-before-you-start/api-keys-explained/#api_1","title":"\ud83e\udd14 API \ud0a4\uac00 \uc65c \ud544\uc694\ud55c\uac00\uc694?","text":""},{"location":"examples/00-before-you-start/api-keys-explained/#_1","title":"\uc2e4\uc0dd\ud65c \ube44\uc720","text":"<ul> <li>\ud5ec\uc2a4\uc7a5 \ud68c\uc6d0\uc99d: \ud5ec\uc2a4\uc7a5\uc744 \uc774\uc6a9\ud558\ub824\uba74 \ud68c\uc6d0\uc99d\uc774 \ud544\uc694\ud558\ub4ef\uc774</li> <li>\ub3c4\uc11c\uad00 \uce74\ub4dc: \ub3c4\uc11c\uad00\uc5d0\uc11c \ucc45\uc744 \ube4c\ub9ac\ub824\uba74 \uce74\ub4dc\uac00 \ud544\uc694\ud558\ub4ef\uc774</li> <li>API \ud0a4: AI \uc11c\ube44\uc2a4\ub97c \uc0ac\uc6a9\ud558\ub824\uba74 API \ud0a4\uac00 \ud544\uc694\ud569\ub2c8\ub2e4</li> </ul>"},{"location":"examples/00-before-you-start/api-keys-explained/#api_2","title":"API \ud0a4\uc758 \uc5ed\ud560","text":"<ol> <li>\uc2e0\uc6d0 \ud655\uc778: \"\ub2f9\uc2e0\uc774 \ub204\uad6c\uc778\uc9c0\" \ud655\uc778</li> <li>\uc0ac\uc6a9\ub7c9 \ucd94\uc801: \uc5bc\ub9c8\ub098 \uc0ac\uc6a9\ud588\ub294\uc9c0 \uae30\ub85d</li> <li>\uc694\uae08 \uccad\uad6c: \uc0ac\uc6a9\ud55c \ub9cc\ud07c \ube44\uc6a9 \uacc4\uc0b0</li> </ol>"},{"location":"examples/00-before-you-start/api-keys-explained/#api_3","title":"\ud83c\udfea API \ud0a4 \ubc1b\ub294 \uacf3","text":""},{"location":"examples/00-before-you-start/api-keys-explained/#1-openai-chatgpt","title":"1. OpenAI (ChatGPT \ub9cc\ub4e0 \ud68c\uc0ac)","text":"<ul> <li>\uc0ac\uc774\ud2b8: platform.openai.com</li> <li>\uac00\uaca9: \uc0ac\uc6a9\ud55c \ub9cc\ud07c (1,000\ud1a0\ud070\ub2f9 \uc57d 2\uc6d0)</li> <li>\ubb34\ub8cc \ud06c\ub808\ub527: \ucc98\uc74c \uac00\uc785 \uc2dc $5 \uc81c\uacf5</li> </ul>"},{"location":"examples/00-before-you-start/api-keys-explained/#2-anthropic-claude","title":"2. Anthropic (Claude \ub9cc\ub4e0 \ud68c\uc0ac)","text":"<ul> <li>\uc0ac\uc774\ud2b8: console.anthropic.com</li> <li>\uac00\uaca9: \uc0ac\uc6a9\ud55c \ub9cc\ud07c (OpenAI\uc640 \ube44\uc2b7)</li> <li>\ubb34\ub8cc \ud06c\ub808\ub527: \ucc98\uc74c \uac00\uc785 \uc2dc \uc81c\uacf5</li> </ul>"},{"location":"examples/00-before-you-start/api-keys-explained/#3-ollama","title":"3. Ollama (\ubb34\ub8cc!)","text":"<ul> <li>\uc0ac\uc774\ud2b8: ollama.ai</li> <li>\uac00\uaca9: \uc644\uc804 \ubb34\ub8cc (\ub0b4 \ucef4\ud4e8\ud130\uc5d0\uc11c \uc2e4\ud589)</li> <li>\ub2e8\uc810: \uc131\ub2a5\uc774 \uc870\uae08 \ub5a8\uc5b4\uc9c8 \uc218 \uc788\uc74c</li> </ul>"},{"location":"examples/00-before-you-start/api-keys-explained/#openai-api","title":"\ud83d\udcdd OpenAI API \ud0a4 \ubc1b\uae30 (\ub2e8\uacc4\ubcc4 \uac00\uc774\ub4dc)","text":""},{"location":"examples/00-before-you-start/api-keys-explained/#1","title":"1\ub2e8\uacc4: \ud68c\uc6d0\uac00\uc785","text":"<pre><code>1. platform.openai.com \uc811\uc18d\n2. \"Sign up\" \ud074\ub9ad\n3. \uc774\uba54\uc77c\ub85c \uac00\uc785 \ub610\ub294 \uad6c\uae00 \uacc4\uc815\uc73c\ub85c \uac00\uc785\n</code></pre>"},{"location":"examples/00-before-you-start/api-keys-explained/#2-api","title":"2\ub2e8\uacc4: API \ud0a4 \uc0dd\uc131","text":"<pre><code>1. \ub85c\uadf8\uc778 \ud6c4 \uc6b0\uce21 \uc0c1\ub2e8 \ud504\ub85c\ud544 \ud074\ub9ad\n2. \"API keys\" \uc120\ud0dd\n3. \"Create new secret key\" \ud074\ub9ad\n4. \ud0a4 \uc774\ub984 \uc785\ub825 (\uc608: \"my-first-key\")\n5. \"Create secret key\" \ud074\ub9ad\n</code></pre>"},{"location":"examples/00-before-you-start/api-keys-explained/#3-api","title":"3\ub2e8\uacc4: API \ud0a4 \uc800\uc7a5","text":"<pre><code>\u26a0\ufe0f \uc911\uc694: API \ud0a4\ub294 \ud55c \ubc88\ub9cc \ubcf4\uc5ec\uc9d1\ub2c8\ub2e4!\n1. \uc0dd\uc131\ub41c \ud0a4\ub97c \ubcf5\uc0ac (sk-\ub85c \uc2dc\uc791\ud558\ub294 \uae34 \ubb38\uc790\uc5f4)\n2. \uc548\uc804\ud55c \uacf3\uc5d0 \uc800\uc7a5\n3. \"Done\" \ud074\ub9ad\n</code></pre>"},{"location":"examples/00-before-you-start/api-keys-explained/#api_4","title":"\ud83d\udd12 API \ud0a4 \uc548\uc804\ud558\uac8c \ubcf4\uad00\ud558\uae30","text":""},{"location":"examples/00-before-you-start/api-keys-explained/#_2","title":"\u274c \ud558\uba74 \uc548 \ub418\ub294 \uac83\ub4e4","text":"<pre><code># \uc808\ub300 \uc774\ub807\uac8c \ud558\uc9c0 \ub9c8\uc138\uc694!\napi_key = \"sk-abc123...\"  # \ucf54\ub4dc\uc5d0 \uc9c1\uc811 \uc4f0\uae30 \u274c\n</code></pre>"},{"location":"examples/00-before-you-start/api-keys-explained/#_3","title":"\u2705 \uc62c\ubc14\ub978 \ubc29\ubc95\ub4e4","text":""},{"location":"examples/00-before-you-start/api-keys-explained/#1_1","title":"\ubc29\ubc95 1: \ud658\uacbd \ubcc0\uc218 \uc0ac\uc6a9 (\ucd94\ucc9c!)","text":"<pre><code>import os\n\n# \ud658\uacbd \ubcc0\uc218\uc5d0\uc11c API \ud0a4 \uac00\uc838\uc624\uae30\napi_key = os.environ.get(\"OPENAI_API_KEY\")\n\n# \uc0ac\uc6a9\ud558\uae30\nfrom pyhub.llm import LLM\nassistant = LLM.create(\"gpt-4o-mini\", api_key=api_key)\n</code></pre>"},{"location":"examples/00-before-you-start/api-keys-explained/#2-env","title":"\ubc29\ubc95 2: .env \ud30c\uc77c \uc0ac\uc6a9","text":"<ol> <li> <p><code>.env</code> \ud30c\uc77c \ub9cc\ub4e4\uae30: <pre><code># .env \ud30c\uc77c \ub0b4\uc6a9\nOPENAI_API_KEY=sk-abc123...\n</code></pre></p> </li> <li> <p>Python\uc5d0\uc11c \uc0ac\uc6a9: <pre><code>from pyhub.llm import LLM\n\n# pyhub-llm\uc774 \uc790\ub3d9\uc73c\ub85c .env \ud30c\uc77c\uc744 \uc77d\uc2b5\ub2c8\ub2e4\nassistant = LLM.create(\"gpt-4o-mini\")\n</code></pre></p> </li> <li> <p><code>.gitignore</code>\uc5d0 \ucd94\uac00 (\uc911\uc694!): <pre><code>.env\n</code></pre></p> </li> </ol>"},{"location":"examples/00-before-you-start/api-keys-explained/#_4","title":"\ud83d\udcb0 \ube44\uc6a9 \uc774\ud574\ud558\uae30","text":""},{"location":"examples/00-before-you-start/api-keys-explained/#_5","title":"\ud1a0\ud070\uc774\ub780?","text":"<ul> <li>\ud1a0\ud070: AI\uac00 \uc774\ud574\ud558\ub294 \ud14d\uc2a4\ud2b8\uc758 \ub2e8\uc704</li> <li>\ud55c\uae00: 1\uae00\uc790 \u2248 2-3\ud1a0\ud070</li> <li>\uc601\uc5b4: 1\ub2e8\uc5b4 \u2248 1-2\ud1a0\ud070</li> </ul>"},{"location":"examples/00-before-you-start/api-keys-explained/#_6","title":"\uc608\uc0c1 \ube44\uc6a9","text":"<pre><code>\"\uc548\ub155\ud558\uc138\uc694\" = \uc57d 5\ud1a0\ud070\n\"Hello\" = \uc57d 1\ud1a0\ud070\n\n1,000\ud1a0\ud070 = \uc57d 2\uc6d0\n\u2192 \"\uc548\ub155\ud558\uc138\uc694\" 200\ubc88 = \uc57d 2\uc6d0\n</code></pre>"},{"location":"examples/00-before-you-start/api-keys-explained/#_7","title":"\ube44\uc6a9 \uc808\uc57d \ud301","text":"<ol> <li>\uc9e7\uace0 \uba85\ud655\ud55c \uc9c8\ubb38 \uc0ac\uc6a9</li> <li>\uce90\uc2f1 \ud65c\uc6a9 (\uac19\uc740 \uc9c8\ubb38 \ubc18\ubcf5 \uc548 \ud568)</li> <li>\uc800\ub834\ud55c \ubaa8\ub378 \uc0ac\uc6a9 (gpt-4o-mini)</li> </ol>"},{"location":"examples/00-before-you-start/api-keys-explained/#api_5","title":"\ud83d\udea6 \uccab API \ud0a4 \uc124\uc815\ud558\uae30","text":""},{"location":"examples/00-before-you-start/api-keys-explained/#windows","title":"Windows (\uba85\ub839 \ud504\ub86c\ud504\ud2b8)","text":"<pre><code>set OPENAI_API_KEY=sk-abc123...\n</code></pre>"},{"location":"examples/00-before-you-start/api-keys-explained/#maclinux","title":"Mac/Linux (\ud130\ubbf8\ub110)","text":"<pre><code>export OPENAI_API_KEY=sk-abc123...\n</code></pre>"},{"location":"examples/00-before-you-start/api-keys-explained/#maclinux_1","title":"\uc601\uad6c \uc124\uc815 (Mac/Linux)","text":"<pre><code>echo 'export OPENAI_API_KEY=sk-abc123...' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"examples/00-before-you-start/api-keys-explained/#api_6","title":"\u2705 API \ud0a4 \uc124\uc815 \ud655\uc778","text":"<pre><code>import os\n\n# API \ud0a4\uac00 \uc124\uc815\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\napi_key = os.environ.get(\"OPENAI_API_KEY\")\n\nif api_key:\n    print(\"\u2705 API \ud0a4\uac00 \uc124\uc815\ub418\uc5c8\uc2b5\ub2c8\ub2e4!\")\n    print(f\"\ud0a4 \uc2dc\uc791 \ubd80\ubd84: {api_key[:7]}...\")\nelse:\n    print(\"\u274c API \ud0a4\uac00 \uc124\uc815\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n</code></pre>"},{"location":"examples/00-before-you-start/api-keys-explained/#_8","title":"\ud83c\udd98 \ubb38\uc81c \ud574\uacb0","text":""},{"location":"examples/00-before-you-start/api-keys-explained/#api_7","title":"\"API \ud0a4\uac00 \uc720\ud6a8\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4\"","text":"<ul> <li>API \ud0a4\ub97c \ub2e4\uc2dc \ud655\uc778\ud558\uc138\uc694</li> <li>\ubcf5\uc0ac\ud560 \ub54c \uacf5\ubc31\uc774 \ud3ec\ud568\ub418\uc9c0 \uc54a\uc558\ub294\uc9c0 \ud655\uc778</li> </ul>"},{"location":"examples/00-before-you-start/api-keys-explained/#_9","title":"\"\ud06c\ub808\ub527\uc774 \ubd80\uc871\ud569\ub2c8\ub2e4\"","text":"<ul> <li>OpenAI \ub300\uc2dc\ubcf4\ub4dc\uc5d0\uc11c \uc794\uc561 \ud655\uc778</li> <li>\uacb0\uc81c \uc218\ub2e8 \ub4f1\ub85d \ud544\uc694</li> </ul>"},{"location":"examples/00-before-you-start/api-keys-explained/#api_8","title":"\"API \ud0a4\ub97c \ucc3e\uc744 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4\"","text":"<ul> <li>\ud658\uacbd \ubcc0\uc218 \uc774\ub984 \ud655\uc778 (OPENAI_API_KEY)</li> <li>\ud130\ubbf8\ub110\uc744 \uc7ac\uc2dc\uc791\ud574\ubcf4\uc138\uc694</li> </ul>"},{"location":"examples/00-before-you-start/api-keys-explained/#_10","title":"\ud83c\udfaf \ub2e4\uc74c \ub2e8\uacc4","text":"<p>API \ud0a4 \uc900\ube44\uac00 \ub05d\ub0ac\ub2e4\uba74, \ub4dc\ub514\uc5b4 \uccab AI \ub300\ud654\ub97c \uc2dc\uc791\ud574\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/00-before-you-start/python-basics/","title":"\ud83d\udc0d Python \uae30\ucd08 \ud655\uc778\ud558\uae30","text":"<p>AI \ud504\ub85c\uadf8\ub798\ubc0d\uc744 \uc2dc\uc791\ud558\uae30 \uc804\uc5d0 Python\uc774 \uc81c\ub300\ub85c \uc124\uce58\ub418\uc5b4 \uc788\ub294\uc9c0 \ud655\uc778\ud574\ubd05\uc2dc\ub2e4.</p>"},{"location":"examples/00-before-you-start/python-basics/#python_1","title":"\ud83d\udd0d Python \uc124\uce58 \ud655\uc778","text":""},{"location":"examples/00-before-you-start/python-basics/#1","title":"1. \ud130\ubbf8\ub110(\uba85\ub839 \ud504\ub86c\ud504\ud2b8) \uc5f4\uae30","text":"<ul> <li>Windows: Win + R \u2192 <code>cmd</code> \uc785\ub825</li> <li>Mac: Spotlight(Cmd + Space) \u2192 <code>Terminal</code> \uc785\ub825</li> <li>Linux: Ctrl + Alt + T</li> </ul>"},{"location":"examples/00-before-you-start/python-basics/#2-python","title":"2. Python \ubc84\uc804 \ud655\uc778","text":"<p><pre><code>python --version\n</code></pre> \ub610\ub294 <pre><code>python3 --version\n</code></pre></p>"},{"location":"examples/00-before-you-start/python-basics/#3","title":"3. \uacb0\uacfc \ud655\uc778","text":"<p><pre><code>Python 3.8.10\n</code></pre> **3.8 \uc774\uc0c1**\uc774\uba74 OK! \ud83d\udc4d</p>"},{"location":"examples/00-before-you-start/python-basics/#python_2","title":"\ud83d\udce5 Python\uc774 \uc5c6\ub2e4\uba74?","text":"<p>python.org\uc5d0\uc11c \ub2e4\uc6b4\ub85c\ub4dc\ud558\uc138\uc694.</p>"},{"location":"examples/00-before-you-start/python-basics/#_1","title":"\uc124\uce58 \uc2dc \uc8fc\uc758\uc0ac\ud56d","text":"<ul> <li>\u2705 \"Add Python to PATH\" \uccb4\ud06c\ud558\uae30</li> <li>\u2705 pip \ud3ec\ud568 \uc124\uce58 \uc120\ud0dd\ud558\uae30</li> </ul>"},{"location":"examples/00-before-you-start/python-basics/#pip","title":"\ud83e\uddf0 pip \ud655\uc778\ud558\uae30","text":"<p>pip\ub294 Python \ud328\ud0a4\uc9c0\ub97c \uc124\uce58\ud558\ub294 \ub3c4\uad6c\uc785\ub2c8\ub2e4.</p> <p><pre><code>pip --version\n</code></pre> \ub610\ub294 <pre><code>pip3 --version\n</code></pre></p> <p>\uacb0\uacfc: <pre><code>pip 21.0.1 from ... (python 3.8)\n</code></pre></p>"},{"location":"examples/00-before-you-start/python-basics/#python_3","title":"\ud83d\udcdd \uaf2d \uc54c\uc544\uc57c \ud560 Python \uae30\ucd08","text":""},{"location":"examples/00-before-you-start/python-basics/#1_1","title":"1. \ubcc0\uc218\uc640 \ucd9c\ub825","text":"<pre><code># \ubcc0\uc218\uc5d0 \uac12 \uc800\uc7a5\ud558\uae30\nname = \"\uae40\ucca0\uc218\"\nage = 25\n\n# \ucd9c\ub825\ud558\uae30\nprint(f\"\uc548\ub155\ud558\uc138\uc694, {name}\ub2d8! \ub098\uc774\ub294 {age}\uc0b4\uc774\uc2dc\ub124\uc694.\")\n</code></pre>"},{"location":"examples/00-before-you-start/python-basics/#2","title":"2. \ud568\uc218 \ub9cc\ub4e4\uae30","text":"<pre><code># \ud568\uc218 \uc815\uc758\ndef greet(name):\n    \"\"\"\uc778\uc0ac\ud558\ub294 \ud568\uc218\"\"\"\n    return f\"\uc548\ub155\ud558\uc138\uc694, {name}\ub2d8!\"\n\n# \ud568\uc218 \uc0ac\uc6a9\nmessage = greet(\"\uc601\ud76c\")\nprint(message)  # \ucd9c\ub825: \uc548\ub155\ud558\uc138\uc694, \uc601\ud76c\ub2d8!\n</code></pre>"},{"location":"examples/00-before-you-start/python-basics/#3_1","title":"3. \uc870\uac74\ubb38","text":"<pre><code>age = 20\n\nif age &gt;= 20:\n    print(\"\uc131\uc778\uc785\ub2c8\ub2e4\")\nelse:\n    print(\"\ubbf8\uc131\ub144\uc790\uc785\ub2c8\ub2e4\")\n</code></pre>"},{"location":"examples/00-before-you-start/python-basics/#4","title":"4. \ubc18\ubcf5\ubb38","text":"<pre><code># \ub9ac\uc2a4\ud2b8 \ub9cc\ub4e4\uae30\nfruits = [\"\uc0ac\uacfc\", \"\ubc14\ub098\ub098\", \"\uc624\ub80c\uc9c0\"]\n\n# \ubc18\ubcf5\ud558\uae30\nfor fruit in fruits:\n    print(f\"\ub098\ub294 {fruit}\ub97c \uc88b\uc544\ud574\uc694\")\n</code></pre>"},{"location":"examples/00-before-you-start/python-basics/#5","title":"5. \ub515\uc154\ub108\ub9ac (\uc911\uc694!)","text":"<pre><code># \ub515\uc154\ub108\ub9ac\ub294 \ud0a4-\uac12 \uc30d\uc73c\ub85c \ub370\uc774\ud130\ub97c \uc800\uc7a5\ud569\ub2c8\ub2e4\nperson = {\n    \"name\": \"\uae40\ucca0\uc218\",\n    \"age\": 25,\n    \"city\": \"\uc11c\uc6b8\"\n}\n\n# \uac12 \uac00\uc838\uc624\uae30\nprint(person[\"name\"])  # \ucd9c\ub825: \uae40\ucca0\uc218\n\n# \uac12 \ubc14\uafb8\uae30\nperson[\"age\"] = 26\n</code></pre>"},{"location":"examples/00-before-you-start/python-basics/#6","title":"6. \uc608\uc678 \ucc98\ub9ac","text":"<pre><code>try:\n    # \ubb54\uac00 \uc2dc\ub3c4\n    number = int(\"abc\")  # \uc5d0\ub7ec \ubc1c\uc0dd!\nexcept ValueError:\n    # \uc5d0\ub7ec\uac00 \ubc1c\uc0dd\ud558\uba74 \uc5ec\uae30 \uc2e4\ud589\n    print(\"\uc22b\uc790\uac00 \uc544\ub2c8\uc5d0\uc694!\")\n</code></pre>"},{"location":"examples/00-before-you-start/python-basics/#_2","title":"\ud83c\udfae \uc5f0\uc2b5 \ubb38\uc81c","text":"<p>\ub2e4\uc74c \ucf54\ub4dc\ub97c \uc774\ud574\ud560 \uc218 \uc788\ub2e4\uba74 \uc900\ube44 \uc644\ub8cc!</p> <pre><code># AI \ub3c4\uc6b0\ubbf8\uc5d0\uac8c \ubb3c\uc5b4\ubcfc \uc9c8\ubb38\ub4e4\nquestions = [\n    \"\uc624\ub298 \ub0a0\uc528 \uc5b4\ub54c?\",\n    \"\ud30c\uc774\uc36c\uc774 \ubb50\uc57c?\",\n    \"\uc810\uc2ec \uba54\ub274 \ucd94\ucc9c\ud574\uc918\"\n]\n\n# \uac01 \uc9c8\ubb38\uc744 \ucd9c\ub825\ud558\uae30\nfor i, question in enumerate(questions, 1):\n    print(f\"{i}. {question}\")\n\n# \uc0ac\uc6a9\uc790 \uc120\ud0dd \ubc1b\uae30\ntry:\n    choice = int(input(\"\uba87 \ubc88 \uc9c8\ubb38\uc744 \uc120\ud0dd\ud558\uc2dc\uaca0\uc5b4\uc694? \"))\n    if 1 &lt;= choice &lt;= len(questions):\n        selected = questions[choice - 1]\n        print(f\"\uc120\ud0dd\ud55c \uc9c8\ubb38: {selected}\")\n    else:\n        print(\"\uc798\ubabb\ub41c \ubc88\ud638\uc785\ub2c8\ub2e4!\")\nexcept ValueError:\n    print(\"\uc22b\uc790\ub97c \uc785\ub825\ud574\uc8fc\uc138\uc694!\")\n</code></pre>"},{"location":"examples/00-before-you-start/python-basics/#_3","title":"\u2705 \uccb4\ud06c\ud3ec\uc778\ud2b8","text":"<p>\ub2e4\uc74c\uc744 \ud560 \uc218 \uc788\ub2e4\uba74 \ub2e4\uc74c \ub2e8\uacc4\ub85c \uc9c4\ud589\ud558\uc138\uc694: - [ ] Python \uc2e4\ud589 \uac00\ub2a5 - [ ] pip\ub85c \ud328\ud0a4\uc9c0 \uc124\uce58 \uac00\ub2a5 - [ ] \uc704\uc758 \uc608\uc81c \ucf54\ub4dc \uc774\ud574 \uac00\ub2a5</p>"},{"location":"examples/00-before-you-start/python-basics/#_4","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>Python \uc900\ube44\uac00 \ub05d\ub0ac\ub2e4\uba74 API \ud0a4 \uc54c\uc544\ubcf4\uae30\ub85c \uc774\ub3d9\ud558\uc138\uc694!</p>"},{"location":"examples/01-hello-llm/","title":"\ud83c\udf89 \uccab AI \ub300\ud654 \uc2dc\uc791\ud558\uae30","text":"<p>\ub4dc\ub514\uc5b4 AI\uc640 \ub300\ud654\ud560 \uc2dc\uac04\uc785\ub2c8\ub2e4! \uc774 \uc139\uc158\uc5d0\uc11c\ub294 \uac00\uc7a5 \uae30\ubcf8\uc801\uc778 \uac83\ubd80\ud130 \ucc28\uadfc\ucc28\uadfc \ubc30\uc6cc\ubd05\uc2dc\ub2e4.</p>"},{"location":"examples/01-hello-llm/#_1","title":"\ud83c\udfaf \uc774 \uc139\uc158\uc5d0\uc11c \ubc30\uc6b8 \ub0b4\uc6a9","text":"<ul> <li>\u2705 AI\uac00 \ubb34\uc5c7\uc778\uc9c0 \uc27d\uac8c \uc774\ud574\ud558\uae30</li> <li>\u2705 \uccab \ubc88\uc9f8 AI \ud504\ub85c\uadf8\ub7a8 \ub9cc\ub4e4\uae30</li> <li>\u2705 AI\uc758 \uc751\ub2f5 \uc774\ud574\ud558\uae30</li> <li>\u2705 \ub2e4\uc591\ud55c \uc9c8\ubb38 \ud574\ubcf4\uae30</li> </ul>"},{"location":"examples/01-hello-llm/#_2","title":"\ud83d\udcda \uc139\uc158 \uad6c\uc131","text":""},{"location":"examples/01-hello-llm/#1-ai","title":"1. AI\ub780 \ubb34\uc5c7\uc778\uac00\uc694?","text":"<ul> <li>AI\ub97c 5\uc0b4 \uc544\uc774\ub3c4 \uc774\ud574\ud560 \uc218 \uc788\uac8c \uc124\uba85</li> <li>\uc6b0\ub9ac\uac00 \uc0ac\uc6a9\ud560 AI \ubaa8\ub378 \uc18c\uac1c</li> <li>AI\uac00 \ud560 \uc218 \uc788\ub294 \uc77c\uacfc \ubabb\ud558\ub294 \uc77c</li> </ul>"},{"location":"examples/01-hello-llm/#2","title":"2. \uccab \ubc88\uc9f8 \ub300\ud654","text":"<ul> <li>Hello World \uc608\uc81c</li> <li>\ucf54\ub4dc \ud55c \uc904\uc529 \uc124\uba85</li> <li>\uc2e4\ud589 \uacb0\uacfc \ud655\uc778</li> </ul>"},{"location":"examples/01-hello-llm/#3","title":"3. \uc751\ub2f5 \uc774\ud574\ud558\uae30","text":"<ul> <li>AI\uac00 \uc8fc\ub294 \ub2f5\ubcc0\uc758 \uad6c\uc870</li> <li>\ud1a0\ud070\uacfc \ube44\uc6a9 \uc774\ud574\ud558\uae30</li> <li>\uc88b\uc740 \uc9c8\ubb38\ud558\ub294 \ubc29\ubc95</li> </ul>"},{"location":"examples/01-hello-llm/#_3","title":"\ud83d\udca1 \ucd08\ubcf4\uc790\ub97c \uc704\ud55c \ud301","text":"<p>\uac71\uc815\ud558\uc9c0 \ub9c8\uc138\uc694!  - \ucc98\uc74c\uc5d4 \ub204\uad6c\ub098 \uc5b4\ub835\uc2b5\ub2c8\ub2e4 - \uc5d0\ub7ec\uac00 \ub098\ub3c4 \uad1c\ucc2e\uc544\uc694 - \ucc9c\ucc9c\ud788 \ub530\ub77c\ud558\uba74 \ub429\ub2c8\ub2e4</p>"},{"location":"examples/01-hello-llm/#_4","title":"\ud83d\ude80 \uc2dc\uc791\ud558\uae30 \uc804 \uccb4\ud06c\ub9ac\uc2a4\ud2b8","text":"<ul> <li> Python \uc124\uce58 \uc644\ub8cc</li> <li> API \ud0a4 \uc900\ube44 \uc644\ub8cc</li> <li> \ud130\ubbf8\ub110 \uc0ac\uc6a9\ubc95 \uc54c\uae30</li> <li> \uc124\ub808\ub294 \ub9c8\uc74c \uc900\ube44! \ud83d\ude0a</li> </ul>"},{"location":"examples/01-hello-llm/#_5","title":"\ud83d\udcdd \uc774 \uc139\uc158\uc758 \ubaa9\ud45c","text":"<p>\uc774 \uc139\uc158\uc744 \ub05d\ub0b4\uba74 \ub2e4\uc74c\uacfc \uac19\uc740 \ucf54\ub4dc\ub97c \uc774\ud574\ud558\uace0 \uc791\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code># AI\uc640 \ub300\ud654\ud558\ub294 \ud504\ub85c\uadf8\ub7a8\nfrom pyhub.llm import LLM\n\n# AI \ub3c4\uc6b0\ubbf8 \ub9cc\ub4e4\uae30\nai_helper = LLM.create(\"gpt-4o-mini\")\n\n# \uc9c8\ubb38\ud558\uace0 \ub2f5\ubcc0 \ubc1b\uae30\nanswer = ai_helper.ask(\"\ud30c\uc774\uc36c\uc740 \uc65c \uc774\ub984\uc774 \ud30c\uc774\uc36c\uc778\uac00\uc694?\")\nprint(answer.text)\n</code></pre>"},{"location":"examples/01-hello-llm/#_6","title":"\ud83c\udfae \uc900\ube44\ub418\uc168\ub098\uc694?","text":"<p>AI\ub780 \ubb34\uc5c7\uc778\uac00\uc694?\ubd80\ud130 \uc2dc\uc791\ud574\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/01-hello-llm/first-chat/","title":"\ud83c\udf88 \uccab \ubc88\uc9f8 AI \ub300\ud654 - Hello World!","text":"<p>\ub4dc\ub514\uc5b4 AI\uc640 \uccab \ub300\ud654\ub97c \ub098\ub20c \uc2dc\uac04\uc785\ub2c8\ub2e4! \ucc28\uadfc\ucc28\uadfc \ub530\ub77c\ud574\ubcf4\uc138\uc694.</p>"},{"location":"examples/01-hello-llm/first-chat/#_1","title":"\ud83c\udfaf \uc774\ubc88\uc5d0 \ub9cc\ub4e4 \uac83","text":"<pre><code>\ub098: \uc548\ub155! \ub098\ub294 \ud30c\uc774\uc36c\uc744 \ubc30\uc6b0\ub294 \ud559\uc0dd\uc774\uc57c.\nAI: \uc548\ub155\ud558\uc138\uc694! \ud30c\uc774\uc36c\uc744 \ubc30\uc6b0\uace0 \uacc4\uc2dc\ub294\uad70\uc694. \uc815\ub9d0 \uc88b\uc740 \uc120\ud0dd\uc774\uc2ed\ub2c8\ub2e4...\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#step-1-pyhub-llm","title":"\ud83d\udce6 Step 1: pyhub-llm \uc124\uce58\ud558\uae30","text":"<p>\ud130\ubbf8\ub110\uc744 \uc5f4\uace0 \ub2e4\uc74c \uba85\ub839\uc5b4\ub97c \uc785\ub825\ud558\uc138\uc694:</p> <pre><code># OpenAI \uc0ac\uc6a9\ud558\ub824\uba74\npip install \"pyhub-llm[openai]\"\n\n# \ub610\ub294 \ubaa8\ub4e0 AI \uc81c\uacf5\uc790 \uc124\uce58\npip install \"pyhub-llm[all]\"\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#_2","title":"\uc124\uce58 \ud655\uc778","text":"<pre><code># Python \uc2e4\ud589\npython\n\n# \uc124\uce58 \ud655\uc778\nimport pyhub.llm\nprint(\"\uc124\uce58 \uc131\uacf5! \ud83c\udf89\")\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#step-2-api","title":"\ud83d\udd11 Step 2: API \ud0a4 \uc124\uc815\ud558\uae30","text":""},{"location":"examples/01-hello-llm/first-chat/#1","title":"\ubc29\ubc95 1: \ud658\uacbd \ubcc0\uc218\ub85c \uc124\uc815 (\ucd94\ucc9c)","text":"<pre><code># Mac/Linux\nexport OPENAI_API_KEY=\"sk-...\"\n\n# Windows\nset OPENAI_API_KEY=sk-...\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#2-env","title":"\ubc29\ubc95 2: .env \ud30c\uc77c \ub9cc\ub4e4\uae30","text":"<ol> <li>\ud504\ub85c\uc81d\ud2b8 \ud3f4\ub354\uc5d0 <code>.env</code> \ud30c\uc77c \uc0dd\uc131</li> <li>\ub2e4\uc74c \ub0b4\uc6a9 \uc785\ub825: <pre><code>OPENAI_API_KEY=sk-...\n</code></pre></li> </ol>"},{"location":"examples/01-hello-llm/first-chat/#step-3","title":"\ud83d\udcac Step 3: \uccab \ubc88\uc9f8 \ucf54\ub4dc \uc791\uc131\ud558\uae30","text":"<p><code>my_first_ai.py</code> \ud30c\uc77c\uc744 \ub9cc\ub4e4\uace0 \ub2e4\uc74c \ucf54\ub4dc\ub97c \uc785\ub825\ud558\uc138\uc694:</p> <pre><code># AI\uc640 \ub300\ud654\ud558\ub294 \uccab \ubc88\uc9f8 \ud504\ub85c\uadf8\ub7a8\n# \ud30c\uc77c\uba85: my_first_ai.py\n\n# 1. \ud544\uc694\ud55c \ub3c4\uad6c \uac00\uc838\uc624\uae30\nfrom pyhub.llm import LLM\n\n# 2. AI \ub3c4\uc6b0\ubbf8 \ub9cc\ub4e4\uae30\nprint(\"AI \ub3c4\uc6b0\ubbf8\ub97c \uc900\ube44\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4...\")\nai = LLM.create(\"gpt-4o-mini\")  # GPT-4 \ubbf8\ub2c8 \ubaa8\ub378 \uc0ac\uc6a9\n\n# 3. AI\uc5d0\uac8c \uc778\uc0ac\ud558\uae30\nprint(\"AI\uc5d0\uac8c \uc9c8\ubb38\ud558\ub294 \uc911...\")\nresponse = ai.ask(\"\uc548\ub155! \ub098\ub294 \ud30c\uc774\uc36c\uc744 \ubc30\uc6b0\ub294 \ud559\uc0dd\uc774\uc57c.\")\n\n# 4. AI\uc758 \ub2f5\ubcc0 \ucd9c\ub825\ud558\uae30\nprint(\"\\n\ud83e\udd16 AI\uc758 \ub2f5\ubcc0:\")\nprint(response.text)\n\n# 5. \uc0ac\uc6a9\ud55c \ud1a0\ud070\uacfc \ube44\uc6a9 \ud655\uc778\nprint(f\"\\n\ud83d\udcca \uc0ac\uc6a9 \uc815\ubcf4:\")\nprint(f\"- \uc0ac\uc6a9\ud55c \ud1a0\ud070: {response.usage.total_tokens}\uac1c\")\nprint(f\"- \uc608\uc0c1 \ube44\uc6a9: \uc57d {response.usage.total_tokens * 0.002:.2f}\uc6d0\")\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#step-4","title":"\ud83c\udfc3 Step 4: \uc2e4\ud589\ud558\uae30","text":"<pre><code>python my_first_ai.py\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#_3","title":"\uc608\uc0c1 \uacb0\uacfc","text":"<pre><code>AI \ub3c4\uc6b0\ubbf8\ub97c \uc900\ube44\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4...\nAI\uc5d0\uac8c \uc9c8\ubb38\ud558\ub294 \uc911...\n\n\ud83e\udd16 AI\uc758 \ub2f5\ubcc0:\n\uc548\ub155\ud558\uc138\uc694! \ud30c\uc774\uc36c\uc744 \ubc30\uc6b0\uace0 \uacc4\uc2dc\ub294\uad70\uc694. \uc815\ub9d0 \uc88b\uc740 \uc120\ud0dd\uc774\uc2ed\ub2c8\ub2e4! \n\ud30c\uc774\uc36c\uc740 \ubc30\uc6b0\uae30 \uc27d\uace0 \uac15\ub825\ud55c \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\uc608\uc694. \n\uad81\uae08\ud55c \uc810\uc774 \uc788\uc73c\uba74 \uc5b8\uc81c\ub4e0\uc9c0 \ubb3c\uc5b4\ubcf4\uc138\uc694. \ud568\uaed8 \uacf5\ubd80\ud574\uc694! \ud83d\ude0a\n\n\ud83d\udcca \uc0ac\uc6a9 \uc815\ubcf4:\n- \uc0ac\uc6a9\ud55c \ud1a0\ud070: 95\uac1c\n- \uc608\uc0c1 \ube44\uc6a9: \uc57d 0.19\uc6d0\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#_4","title":"\ud83d\udd0d \ucf54\ub4dc \ud55c \uc904\uc529 \uc774\ud574\ud558\uae30","text":""},{"location":"examples/01-hello-llm/first-chat/#1_1","title":"1. \ub3c4\uad6c \uac00\uc838\uc624\uae30","text":"<p><pre><code>from pyhub.llm import LLM\n</code></pre> - <code>pyhub.llm</code>: \uc6b0\ub9ac\uac00 \uc124\uce58\ud55c \ud328\ud0a4\uc9c0 - <code>LLM</code>: AI\uc640 \ub300\ud654\ud558\ub294 \ub3c4\uad6c</p>"},{"location":"examples/01-hello-llm/first-chat/#2-ai","title":"2. AI \ub9cc\ub4e4\uae30","text":"<p><pre><code>ai = LLM.create(\"gpt-4o-mini\")\n</code></pre> - <code>LLM.create()</code>: AI \ub3c4\uc6b0\ubbf8\ub97c \ub9cc\ub4dc\ub294 \ud568\uc218 - <code>\"gpt-4o-mini\"</code>: \uc0ac\uc6a9\ud560 AI \ubaa8\ub378 \uc774\ub984 - <code>ai</code>: \ub9cc\ub4e0 AI\ub97c \uc800\uc7a5\ud560 \ubcc0\uc218</p>"},{"location":"examples/01-hello-llm/first-chat/#3","title":"3. \uc9c8\ubb38\ud558\uae30","text":"<p><pre><code>response = ai.ask(\"\uc548\ub155! \ub098\ub294 \ud30c\uc774\uc36c\uc744 \ubc30\uc6b0\ub294 \ud559\uc0dd\uc774\uc57c.\")\n</code></pre> - <code>ai.ask()</code>: AI\uc5d0\uac8c \uc9c8\ubb38\ud558\ub294 \ud568\uc218 - <code>response</code>: AI\uc758 \ub2f5\ubcc0\uc744 \uc800\uc7a5\ud560 \ubcc0\uc218</p>"},{"location":"examples/01-hello-llm/first-chat/#4","title":"4. \ub2f5\ubcc0 \ucd9c\ub825","text":"<p><pre><code>print(response.text)\n</code></pre> - <code>response.text</code>: AI\uac00 \ub2f5\ud55c \ud14d\uc2a4\ud2b8 - <code>print()</code>: \ud654\uba74\uc5d0 \ucd9c\ub825</p>"},{"location":"examples/01-hello-llm/first-chat/#_5","title":"\ud83c\udfae \uc5f0\uc2b5\ud574\ubcf4\uae30","text":""},{"location":"examples/01-hello-llm/first-chat/#1_2","title":"\uc5f0\uc2b5 1: \ub2e4\ub978 \uc9c8\ubb38\ud574\ubcf4\uae30","text":"<pre><code># \ub2e4\uc591\ud55c \uc9c8\ubb38 \uc2dc\ub3c4\nquestions = [\n    \"\uc624\ub298 \uc810\uc2ec \uba54\ub274 \ucd94\ucc9c\ud574\uc918\",\n    \"\ud30c\uc774\uc36c\uc73c\ub85c \ubb58 \ub9cc\ub4e4 \uc218 \uc788\uc5b4?\",\n    \"1\ubd80\ud130 10\uae4c\uc9c0 \ub354\ud558\uba74 \uc5bc\ub9c8\uc57c?\"\n]\n\nfor question in questions:\n    response = ai.ask(question)\n    print(f\"Q: {question}\")\n    print(f\"A: {response.text}\\n\")\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#2","title":"\uc5f0\uc2b5 2: \ub300\ud654 \uc774\uc5b4\uac00\uae30","text":"<pre><code># \uc5f0\uc18d \ub300\ud654\nresponse1 = ai.ask(\"\ub0b4 \uc774\ub984\uc740 \ucca0\uc218\uc57c\")\nprint(\"AI:\", response1.text)\n\nresponse2 = ai.ask(\"\ub0b4 \uc774\ub984\uc774 \ubb50\ub77c\uace0 \ud588\uc9c0?\")\nprint(\"AI:\", response2.text)  # AI\ub294 \uae30\uc5b5\ud558\uc9c0 \ubabb\ud569\ub2c8\ub2e4!\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#3_1","title":"\uc5f0\uc2b5 3: \ub2e4\ub978 \ubaa8\ub378 \uc0ac\uc6a9\ud574\ubcf4\uae30","text":"<pre><code># \ub2e4\ub978 \ubaa8\ub378\ub4e4 \uc2dc\ub3c4\nmodels = [\"gpt-4o-mini\", \"gpt-3.5-turbo\"]\n\nfor model_name in models:\n    ai = LLM.create(model_name)\n    response = ai.ask(\"\ub108\ub294 \uc5b4\ub5a4 AI\uc57c?\")\n    print(f\"{model_name}: {response.text[:50]}...\")\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#_6","title":"\ud83d\udea8 \uc790\uc8fc \ubc1c\uc0dd\ud558\ub294 \uc624\ub958\uc640 \ud574\uacb0\ubc95","text":""},{"location":"examples/01-hello-llm/first-chat/#1-api-key-not-found","title":"1. \"API key not found\"","text":"<pre><code># \ud574\uacb0\ubc95: API \ud0a4 \uc9c1\uc811 \uc804\ub2ec\nai = LLM.create(\"gpt-4o-mini\", api_key=\"sk-...\")\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#2-rate-limit-exceeded","title":"2. \"Rate limit exceeded\"","text":"<pre><code># \ud574\uacb0\ubc95: \uc7a0\uc2dc \uae30\ub2e4\ub9ac\uae30\nimport time\ntime.sleep(1)  # 1\ucd08 \ub300\uae30\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#3-model-not-found","title":"3. \"Model not found\"","text":"<pre><code># \ud574\uacb0\ubc95: \uc62c\ubc14\ub978 \ubaa8\ub378\uba85 \uc0ac\uc6a9\n# \u274c ai = LLM.create(\"gpt-4-mini\")\n# \u2705 ai = LLM.create(\"gpt-4o-mini\")\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#_7","title":"\ud83d\udca1 \ud301\uacfc \ud2b8\ub9ad","text":""},{"location":"examples/01-hello-llm/first-chat/#1_3","title":"1. \uae34 \ub2f5\ubcc0 \ubc1b\uae30","text":"<pre><code>response = ai.ask(\n    \"\ud30c\uc774\uc36c\uc758 \uc7a5\uc810\uc744 5\uac00\uc9c0 \uc54c\ub824\uc918\",\n    max_tokens=500  # \ub354 \uae34 \ub2f5\ubcc0 \ud5c8\uc6a9\n)\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#2_1","title":"2. \uac04\ub2e8\ud55c \ub2f5\ubcc0 \ubc1b\uae30","text":"<pre><code>response = ai.ask(\n    \"1+1\uc740?\",\n    system=\"\uc9e7\uace0 \uac04\ub2e8\ud558\uac8c \ub2f5\ud574\uc8fc\uc138\uc694.\"\n)\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#3_2","title":"3. \ub2f5\ubcc0 \ud615\uc2dd \uc9c0\uc815\ud558\uae30","text":"<pre><code>response = ai.ask(\n    \"\uc88b\uc544\ud558\ub294 \uacfc\uc77c 3\uac1c\ub97c \uc54c\ub824\uc918\",\n    system=\"\ubc88\ud638\ub97c \ub9e4\uaca8\uc11c \ub2f5\ud574\uc8fc\uc138\uc694.\"\n)\n</code></pre>"},{"location":"examples/01-hello-llm/first-chat/#_8","title":"\u2705 \ubc30\uc6b4 \ub0b4\uc6a9 \uc815\ub9ac","text":"<p>\uc774\uc81c \uc5ec\ub7ec\ubd84\uc740: - \u2705 pyhub-llm \uc124\uce58\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4 - \u2705 AI \ub3c4\uc6b0\ubbf8\ub97c \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4 - \u2705 \uc9c8\ubb38\ud558\uace0 \ub2f5\ubcc0\ubc1b\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4 - \u2705 \ud1a0\ud070\uacfc \ube44\uc6a9\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4</p>"},{"location":"examples/01-hello-llm/first-chat/#_9","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>\uae30\ubcf8\uc801\uc778 \ub300\ud654\ub97c \uc131\uacf5\ud588\ub2e4\uba74, \uc751\ub2f5 \uc774\ud574\ud558\uae30\ub85c \ub118\uc5b4\uac00\uc11c AI\uc758 \ub2f5\ubcc0\uc744 \ub354 \uae4a\uc774 \uc774\ud574\ud574\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/01-hello-llm/understanding-responses/","title":"\ud83d\udd0d AI \uc751\ub2f5 \uc774\ud574\ud558\uae30","text":"<p>AI\uac00 \uc8fc\ub294 \ub2f5\ubcc0\uc5d0\ub294 \ud14d\uc2a4\ud2b8 \uc678\uc5d0\ub3c4 \ub9ce\uc740 \uc815\ubcf4\uac00 \ub2f4\uaca8\uc788\uc2b5\ub2c8\ub2e4. \uc790\uc138\ud788 \uc54c\uc544\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/01-hello-llm/understanding-responses/#_1","title":"\ud83d\udce6 \uc751\ub2f5 \uac1d\uccb4\uc758 \uad6c\uc870","text":"<p>AI\uc758 \uc751\ub2f5\uc740 \ub2e8\uc21c\ud55c \ud14d\uc2a4\ud2b8\uac00 \uc544\ub2c8\ub77c \uc5ec\ub7ec \uc815\ubcf4\ub97c \ub2f4\uc740 \"\uc0c1\uc790\"\uc785\ub2c8\ub2e4.</p> <pre><code>from pyhub.llm import LLM\n\n# AI\uc5d0\uac8c \uc9c8\ubb38\nai = LLM.create(\"gpt-4o-mini\")\nresponse = ai.ask(\"\uc548\ub155\ud558\uc138\uc694!\")\n\n# response \uc548\uc5d0\ub294 \ubb50\uac00 \uc788\uc744\uae4c?\nprint(type(response))  # &lt;class 'CompletionResponse'&gt;\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#_2","title":"\uc751\ub2f5\uc5d0 \ud3ec\ud568\ub41c \uc815\ubcf4\ub4e4","text":"<pre><code># 1. \ub2f5\ubcc0 \ud14d\uc2a4\ud2b8\nprint(\"\ub2f5\ubcc0:\", response.text)\n\n# 2. \uc0ac\uc6a9\ub7c9 \uc815\ubcf4\nprint(\"\uc785\ub825 \ud1a0\ud070:\", response.usage.prompt_tokens)\nprint(\"\ucd9c\ub825 \ud1a0\ud070:\", response.usage.completion_tokens)\nprint(\"\ucd1d \ud1a0\ud070:\", response.usage.total_tokens)\n\n# 3. \ubaa8\ub378 \uc815\ubcf4\nprint(\"\uc0ac\uc6a9\ud55c \ubaa8\ub378:\", response.model)\n\n# 4. \uc6d0\ubcf8 \uc751\ub2f5 (\uace0\uae09)\nprint(\"\uc6d0\ubcf8 \ub370\uc774\ud130:\", response.raw)\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#_3","title":"\ud83d\udcb0 \ud1a0\ud070\uacfc \ube44\uc6a9 \uc774\ud574\ud558\uae30","text":""},{"location":"examples/01-hello-llm/understanding-responses/#_4","title":"\ud1a0\ud070\uc774\ub780?","text":"<p>\ud1a0\ud070\uc740 AI\uac00 \ud14d\uc2a4\ud2b8\ub97c \uc774\ud574\ud558\ub294 \ub2e8\uc704\uc785\ub2c8\ub2e4.</p> <pre><code># \ud1a0\ud070 \uc608\uc2dc \uc2dc\uac01\ud654\nexamples = [\n    \"\uc548\ub155\",        # \uc57d 2\ud1a0\ud070\n    \"Hello\",       # \uc57d 1\ud1a0\ud070\n    \"\uc548\ub155\ud558\uc138\uc694\",   # \uc57d 5\ud1a0\ud070\n    \"I love you\",  # \uc57d 3\ud1a0\ud070\n]\n\nfor text in examples:\n    response = ai.ask(f\"'{text}'\ub294 \uba87 \uae00\uc790\uc57c?\")\n    print(f\"'{text}' = {response.usage.prompt_tokens}\ud1a0\ud070\")\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#_5","title":"\ud1a0\ud070 \uacc4\uc0b0 \uaddc\uce59","text":"<ul> <li>\ud55c\uae00: 1\uae00\uc790 \u2248 2-3\ud1a0\ud070</li> <li>\uc601\uc5b4: 1\ub2e8\uc5b4 \u2248 1-2\ud1a0\ud070</li> <li>\uc22b\uc790: 1\uc790\ub9ac \u2248 1\ud1a0\ud070</li> <li>\ud2b9\uc218\ubb38\uc790: 1\uac1c \u2248 1\ud1a0\ud070</li> </ul>"},{"location":"examples/01-hello-llm/understanding-responses/#_6","title":"\ube44\uc6a9 \uacc4\uc0b0\ud558\uae30","text":"<pre><code>def calculate_cost(response, model=\"gpt-4o-mini\"):\n    \"\"\"\uc751\ub2f5\uc758 \uc608\uc0c1 \ube44\uc6a9\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4\"\"\"\n\n    # \ubaa8\ub378\ubcc4 1,000\ud1a0\ud070\ub2f9 \uac00\uaca9 (\uc6d0\ud654 \uae30\uc900)\n    prices = {\n        \"gpt-4o-mini\": {\n            \"input\": 0.2,    # \uc785\ub825 1,000\ud1a0\ud070\ub2f9 0.2\uc6d0\n            \"output\": 0.8    # \ucd9c\ub825 1,000\ud1a0\ud070\ub2f9 0.8\uc6d0\n        },\n        \"gpt-4o\": {\n            \"input\": 5,      # \uc785\ub825 1,000\ud1a0\ud070\ub2f9 5\uc6d0\n            \"output\": 15     # \ucd9c\ub825 1,000\ud1a0\ud070\ub2f9 15\uc6d0\n        }\n    }\n\n    price = prices.get(model, prices[\"gpt-4o-mini\"])\n\n    # \ube44\uc6a9 \uacc4\uc0b0\n    input_cost = (response.usage.prompt_tokens / 1000) * price[\"input\"]\n    output_cost = (response.usage.completion_tokens / 1000) * price[\"output\"]\n    total_cost = input_cost + output_cost\n\n    return {\n        \"input_cost\": input_cost,\n        \"output_cost\": output_cost,\n        \"total_cost\": total_cost\n    }\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nresponse = ai.ask(\"\ud30c\uc774\uc36c\uc73c\ub85c \uacc4\uc0b0\uae30 \ub9cc\ub4dc\ub294 \ubc95 \uc54c\ub824\uc918\")\ncost = calculate_cost(response)\n\nprint(f\"\ud83d\udcb0 \ube44\uc6a9 \ubd84\uc11d:\")\nprint(f\"- \uc9c8\ubb38 \ube44\uc6a9: {cost['input_cost']:.3f}\uc6d0\")\nprint(f\"- \ub2f5\ubcc0 \ube44\uc6a9: {cost['output_cost']:.3f}\uc6d0\")\nprint(f\"- \ucd1d \ube44\uc6a9: {cost['total_cost']:.3f}\uc6d0\")\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#_7","title":"\ud83c\udfaf \uc88b\uc740 \uc9c8\ubb38\ud558\ub294 \ubc29\ubc95","text":""},{"location":"examples/01-hello-llm/understanding-responses/#1","title":"1. \uba85\ud655\ud558\uace0 \uad6c\uccb4\uc801\uc73c\ub85c","text":"<pre><code># \u274c \ub098\uc05c \uc608\nresponse = ai.ask(\"\ucf54\ub4dc \uc368\uc918\")\n\n# \u2705 \uc88b\uc740 \uc608\nresponse = ai.ask(\"\"\"\nPython\uc73c\ub85c \uac04\ub2e8\ud55c \uacc4\uc0b0\uae30\ub97c \ub9cc\ub4e4\uc5b4\uc918.\n- \ub354\ud558\uae30, \ube7c\uae30, \uacf1\ud558\uae30, \ub098\ub204\uae30 \uae30\ub2a5\n- \uc0ac\uc6a9\uc790 \uc785\ub825 \ubc1b\uae30\n- \uc5d0\ub7ec \ucc98\ub9ac \ud3ec\ud568\n\"\"\")\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#2","title":"2. \ub9e5\ub77d \uc81c\uacf5\ud558\uae30","text":"<pre><code># \u274c \ub098\uc05c \uc608\nresponse = ai.ask(\"\uc774\uac70 \uace0\uccd0\uc918\")\n\n# \u2705 \uc88b\uc740 \uc608\nresponse = ai.ask(\"\"\"\n\ub2e4\uc74c Python \ucf54\ub4dc\uc5d0\uc11c ZeroDivisionError\uac00 \ubc1c\uc0dd\ud569\ub2c8\ub2e4.\n\uc5b4\ub5bb\uac8c \uace0\uce60 \uc218 \uc788\uc744\uae4c\uc694?\n\ndef divide(a, b):\n    return a / b\n\nresult = divide(10, 0)\n\"\"\")\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#3","title":"3. \uc6d0\ud558\ub294 \ud615\uc2dd \uc9c0\uc815\ud558\uae30","text":"<pre><code># \ub2f5\ubcc0 \ud615\uc2dd\uc744 \uc9c0\uc815\ud558\uba74 \ub354 \uc720\uc6a9\ud55c \ub2f5\ubcc0\uc744 \ubc1b\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4\nresponse = ai.ask(\"\"\"\n\ud55c\uad6d\uc758 \uc8fc\uc694 \ub3c4\uc2dc 5\uac1c\ub97c \uc54c\ub824\uc918.\n\ub2e4\uc74c \ud615\uc2dd\uc73c\ub85c \ub2f5\ud574\uc918:\n1. \ub3c4\uc2dc\uba85 - \uc778\uad6c\uc218 - \ud2b9\uc9d5\n\"\"\")\n\nprint(response.text)\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#_8","title":"\ud83d\udcca \uc751\ub2f5 \ud488\uc9c8 \uac1c\uc120\ud558\uae30","text":""},{"location":"examples/01-hello-llm/understanding-responses/#1_1","title":"1. \uc2dc\uc2a4\ud15c \ud504\ub86c\ud504\ud2b8 \ud65c\uc6a9","text":"<pre><code># AI\uc5d0\uac8c \uc5ed\ud560 \ubd80\uc5ec\ud558\uae30\nresponse = ai.ask(\n    \"for \ub8e8\ud504 \uc124\uba85\ud574\uc918\",\n    system=\"\ub2f9\uc2e0\uc740 \ucd08\ub4f1\ud559\uc0dd\ub3c4 \uc774\ud574\ud560 \uc218 \uc788\uac8c \uc124\uba85\ud558\ub294 \uce5c\uc808\ud55c \uc120\uc0dd\ub2d8\uc785\ub2c8\ub2e4.\"\n)\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#2-temperature","title":"2. \uc628\ub3c4(Temperature) \uc870\uc808","text":"<pre><code># \uc628\ub3c4: 0 = \uc77c\uad00\ub41c \ub2f5\ubcc0, 1 = \ucc3d\uc758\uc801\uc778 \ub2f5\ubcc0\n\n# \uc0ac\uc2e4\uc801\uc778 \uc815\ubcf4 (\ub0ae\uc740 \uc628\ub3c4)\nresponse = ai.ask(\n    \"\ud55c\uad6d\uc758 \uc218\ub3c4\ub294?\",\n    temperature=0.1\n)\n\n# \ucc3d\uc758\uc801\uc778 \ub2f5\ubcc0 (\ub192\uc740 \uc628\ub3c4)\nresponse = ai.ask(\n    \"\uc678\uacc4\uc778\uc774 \uc9c0\uad6c\uc5d0 \uc628\ub2e4\uba74 \uc5b4\ub5a4 \uc77c\uc774 \uc77c\uc5b4\ub0a0\uae4c?\",\n    temperature=0.9\n)\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#3_1","title":"3. \ucd5c\ub300 \ud1a0\ud070 \uc124\uc815","text":"<pre><code># \uc9e7\uc740 \ub2f5\ubcc0\nresponse = ai.ask(\n    \"\uc778\uacf5\uc9c0\ub2a5\uc774 \ubb50\uc57c?\",\n    max_tokens=50  # \uc57d 20-30 \uae00\uc790\n)\n\n# \uae34 \ub2f5\ubcc0\nresponse = ai.ask(\n    \"\uc778\uacf5\uc9c0\ub2a5\uc758 \uc5ed\uc0ac\ub97c \uc790\uc138\ud788 \uc124\uba85\ud574\uc918\",\n    max_tokens=1000  # \uc57d 400-500 \uae00\uc790\n)\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#_9","title":"\ud83d\udd27 \ub514\ubc84\uae45\uacfc \ubb38\uc81c \ud574\uacb0","text":""},{"location":"examples/01-hello-llm/understanding-responses/#_10","title":"\uc751\ub2f5 \uc0c1\ud0dc \ud655\uc778\ud558\uae30","text":"<pre><code>def analyze_response(response):\n    \"\"\"\uc751\ub2f5\uc744 \ubd84\uc11d\ud558\uace0 \ubb38\uc81c\ub97c \uc9c4\ub2e8\ud569\ub2c8\ub2e4\"\"\"\n\n    print(\"\ud83d\udd0d \uc751\ub2f5 \ubd84\uc11d:\")\n    print(f\"- \ubaa8\ub378: {response.model}\")\n    print(f\"- \ub2f5\ubcc0 \uae38\uc774: {len(response.text)}\uc790\")\n    print(f\"- \ud1a0\ud070 \uc0ac\uc6a9\ub7c9: {response.usage.total_tokens}\")\n\n    # \ube44\uc6a9 \uacc4\uc0b0\n    cost = response.usage.total_tokens * 0.002\n    print(f\"- \uc608\uc0c1 \ube44\uc6a9: {cost:.2f}\uc6d0\")\n\n    # \ub2f5\ubcc0 \ud488\uc9c8 \uccb4\ud06c\n    if len(response.text) &lt; 10:\n        print(\"\u26a0\ufe0f \ub2f5\ubcc0\uc774 \ub108\ubb34 \uc9e7\uc2b5\ub2c8\ub2e4. \uc9c8\ubb38\uc744 \ub354 \uad6c\uccb4\uc801\uc73c\ub85c \ud574\ubcf4\uc138\uc694.\")\n\n    if response.usage.total_tokens &gt; 1000:\n        print(\"\u26a0\ufe0f \ud1a0\ud070\uc744 \ub9ce\uc774 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4. \uc9c8\ubb38\uc744 \uac04\ub2e8\ud558\uac8c \ud574\ubcf4\uc138\uc694.\")\n\n    return response\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nresponse = ai.ask(\"\uc548\ub155\")\nanalyze_response(response)\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#_11","title":"\ud83d\udcdd \uc2e4\uc804 \uc608\uc81c: \uc2a4\ub9c8\ud2b8 \uc9c8\ubb38 \ub3c4\uc6b0\ubbf8","text":"<pre><code>class SmartAI:\n    \"\"\"\ub611\ub611\ud558\uac8c \uc9c8\ubb38\ud558\uace0 \ube44\uc6a9\uc744 \uad00\ub9ac\ud558\ub294 AI \ub3c4\uc6b0\ubbf8\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.ai = LLM.create(model)\n        self.total_cost = 0\n        self.history = []\n\n    def ask(self, question, save_money=True):\n        \"\"\"\uc9c8\ubb38\ud558\uace0 \ube44\uc6a9\uc744 \ucd94\uc801\ud569\ub2c8\ub2e4\"\"\"\n\n        # \ube44\uc6a9 \uc808\uc57d \ubaa8\ub4dc\n        if save_money:\n            # \uc9e7\uc740 \ub2f5\ubcc0 \uc694\uccad\n            full_question = f\"{question}\\n(\ud55c \ubb38\ub2e8\uc73c\ub85c \uac04\ub2e8\ud788 \ub2f5\ud574\uc8fc\uc138\uc694)\"\n            response = self.ai.ask(full_question, max_tokens=200)\n        else:\n            response = self.ai.ask(question)\n\n        # \ube44\uc6a9 \uacc4\uc0b0\n        cost = response.usage.total_tokens * 0.002\n        self.total_cost += cost\n\n        # \uae30\ub85d \uc800\uc7a5\n        self.history.append({\n            \"question\": question,\n            \"answer\": response.text,\n            \"tokens\": response.usage.total_tokens,\n            \"cost\": cost\n        })\n\n        return response\n\n    def show_summary(self):\n        \"\"\"\uc0ac\uc6a9 \uc694\uc57d\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4\"\"\"\n        print(\"\\n\ud83d\udcca \uc0ac\uc6a9 \uc694\uc57d:\")\n        print(f\"- \ucd1d \uc9c8\ubb38 \uc218: {len(self.history)}\")\n        print(f\"- \ucd1d \ube44\uc6a9: {self.total_cost:.2f}\uc6d0\")\n        print(f\"- \ud3c9\uade0 \ube44\uc6a9: {self.total_cost/len(self.history):.2f}\uc6d0\")\n\n        # \uac00\uc7a5 \ube44\uc2fc \uc9c8\ubb38\n        expensive = max(self.history, key=lambda x: x['cost'])\n        print(f\"\\n\ud83d\udcb8 \uac00\uc7a5 \ube44\uc2fc \uc9c8\ubb38: {expensive['cost']:.2f}\uc6d0\")\n        print(f\"   '{expensive['question'][:30]}...'\")\n\n# \uc0ac\uc6a9\ud574\ubcf4\uae30\nsmart_ai = SmartAI()\n\n# \uc5ec\ub7ec \uc9c8\ubb38\ud558\uae30\nquestions = [\n    \"\ud30c\uc774\uc36c\uc774 \ubb50\uc57c?\",\n    \"\ub9ac\uc2a4\ud2b8\uc640 \ud29c\ud50c\uc758 \ucc28\uc774\uc810\uc740?\",\n    \"\uc6f9 \uc2a4\ud06c\ub798\ud551\ud558\ub294 \ubc29\ubc95 \uc54c\ub824\uc918\"\n]\n\nfor q in questions:\n    response = smart_ai.ask(q)\n    print(f\"\\nQ: {q}\")\n    print(f\"A: {response.text[:100]}...\")\n\n# \uc694\uc57d \ubcf4\uae30\nsmart_ai.show_summary()\n</code></pre>"},{"location":"examples/01-hello-llm/understanding-responses/#_12","title":"\u2705 \ud575\uc2ec \uc815\ub9ac","text":"<ol> <li>**\uc751\ub2f5 \uac1d\uccb4**\ub294 \ud14d\uc2a4\ud2b8 \uc678\uc5d0\ub3c4 \ub9ce\uc740 \uc815\ubcf4 \ud3ec\ud568</li> <li>**\ud1a0\ud070**\uc740 AI\uac00 \ud14d\uc2a4\ud2b8\ub97c \ucc98\ub9ac\ud558\ub294 \ub2e8\uc704</li> <li>**\uc88b\uc740 \uc9c8\ubb38**\uc774 \uc88b\uc740 \ub2f5\ubcc0\uc744 \ub9cc\ub4ed\ub2c8\ub2e4</li> <li>**\ube44\uc6a9 \uad00\ub9ac**\ub294 \ucc98\uc74c\ubd80\ud130 \uc2b5\uad00\ud654\ud558\uc138\uc694</li> </ol>"},{"location":"examples/01-hello-llm/understanding-responses/#_13","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>\uc774\uc81c AI \uc751\ub2f5\uc744 \uc644\ubcbd\ud788 \uc774\ud574\ud588\uc73c\ub2c8, \uc77c\uc0c1 \uc791\uc5c5 \uc790\ub3d9\ud654\ub85c \ub118\uc5b4\uac00\uc11c \uc2e4\uc6a9\uc801\uc778 \uc608\uc81c\ub4e4\uc744 \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/01-hello-llm/what-is-llm/","title":"\ud83e\udd16 AI\ub780 \ubb34\uc5c7\uc778\uac00\uc694?","text":"<p>AI\ub97c \ucc98\uc74c \uc811\ud558\uc2dc\ub294 \ubd84\ub4e4\uc744 \uc704\ud574 \uc27d\uac8c \uc124\uba85\ud574\ub4dc\ub9b4\uac8c\uc694!</p>"},{"location":"examples/01-hello-llm/what-is-llm/#_1","title":"\ud83c\udfad \uc26c\uc6b4 \ube44\uc720\ub85c \uc774\ud574\ud558\uae30","text":""},{"location":"examples/01-hello-llm/what-is-llm/#ai_1","title":"AI\ub294 \"\ub611\ub611\ud55c \ube44\uc11c\"\uc785\ub2c8\ub2e4","text":"<p>\uc0c1\uc0c1\ud574\ubcf4\uc138\uc694: - \uc77c\ubc18 \uacc4\uc0b0\uae30: 2+2=? \u2192 4 (\uc815\ud574\uc9c4 \uacc4\uc0b0\ub9cc) - AI \ube44\uc11c: \"\uc624\ub298 \ubb50 \uba39\uc744\uae4c?\" \u2192 \"\ub0a0\uc528\uac00 \ucd94\uc6b0\ub2c8 \ub530\ub73b\ud55c \uad6d\ubb3c \uc694\ub9ac\ub294 \uc5b4\ub5a0\uc138\uc694?\" (\uc0c1\ud669\uc5d0 \ub9de\ub294 \uc81c\uc548)</p>"},{"location":"examples/01-hello-llm/what-is-llm/#_2","title":"\uc2e4\uc0dd\ud65c \uc608\uc2dc","text":"<ul> <li>\ubc88\uc5ed\uac00: \ud55c\uad6d\uc5b4 \u2194 \uc601\uc5b4 \ubc88\uc5ed</li> <li>\uc791\uac00: \uc774\uba54\uc77c, \ud3b8\uc9c0, \uc774\uc57c\uae30 \uc791\uc131</li> <li>\uc120\uc0dd\ub2d8: \ubaa8\ub974\ub294 \uac83 \uc124\uba85</li> <li>\uc694\ub9ac\uc0ac: \ub808\uc2dc\ud53c \ucd94\ucc9c</li> <li>\uce5c\uad6c: \uace0\ubbfc \uc0c1\ub2f4</li> </ul>"},{"location":"examples/01-hello-llm/what-is-llm/#ai_2","title":"\ud83e\udde0 AI\ub294 \uc5b4\ub5bb\uac8c \ub611\ub611\ud574\uc84c\ub098\uc694?","text":""},{"location":"examples/01-hello-llm/what-is-llm/#_3","title":"\ud559\uc2b5 \uacfc\uc815 (\uc0ac\ub78c\uacfc \ube44\uc2b7!)","text":"<ol> <li>\ub9ce\uc774 \uc77d\uae30: \uc218\ubc31\ub9cc \uad8c\uc758 \ucc45, \uc6f9\uc0ac\uc774\ud2b8 \uc77d\uc74c</li> <li>\ud328\ud134 \ucc3e\uae30: \"\uc548\ub155\"\ub2e4\uc74c\uc5d4 \ubcf4\ud1b5 \"\ud558\uc138\uc694\"\uac00 \uc628\ub2e4</li> <li>\uc5f0\uc2b5\ud558\uae30: \uc218\ub9ce\uc740 \uc9c8\ubb38\uacfc \ub2f5\ubcc0 \uc5f0\uc2b5</li> <li>\ud53c\ub4dc\ubc31: \uc88b\uc740 \ub2f5\ubcc0\uacfc \ub098\uc05c \ub2f5\ubcc0 \uad6c\ubd84 \ud559\uc2b5</li> </ol>"},{"location":"examples/01-hello-llm/what-is-llm/#ai_3","title":"\ud83d\udcca \uc6b0\ub9ac\uac00 \uc0ac\uc6a9\ud560 AI \ubaa8\ub378\ub4e4","text":""},{"location":"examples/01-hello-llm/what-is-llm/#1-gpt-4-openai","title":"1. GPT-4 (OpenAI)","text":"<ul> <li>\ud2b9\uc9d5: \uac00\uc7a5 \ub611\ub611\ud558\uc9c0\ub9cc \ube44\uc308</li> <li>\uc798\ud558\ub294 \uac83: \ubcf5\uc7a1\ud55c \ubb38\uc81c \ud574\uacb0, \ucc3d\uc758\uc801 \uae00\uc4f0\uae30</li> <li>\ube44\uc720: \ub300\ud559 \uad50\uc218\ub2d8</li> </ul>"},{"location":"examples/01-hello-llm/what-is-llm/#2-gpt-4o-mini-openai","title":"2. GPT-4o-mini (OpenAI)","text":"<ul> <li>\ud2b9\uc9d5: \ube60\ub974\uace0 \uc800\ub834\ud568</li> <li>\uc798\ud558\ub294 \uac83: \uc77c\uc0c1\uc801\uc778 \ub300\ud654, \uac04\ub2e8\ud55c \uc791\uc5c5</li> <li>\ube44\uc720: \ub611\ub611\ud55c \ub300\ud559\uc0dd</li> <li>\ucd94\ucc9c: \ucd08\ubcf4\uc790\uc5d0\uac8c \ucd5c\uace0! \ud83d\udc4d</li> </ul>"},{"location":"examples/01-hello-llm/what-is-llm/#3-claude-anthropic","title":"3. Claude (Anthropic)","text":"<ul> <li>\ud2b9\uc9d5: \uc548\uc804\ud558\uace0 \uc815\uc9c1\ud568</li> <li>\uc798\ud558\ub294 \uac83: \uae34 \ubb38\uc11c \ubd84\uc11d, \ucf54\ub4dc \uc791\uc131</li> <li>\ube44\uc720: \uc2e0\uc911\ud55c \uc804\ubb38\uac00</li> </ul>"},{"location":"examples/01-hello-llm/what-is-llm/#4-llama-ollama","title":"4. Llama (Ollama\ub85c \uc2e4\ud589)","text":"<ul> <li>\ud2b9\uc9d5: \ubb34\ub8cc! \ub0b4 \ucef4\ud4e8\ud130\uc5d0\uc11c \uc2e4\ud589</li> <li>\uc798\ud558\ub294 \uac83: \uae30\ubcf8\uc801\uc778 \ub300\ud654</li> <li>\ube44\uc720: \uc9d1\uc5d0\uc11c \ud0a4\uc6b0\ub294 \ub611\ub611\ud55c \uac15\uc544\uc9c0</li> </ul>"},{"location":"examples/01-hello-llm/what-is-llm/#ai_4","title":"\u2705 AI\uac00 \uc798\ud558\ub294 \uc77c","text":""},{"location":"examples/01-hello-llm/what-is-llm/#1","title":"1. \uae00\uc4f0\uae30\uc640 \ud3b8\uc9d1","text":"<pre><code># \uc608\uc2dc: \uc774\uba54\uc77c \uc791\uc131\n\"\uad50\uc218\ub2d8\uaed8 \uacfc\uc81c \uc81c\ucd9c\uc774 \ub2a6\uc5b4\uc9c4 \uac83\uc5d0 \ub300\ud55c \uc0ac\uacfc \uc774\uba54\uc77c\uc744 \uc368\uc918\"\n</code></pre>"},{"location":"examples/01-hello-llm/what-is-llm/#2","title":"2. \ubc88\uc5ed","text":"<pre><code># \uc608\uc2dc: \ub2e4\uad6d\uc5b4 \ubc88\uc5ed\n\"'\uc0ac\ub791\ud574'\ub97c 10\uac1c \uc5b8\uc5b4\ub85c \ubc88\uc5ed\ud574\uc918\"\n</code></pre>"},{"location":"examples/01-hello-llm/what-is-llm/#3","title":"3. \uc124\uba85\uacfc \uad50\uc721","text":"<pre><code># \uc608\uc2dc: \ubcf5\uc7a1\ud55c \uac1c\ub150 \uc124\uba85\n\"\uad11\ud569\uc131\uc744 \ucd08\ub4f1\ud559\uc0dd\ub3c4 \uc774\ud574\ud560 \uc218 \uc788\uac8c \uc124\uba85\ud574\uc918\"\n</code></pre>"},{"location":"examples/01-hello-llm/what-is-llm/#4","title":"4. \ucf54\ub4dc \uc791\uc131","text":"<pre><code># \uc608\uc2dc: \ud504\ub85c\uadf8\ub798\ubc0d \ub3c4\uc6c0\n\"Python\uc73c\ub85c \uad6c\uad6c\ub2e8 \ucd9c\ub825\ud558\ub294 \ucf54\ub4dc \ub9cc\ub4e4\uc5b4\uc918\"\n</code></pre>"},{"location":"examples/01-hello-llm/what-is-llm/#5","title":"5. \ucc3d\uc758\uc801 \uc791\uc5c5","text":"<pre><code># \uc608\uc2dc: \uc544\uc774\ub514\uc5b4 \uc0dd\uc131\n\"\uae40\uce58\ub97c \ud65c\uc6a9\ud55c \uc0c8\ub85c\uc6b4 \uc694\ub9ac \uc544\uc774\ub514\uc5b4 5\uac1c \uc81c\uc548\ud574\uc918\"\n</code></pre>"},{"location":"examples/01-hello-llm/what-is-llm/#ai_5","title":"\u274c AI\uac00 \ubabb\ud558\ub294 \uc77c","text":""},{"location":"examples/01-hello-llm/what-is-llm/#1_1","title":"1. \uc2e4\uc2dc\uac04 \uc815\ubcf4","text":"<ul> <li>\u274c \"\uc9c0\uae08 \ub0a0\uc528 \uc5b4\ub54c?\" (\uc778\ud130\ub137 \uac80\uc0c9 \ubd88\uac00)</li> <li>\u274c \"\uc624\ub298 \uc8fc\uc2dd \uc2dc\uc138\ub294?\" (\uc2e4\uc2dc\uac04 \ub370\uc774\ud130 \uc5c6\uc74c)</li> </ul>"},{"location":"examples/01-hello-llm/what-is-llm/#2_1","title":"2. \uac1c\uc778\uc815\ubcf4","text":"<ul> <li>\u274c \"\ub0b4 \uc774\ub984\uc774 \ubb50\uc57c?\" (\ub2f9\uc2e0\uc744 \ubaa8\ub984)</li> <li>\u274c \"\uc5b4\uc81c \ub0b4\uac00 \ubb50\ud588\uc9c0?\" (\uae30\uc5b5 \uc5c6\uc74c)</li> </ul>"},{"location":"examples/01-hello-llm/what-is-llm/#3_1","title":"3. \ubb3c\ub9ac\uc801 \ud589\ub3d9","text":"<ul> <li>\u274c \"\ucee4\ud53c \ud55c \uc794 \ud0c0\uc918\" (\ub85c\ubd07\uc774 \uc544\ub2d8)</li> <li>\u274c \"\ub0b4 \ubc29 \uccad\uc18c\ud574\uc918\" (\ubb3c\ub9ac\uc801 \uc791\uc5c5 \ubd88\uac00)</li> </ul>"},{"location":"examples/01-hello-llm/what-is-llm/#4-100","title":"4. 100% \uc815\ud655\ud55c \uc815\ubcf4","text":"<ul> <li>\u26a0\ufe0f \uac00\ub054 \ud2c0\ub9b4 \uc218 \uc788\uc74c</li> <li>\u26a0\ufe0f \uc911\uc694\ud55c \uc815\ubcf4\ub294 \ubc18\ub4dc\uc2dc \ud655\uc778</li> </ul>"},{"location":"examples/01-hello-llm/what-is-llm/#ai_6","title":"\ud83c\udfaf AI \uc120\ud0dd \uac00\uc774\ub4dc","text":""},{"location":"examples/01-hello-llm/what-is-llm/#_4","title":"\ucc98\uc74c \uc2dc\uc791\ud55c\ub2e4\uba74?","text":"<pre><code>1. Ollama (\ubb34\ub8cc) \u2192 \uc5f0\uc2b5\uc6a9\n2. GPT-4o-mini \u2192 \uc2e4\uc804\uc6a9 (\ucd94\ucc9c!)\n3. GPT-4 \u2192 \ubcf5\uc7a1\ud55c \uc791\uc5c5\uc6a9\n</code></pre>"},{"location":"examples/01-hello-llm/what-is-llm/#_5","title":"\uc6a9\ub3c4\ubcc4 \ucd94\ucc9c","text":"<ul> <li>\uacf5\ubd80/\ud559\uc2b5: GPT-4o-mini</li> <li>\ucf54\ub4dc \uc791\uc131: Claude</li> <li>\ucc3d\uc758\uc801 \uae00\uc4f0\uae30: GPT-4</li> <li>\ube44\uc6a9 \uc808\uc57d: Ollama</li> </ul>"},{"location":"examples/01-hello-llm/what-is-llm/#_6","title":"\ud83d\udcad \uc790\uc8fc \ubb3b\ub294 \uc9c8\ubb38","text":""},{"location":"examples/01-hello-llm/what-is-llm/#q-ai","title":"Q: AI\uac00 \ub098\ub97c \ub300\uccb4\ud560\uae4c\uc694?","text":"<p>A: \uc544\ub2c8\uc694! AI\ub294 \ub3c4\uad6c\uc785\ub2c8\ub2e4.  - \uacc4\uc0b0\uae30\uac00 \uc218\ud559\uc790\ub97c \ub300\uccb4\ud558\uc9c0 \uc54a\ub4ef\uc774 - AI\ub294 \uc6b0\ub9ac\ub97c \ub3d5\ub294 \ub3c4\uad6c\uc77c \ubfd0\uc785\ub2c8\ub2e4</p>"},{"location":"examples/01-hello-llm/what-is-llm/#q-ai_1","title":"Q: AI\ub97c \ubbff\uc5b4\ub3c4 \ub420\uae4c\uc694?","text":"<p>A: \ucc38\uace0\uc6a9\uc73c\ub85c\ub294 \uc88b\uc9c0\ub9cc, \uc911\uc694\ud55c \uac83\uc740 \ud655\uc778\ud558\uc138\uc694. - \u2705 \uc544\uc774\ub514\uc5b4 \uc5bb\uae30 - \u2705 \ucd08\uc548 \uc791\uc131 - \u26a0\ufe0f \ucd5c\uc885 \ud655\uc778\uc740 \uc0ac\ub78c\uc774</p>"},{"location":"examples/01-hello-llm/what-is-llm/#q-ai_2","title":"Q: AI\ub294 \uac10\uc815\uc774 \uc788\ub098\uc694?","text":"<p>A: \uc544\ub2c8\uc694. AI\ub294 \ud328\ud134\uc744 \ud559\uc2b5\ud55c \ud504\ub85c\uadf8\ub7a8\uc785\ub2c8\ub2e4. - \uacf5\uac10\ud558\ub294 \uac83\ucc98\ub7fc \ubcf4\uc774\uc9c0\ub9cc - \uc2e4\uc81c \uac10\uc815\uc740 \uc5c6\uc2b5\ub2c8\ub2e4</p>"},{"location":"examples/01-hello-llm/what-is-llm/#_7","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>\uc774\uc81c AI\uac00 \ubb34\uc5c7\uc778\uc9c0 \uc54c\uc558\uc73c\ub2c8, \uccab \ubc88\uc9f8 \ub300\ud654\ub97c \uc2dc\uc791\ud574\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/02-everyday-tasks/","title":"\ud83d\udee0\ufe0f \uc77c\uc0c1 \uc791\uc5c5 \uc790\ub3d9\ud654","text":"<p>AI\ub97c \ud65c\uc6a9\ud574\uc11c \ub9e4\uc77c \ubc18\ubcf5\ud558\ub294 \uc791\uc5c5\ub4e4\uc744 \uc790\ub3d9\ud654\ud574\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/02-everyday-tasks/#_2","title":"\ud83c\udfaf \uc774 \uc139\uc158\uc5d0\uc11c \ub9cc\ub4e4 \uac83\ub4e4","text":"<ul> <li>\ud83c\udf0d AI \ubc88\uc5ed\uae30 - \ub2e4\uad6d\uc5b4 \ubc88\uc5ed</li> <li>\ud83d\udcdd \ud14d\uc2a4\ud2b8 \uac1c\uc120 \ub3c4\uad6c - \ub9de\ucda4\ubc95\uacfc \ubb38\ubc95 \uac80\uc0ac</li> <li>\ud83d\uddde\ufe0f \ub611\ub611\ud55c \uc694\uc57d\uae30 - \uae34 \uae00\uc744 \uc9e7\uac8c</li> <li>\ud83d\udcac AI \ube44\uc11c - \uc77c\uc0c1\uc801\uc778 \uc9c8\ubb38 \ub2f5\ubcc0</li> </ul>"},{"location":"examples/02-everyday-tasks/#_3","title":"\ud83d\udcda \uc139\uc158 \uad6c\uc131","text":""},{"location":"examples/02-everyday-tasks/#1-ai","title":"1. AI \ube44\uc11c \ub9cc\ub4e4\uae30","text":"<ul> <li>\ub0a0\uc528, \uc2dc\uac04, \uacc4\uc0b0 \ub4f1 \uc77c\uc0c1 \uc9c8\ubb38 \ub2f5\ubcc0</li> <li>\uc720\uc6a9\ud55c \uc815\ubcf4 \uc81c\uacf5\ud558\uae30</li> <li>\uac1c\uc778 \ube44\uc11c\ucc98\ub7fc \ud65c\uc6a9\ud558\uae30</li> </ul>"},{"location":"examples/02-everyday-tasks/#2","title":"2. \ud14d\uc2a4\ud2b8 \uac1c\uc120 \ub3c4\uad6c","text":"<ul> <li>\ub9de\ucda4\ubc95\uacfc \ubb38\ubc95 \uac80\uc0ac</li> <li>\ubb38\uc7a5 \ub2e4\ub4ec\uae30</li> <li>\uae00\uc4f0\uae30 \uc2a4\ud0c0\uc77c \uac1c\uc120</li> </ul>"},{"location":"examples/02-everyday-tasks/#3","title":"3. \ub2e4\uad6d\uc5b4 \ubc88\uc5ed\uae30","text":"<ul> <li>\uc5ec\ub7ec \uc5b8\uc5b4\ub85c \ubc88\uc5ed\ud558\uae30</li> <li>\ubc88\uc5ed \ud488\uc9c8 \ub192\uc774\uae30</li> <li>\uc804\ubb38 \uc6a9\uc5b4 \ubc88\uc5ed\ud558\uae30</li> </ul>"},{"location":"examples/02-everyday-tasks/#4","title":"4. \ub611\ub611\ud55c \uc694\uc57d\uae30","text":"<ul> <li>\uae34 \uae00\uc744 \ud575\uc2ec\ub9cc \uc694\uc57d</li> <li>\ub274\uc2a4 \uae30\uc0ac \uc694\uc57d</li> <li>\ud68c\uc758\ub85d \uc815\ub9ac\ud558\uae30</li> </ul>"},{"location":"examples/02-everyday-tasks/#_4","title":"\ud83d\udca1 \uc774\ub7f0 \ubd84\ub4e4\uc5d0\uac8c \ucd94\ucc9c\ud574\uc694","text":"<ul> <li>\ud83d\udce7 \uc774\uba54\uc77c\uc744 \uc790\uc8fc \uc4f0\ub294 \uc9c1\uc7a5\uc778</li> <li>\ud83d\udcda \uacfc\uc81c\uc640 \ub808\ud3ec\ud2b8\ub97c \uc4f0\ub294 \ud559\uc0dd</li> <li>\ud83c\udf10 \uc678\uad6d\uc5b4 \uc790\ub8cc\ub97c \uc77d\ub294 \uc5f0\uad6c\uc6d0</li> <li>\ud83d\udcf0 \ub9ce\uc740 \uc815\ubcf4\ub97c \ube60\ub974\uac8c \ud30c\uc545\ud574\uc57c \ud558\ub294 \ubaa8\ub4e0 \ubd84</li> </ul>"},{"location":"examples/02-everyday-tasks/#_5","title":"\ud83d\ude80 \uc2dc\uc791\ud558\uae30 \uc804\uc5d0","text":"<p>\uac01 \ub3c4\uad6c\ub294 \ub3c5\ub9bd\uc801\uc73c\ub85c \uc791\ub3d9\ud558\ubbc0\ub85c \uc6d0\ud558\ub294 \uac83\ubd80\ud130 \uc2dc\uc791\ud558\uc138\uc694!</p> <pre><code># \uae30\ubcf8 \uc124\uc815 (\ubaa8\ub4e0 \uc608\uc81c\uc5d0\uc11c \uc0ac\uc6a9)\nfrom pyhub.llm import LLM\n\n# AI \ub3c4\uc6b0\ubbf8 \uc900\ube44\nai = LLM.create(\"gpt-4o-mini\")\n</code></pre>"},{"location":"examples/02-everyday-tasks/#_6","title":"\ud83d\udcca \uc608\uc0c1 \uc0ac\uc6a9 \ube44\uc6a9","text":"\uc791\uc5c5 \ud3c9\uade0 \ud1a0\ud070 \uc608\uc0c1 \ube44\uc6a9 \uc9e7\uc740 \ubc88\uc5ed 100-200 0.2-0.4\uc6d0 \ubb38\ubc95 \uac80\uc0ac 200-400 0.4-0.8\uc6d0 \uc694\uc57d\ud558\uae30 500-1000 1-2\uc6d0 \ub300\ud654\ud558\uae30 100-300 0.2-0.6\uc6d0"},{"location":"examples/02-everyday-tasks/#_7","title":"\ud83c\udf89 \uc644\uc131 \uc608\uc2dc","text":"<p>\uc774 \uc139\uc158\uc744 \ub05d\ub0b4\uba74 \uc774\ub7f0 \ud504\ub85c\uadf8\ub7a8\uc744 \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code># \ub2e4\uad6d\uc5b4 \uc778\uc0ac \uc0dd\uc131\uae30\ndef global_greeting(name):\n    prompt = f\"{name}\ub2d8\uc744 \uc704\ud55c \uc778\uc0ac\ub9d0\uc744 \ud55c\uad6d\uc5b4, \uc601\uc5b4, \uc77c\ubcf8\uc5b4, \uc911\uad6d\uc5b4\ub85c \ub9cc\ub4e4\uc5b4\uc918\"\n    response = ai.ask(prompt)\n    return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nprint(global_greeting(\"\uae40\ucca0\uc218\"))\n</code></pre> <p>\ucd9c\ub825: <pre><code>\ud83c\uddf0\ud83c\uddf7 \ud55c\uad6d\uc5b4: \uc548\ub155\ud558\uc138\uc694, \uae40\ucca0\uc218\ub2d8!\n\ud83c\uddfa\ud83c\uddf8 English: Hello, Mr. Kim Cheol-su!\n\ud83c\uddef\ud83c\uddf5 \u65e5\u672c\u8a9e: \u3053\u3093\u306b\u3061\u306f\u3001\u30ad\u30e0\u30fb\u30c1\u30e7\u30eb\u30b9\u3055\u3093\uff01\n\ud83c\udde8\ud83c\uddf3 \u4e2d\u6587: \u4f60\u597d\uff0c\u91d1\u54f2\u6d19\u5148\u751f\uff01\n</code></pre></p>"},{"location":"examples/02-everyday-tasks/#_8","title":"\ud83d\udd27 \uc900\ube44\ubb3c","text":"<ul> <li>\u2705 Python \uae30\ubcf8 \uc9c0\uc2dd</li> <li>\u2705 pyhub-llm \uc124\uce58 \uc644\ub8cc</li> <li>\u2705 API \ud0a4 \uc124\uc815 \uc644\ub8cc</li> <li>\u2705 \uc790\ub3d9\ud654\ud558\uace0 \uc2f6\uc740 \uc791\uc5c5 \ubaa9\ub85d</li> </ul>"},{"location":"examples/02-everyday-tasks/#_9","title":"\ud83c\udfaf \ud559\uc2b5 \ubaa9\ud45c","text":"<p>\uc774 \uc139\uc158\uc744 \ub9c8\uce58\uba74: - AI\ub97c \uc77c\uc0c1 \uc5c5\ubb34\uc5d0 \ud65c\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4 - \ubc18\ubcf5 \uc791\uc5c5\uc744 \uc790\ub3d9\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4 - \uc0dd\uc0b0\uc131\uc744 \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\uc2b5\ub2c8\ub2e4</p> <p>\uc900\ube44\ub418\uc168\ub098\uc694? AI \ube44\uc11c \ub9cc\ub4e4\uae30\ubd80\ud130 \uc2dc\uc791\ud574\ubd05\uc2dc\ub2e4! \ud83d\ude80</p>"},{"location":"examples/02-everyday-tasks/ai-assistant/","title":"\ud83e\udd16 AI \ube44\uc11c \ub9cc\ub4e4\uae30","text":"<p>\uc77c\uc0c1\uc0dd\ud65c\uc5d0\uc11c \uc790\uc8fc \ud558\ub294 \uc9c8\ubb38\ub4e4\uc5d0 \ub2f5\ud558\ub294 \ub611\ub611\ud55c AI \ube44\uc11c\ub97c \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/02-everyday-tasks/ai-assistant/#_1","title":"\ud83c\udfaf \ub9cc\ub4e4 \uac83","text":"<pre><code>\ub098: \uc624\ub298 \uc800\ub141 \uba54\ub274 \ucd94\ucc9c\ud574\uc918\nAI: \uc624\ub298\uac19\uc774 \uc300\uc300\ud55c \ub0a0\uc528\uc5d4 \ub530\ub73b\ud55c \uae40\uce58\ucc0c\uac1c\ub098 \ubd80\ub300\ucc0c\uac1c\ub294 \uc5b4\ub5a0\uc138\uc694?\n\n\ub098: 10\ub2ec\ub7ec\ub294 \ud55c\uad6d\ub3c8\uc73c\ub85c \uc5bc\ub9c8\uc57c?\nAI: \ud604\uc7ac \ud658\uc728 \uae30\uc900\uc73c\ub85c \uc57d 13,000\uc6d0\uc785\ub2c8\ub2e4.\n</code></pre>"},{"location":"examples/02-everyday-tasks/ai-assistant/#ai_1","title":"\ud83d\udcdd \uae30\ubcf8 AI \ube44\uc11c \ub9cc\ub4e4\uae30","text":""},{"location":"examples/02-everyday-tasks/ai-assistant/#step-1","title":"Step 1: \uac04\ub2e8\ud55c \ube44\uc11c \ud074\ub798\uc2a4","text":"<pre><code># ai_assistant.py\nfrom pyhub.llm import LLM\nfrom datetime import datetime\n\nclass AIAssistant:\n    \"\"\"\uc77c\uc0c1 \uc9c8\ubb38\uc5d0 \ub2f5\ud558\ub294 AI \ube44\uc11c\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\"):\n        # AI \ubaa8\ub378 \ucd08\uae30\ud654\n        self.ai = LLM.create(model)\n        self.name = \"\ub3c4\uc6b0\ubbf8\"  # \ube44\uc11c \uc774\ub984\n\n    def answer(self, question):\n        \"\"\"\uc9c8\ubb38\uc5d0 \ub2f5\ubcc0\ud569\ub2c8\ub2e4\"\"\"\n        # \ud604\uc7ac \uc2dc\uac04\uacfc \uc694\uc77c \uc815\ubcf4 \ucd94\uac00\n        current_time = datetime.now().strftime(\"%Y\ub144 %m\uc6d4 %d\uc77c %H\uc2dc %M\ubd84\")\n        weekday = [\"\uc6d4\", \"\ud654\", \"\uc218\", \"\ubaa9\", \"\uae08\", \"\ud1a0\", \"\uc77c\"][datetime.now().weekday()]\n\n        # \ucee8\ud14d\uc2a4\ud2b8\uc640 \ud568\uaed8 \uc9c8\ubb38\n        prompt = f\"\"\"\n        \ud604\uc7ac \uc2dc\uac01: {current_time} ({weekday}\uc694\uc77c)\n        \uc9c8\ubb38: {question}\n\n        \uce5c\uc808\ud558\uace0 \ub3c4\uc6c0\uc774 \ub418\ub294 \ub2f5\ubcc0\uc744 \ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9\ud558\uae30\nassistant = AIAssistant()\nprint(assistant.answer(\"\uc624\ub298 \ubb50 \uba39\uc744\uae4c?\"))\n</code></pre>"},{"location":"examples/02-everyday-tasks/ai-assistant/#step-2","title":"Step 2: \ud2b9\ud654\ub41c \uae30\ub2a5 \ucd94\uac00","text":"<pre><code>class SmartAssistant(AIAssistant):\n    \"\"\"\ub354 \ub611\ub611\ud55c AI \ube44\uc11c\"\"\"\n\n    def recommend_food(self, meal_time=\"\uc810\uc2ec\", preference=None):\n        \"\"\"\uc2dd\uc0ac \uba54\ub274\ub97c \ucd94\ucc9c\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"{meal_time} \uba54\ub274\ub97c \ucd94\ucc9c\ud574\uc8fc\uc138\uc694.\"\n\n        if preference:\n            prompt += f\" {preference}\uc744/\ub97c \uc120\ud638\ud569\ub2c8\ub2e4.\"\n\n        # \uacc4\uc808 \uc815\ubcf4 \ucd94\uac00\n        month = datetime.now().month\n        if month in [12, 1, 2]:\n            prompt += \" \uaca8\uc6b8\uc774\ub77c \ub530\ub73b\ud55c \uc74c\uc2dd\uc774\uba74 \uc88b\uaca0\uc5b4\uc694.\"\n        elif month in [6, 7, 8]:\n            prompt += \" \uc5ec\ub984\uc774\ub77c \uc2dc\uc6d0\ud55c \uc74c\uc2dd\uc774\uba74 \uc88b\uaca0\uc5b4\uc694.\"\n\n        return self.answer(prompt)\n\n    def calculate(self, expression):\n        \"\"\"\uacc4\uc0b0\uc744 \ub3c4\uc640\uc90d\ub2c8\ub2e4\"\"\"\n        prompt = f\"\ub2e4\uc74c\uc744 \uacc4\uc0b0\ud574\uc8fc\uc138\uc694: {expression}\"\n        return self.answer(prompt)\n\n    def translate(self, text, target_language=\"\uc601\uc5b4\"):\n        \"\"\"\ubc88\uc5ed\uc744 \ub3c4\uc640\uc90d\ub2c8\ub2e4\"\"\"\n        prompt = f\"'{text}'\ub97c {target_language}\ub85c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\"\n        return self.answer(prompt)\n\n    def explain(self, topic):\n        \"\"\"\uc5b4\ub824\uc6b4 \uac1c\ub150\uc744 \uc27d\uac8c \uc124\uba85\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"{topic}\uc5d0 \ub300\ud574 \ucd08\ub4f1\ud559\uc0dd\ub3c4 \uc774\ud574\ud560 \uc218 \uc788\uac8c \uc124\uba85\ud574\uc8fc\uc138\uc694.\"\n        return self.answer(prompt)\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nassistant = SmartAssistant()\n\n# \uba54\ub274 \ucd94\ucc9c\nprint(\"\ud83c\udf7d\ufe0f \uba54\ub274 \ucd94\ucc9c:\")\nprint(assistant.recommend_food(\"\uc800\ub141\", \"\ud55c\uc2dd\"))\n\n# \uacc4\uc0b0\nprint(\"\\n\ud83e\uddee \uacc4\uc0b0:\")\nprint(assistant.calculate(\"1\ub2ec\ub7ec\uac00 1,300\uc6d0\uc77c \ub54c 50\ub2ec\ub7ec\ub294 \uba87 \uc6d0?\"))\n\n# \ubc88\uc5ed\nprint(\"\\n\ud83c\udf0f \ubc88\uc5ed:\")\nprint(assistant.translate(\"\uc88b\uc740 \ud558\ub8e8 \ub418\uc138\uc694\", \"\uc77c\ubcf8\uc5b4\"))\n\n# \uc124\uba85\nprint(\"\\n\ud83d\udcda \uc124\uba85:\")\nprint(assistant.explain(\"\uad11\ud569\uc131\"))\n</code></pre>"},{"location":"examples/02-everyday-tasks/ai-assistant/#ai_2","title":"\ud83c\udfa8 \ub300\ud654\ud615 AI \ube44\uc11c","text":""},{"location":"examples/02-everyday-tasks/ai-assistant/#_2","title":"\uc778\ud130\ub799\ud2f0\ube0c \ube44\uc11c \ub9cc\ub4e4\uae30","text":"<pre><code>class InteractiveAssistant(SmartAssistant):\n    \"\"\"\ub300\ud654\ud615 AI \ube44\uc11c\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\"):\n        super().__init__(model)\n        self.commands = {\n            \"\uba54\ub274\": self.food_menu,\n            \"\uacc4\uc0b0\": self.calc_menu,\n            \"\ubc88\uc5ed\": self.trans_menu,\n            \"\uc124\uba85\": self.explain_menu,\n            \"\ub3c4\uc6c0\ub9d0\": self.show_help\n        }\n\n    def start(self):\n        \"\"\"\ub300\ud654\ud615 \uc138\uc158\uc744 \uc2dc\uc791\ud569\ub2c8\ub2e4\"\"\"\n        print(f\"\uc548\ub155\ud558\uc138\uc694! {self.name}\uc785\ub2c8\ub2e4. \ubb34\uc5c7\uc744 \ub3c4\uc640\ub4dc\ub9b4\uae4c\uc694?\")\n        print(\"(\uc885\ub8cc\ud558\ub824\uba74 '\uc885\ub8cc' \ub610\ub294 'quit'\uc744 \uc785\ub825\ud558\uc138\uc694)\")\n        self.show_help()\n\n        while True:\n            user_input = input(\"\\n\ud83d\udc64 you: \").strip()\n\n            if user_input.lower() in ['\uc885\ub8cc', 'quit', 'exit']:\n                print(f\"\uc88b\uc740 \ud558\ub8e8 \ub418\uc138\uc694! \ud83d\udc4b\")\n                break\n\n            # \uba85\ub839\uc5b4 \ud655\uc778\n            command_found = False\n            for cmd, func in self.commands.items():\n                if user_input.startswith(cmd):\n                    func(user_input)\n                    command_found = True\n                    break\n\n            # \uc77c\ubc18 \uc9c8\ubb38\n            if not command_found:\n                response = self.answer(user_input)\n                print(f\"\ud83e\udd16 {self.name}: {response}\")\n\n    def show_help(self):\n        \"\"\"\ub3c4\uc6c0\ub9d0\uc744 \ud45c\uc2dc\ud569\ub2c8\ub2e4\"\"\"\n        print(\"\\n\ud83d\udccb \uc0ac\uc6a9 \uac00\ub2a5\ud55c \uba85\ub839\uc5b4:\")\n        print(\"  \uba54\ub274 - \uc2dd\uc0ac \uba54\ub274 \ucd94\ucc9c\")\n        print(\"  \uacc4\uc0b0 - \uc218\uc2dd\uc774\ub098 \ub2e8\uc704 \ubcc0\ud658\")\n        print(\"  \ubc88\uc5ed - \ub2e4\uad6d\uc5b4 \ubc88\uc5ed\")\n        print(\"  \uc124\uba85 - \uc5b4\ub824\uc6b4 \uac1c\ub150 \uc124\uba85\")\n        print(\"  \ub3c4\uc6c0\ub9d0 - \uc774 \uba54\uc2dc\uc9c0 \ud45c\uc2dc\")\n        print(\"  \ub610\ub294 \uc790\uc720\ub86d\uac8c \uc9c8\ubb38\ud558\uc138\uc694!\")\n\n    def food_menu(self, user_input):\n        \"\"\"\uba54\ub274 \ucd94\ucc9c \ucc98\ub9ac\"\"\"\n        print(\"\ud83c\udf7d\ufe0f \uba54\ub274 \ucd94\ucc9c \ubaa8\ub4dc\")\n        meal = input(\"\uc5b4\ub290 \ub07c\ub2c8\uc778\uac00\uc694? (\uc544\uce68/\uc810\uc2ec/\uc800\ub141): \")\n        pref = input(\"\uc120\ud638\ud558\ub294 \uc74c\uc2dd \uc885\ub958\uac00 \uc788\ub098\uc694? (\ud55c\uc2dd/\uc911\uc2dd/\uc77c\uc2dd/\uc591\uc2dd \ub4f1): \")\n\n        result = self.recommend_food(meal, pref)\n        print(f\"\ud83e\udd16 {self.name}: {result}\")\n\n    def calc_menu(self, user_input):\n        \"\"\"\uacc4\uc0b0 \ucc98\ub9ac\"\"\"\n        print(\"\ud83e\uddee \uacc4\uc0b0 \ubaa8\ub4dc\")\n        expr = input(\"\uacc4\uc0b0\ud560 \ub0b4\uc6a9\uc744 \uc785\ub825\ud558\uc138\uc694: \")\n\n        result = self.calculate(expr)\n        print(f\"\ud83e\udd16 {self.name}: {result}\")\n\n    def trans_menu(self, user_input):\n        \"\"\"\ubc88\uc5ed \ucc98\ub9ac\"\"\"\n        print(\"\ud83c\udf0f \ubc88\uc5ed \ubaa8\ub4dc\")\n        text = input(\"\ubc88\uc5ed\ud560 \ud14d\uc2a4\ud2b8: \")\n        lang = input(\"\ubaa9\ud45c \uc5b8\uc5b4 (\uc601\uc5b4/\uc77c\ubcf8\uc5b4/\uc911\uad6d\uc5b4 \ub4f1): \")\n\n        result = self.translate(text, lang)\n        print(f\"\ud83e\udd16 {self.name}: {result}\")\n\n    def explain_menu(self, user_input):\n        \"\"\"\uc124\uba85 \ucc98\ub9ac\"\"\"\n        print(\"\ud83d\udcda \uc124\uba85 \ubaa8\ub4dc\")\n        topic = input(\"\uc124\uba85\uc774 \ud544\uc694\ud55c \uc8fc\uc81c: \")\n\n        result = self.explain(topic)\n        print(f\"\ud83e\udd16 {self.name}: {result}\")\n\n# \uc2e4\ud589\ud558\uae30\nif __name__ == \"__main__\":\n    assistant = InteractiveAssistant()\n    assistant.start()\n</code></pre>"},{"location":"examples/02-everyday-tasks/ai-assistant/#_3","title":"\ud83d\udd27 \uace0\uae09 \uae30\ub2a5 \ucd94\uac00","text":""},{"location":"examples/02-everyday-tasks/ai-assistant/#1","title":"1. \ud560 \uc77c \uad00\ub9ac \uae30\ub2a5","text":"<pre><code>class TaskAssistant(SmartAssistant):\n    \"\"\"\ud560 \uc77c\uc744 \uad00\ub9ac\ud558\ub294 AI \ube44\uc11c\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.tasks = []  # \ud560 \uc77c \ubaa9\ub85d\n\n    def add_task(self, task):\n        \"\"\"\ud560 \uc77c\uc744 \ucd94\uac00\ud569\ub2c8\ub2e4\"\"\"\n        self.tasks.append({\n            \"task\": task,\n            \"created\": datetime.now(),\n            \"completed\": False\n        })\n        return f\"\u2705 '{task}' \ud56d\ubaa9\uc744 \ucd94\uac00\ud588\uc2b5\ub2c8\ub2e4.\"\n\n    def list_tasks(self):\n        \"\"\"\ud560 \uc77c \ubaa9\ub85d\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4\"\"\"\n        if not self.tasks:\n            return \"\ud83d\udccb \ud560 \uc77c\uc774 \uc5c6\uc2b5\ub2c8\ub2e4!\"\n\n        result = \"\ud83d\udccb \ud560 \uc77c \ubaa9\ub85d:\\n\"\n        for i, task in enumerate(self.tasks, 1):\n            status = \"\u2713\" if task[\"completed\"] else \"\u25cb\"\n            result += f\"{i}. [{status}] {task['task']}\\n\"\n\n        return result\n\n    def complete_task(self, task_num):\n        \"\"\"\ud560 \uc77c\uc744 \uc644\ub8cc \ucc98\ub9ac\ud569\ub2c8\ub2e4\"\"\"\n        if 1 &lt;= task_num &lt;= len(self.tasks):\n            self.tasks[task_num-1][\"completed\"] = True\n            return f\"\u2705 \uc644\ub8cc\ud588\uc2b5\ub2c8\ub2e4!\"\n        return \"\u274c \uc798\ubabb\ub41c \ubc88\ud638\uc785\ub2c8\ub2e4.\"\n\n    def get_task_suggestion(self):\n        \"\"\"AI\uac00 \ud560 \uc77c\uc744 \uc81c\uc548\ud569\ub2c8\ub2e4\"\"\"\n        current_tasks = [t[\"task\"] for t in self.tasks if not t[\"completed\"]]\n\n        prompt = f\"\"\"\n        \ud604\uc7ac \ud560 \uc77c \ubaa9\ub85d: {current_tasks}\n        \uc2dc\uac04: {datetime.now().strftime(\"%H\uc2dc\")}\n\n        \uc9c0\uae08 \ud574\uc57c \ud560 \uac00\uc7a5 \uc911\uc694\ud55c \uc77c 1\uac00\uc9c0\ub97c \ucd94\ucc9c\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        return self.answer(prompt)\n\n# \uc0ac\uc6a9 \uc608\uc2dc\ntask_assistant = TaskAssistant()\n\n# \ud560 \uc77c \ucd94\uac00\nprint(task_assistant.add_task(\"Python \uacf5\ubd80\ud558\uae30\"))\nprint(task_assistant.add_task(\"\uc6b4\ub3d9 30\ubd84\"))\nprint(task_assistant.add_task(\"\ucc45 \uc77d\uae30\"))\n\n# \ubaa9\ub85d \ubcf4\uae30\nprint(task_assistant.list_tasks())\n\n# AI \ucd94\ucc9c \ubc1b\uae30\nprint(\"\\n\ud83e\udd16 AI \ucd94\ucc9c:\")\nprint(task_assistant.get_task_suggestion())\n</code></pre>"},{"location":"examples/02-everyday-tasks/ai-assistant/#2","title":"2. \uc77c\uc815 \uad00\ub9ac \uae30\ub2a5","text":"<pre><code>class ScheduleAssistant(SmartAssistant):\n    \"\"\"\uc77c\uc815\uc744 \uad00\ub9ac\ud558\ub294 AI \ube44\uc11c\"\"\"\n\n    def parse_schedule(self, text):\n        \"\"\"\uc790\uc5f0\uc5b4\ub85c \ub41c \uc77c\uc815\uc744 \ud30c\uc2f1\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\uc5d0\uc11c \uc77c\uc815 \uc815\ubcf4\ub97c \ucd94\ucd9c\ud574\uc8fc\uc138\uc694:\n        \"{text}\"\n\n        \ub2e4\uc74c \ud615\uc2dd\uc73c\ub85c \ub2f5\ud574\uc8fc\uc138\uc694:\n        - \ub0a0\uc9dc: YYYY-MM-DD\n        - \uc2dc\uac04: HH:MM\n        - \uc81c\ubaa9: \uc77c\uc815 \uc81c\ubaa9\n        - \uc7a5\uc18c: \uc7a5\uc18c (\uc5c6\uc73c\uba74 \"\uc5c6\uc74c\")\n        \"\"\"\n\n        return self.answer(prompt)\n\n    def remind_schedule(self, schedules):\n        \"\"\"\uc624\ub298\uc758 \uc77c\uc815\uc744 \uc54c\ub824\uc90d\ub2c8\ub2e4\"\"\"\n        today = datetime.now().strftime(\"%Y-%m-%d\")\n\n        prompt = f\"\"\"\n        \uc624\ub298({today})\uc758 \uc77c\uc815\uc785\ub2c8\ub2e4:\n        {schedules}\n\n        \uce5c\uc808\ud558\uac8c \uc624\ub298\uc758 \uc77c\uc815\uc744 \ube0c\ub9ac\ud551\ud574\uc8fc\uc138\uc694.\n        \uc900\ube44\ud560 \uac83\uc774\ub098 \uc8fc\uc758\uc0ac\ud56d\ub3c4 \ud568\uaed8 \uc54c\ub824\uc8fc\uc138\uc694.\n        \"\"\"\n\n        return self.answer(prompt)\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nschedule_ai = ScheduleAssistant()\n\n# \uc790\uc5f0\uc5b4 \uc77c\uc815 \ud30c\uc2f1\ntext = \"\ub0b4\uc77c \uc624\ud6c4 3\uc2dc\uc5d0 \uac15\ub0a8\uc5ed\uc5d0\uc11c \uce5c\uad6c \ub9cc\ub098\uae30\"\nparsed = schedule_ai.parse_schedule(text)\nprint(\"\ud83d\udcc5 \ud30c\uc2f1\ub41c \uc77c\uc815:\")\nprint(parsed)\n\n# \uc77c\uc815 \ube0c\ub9ac\ud551\nschedules = \"\"\"\n- 09:00 \ud300 \ud68c\uc758 (\ud68c\uc758\uc2e4 A)\n- 12:00 \uc810\uc2ec \uc57d\uc18d (\ud68c\uc0ac \uadfc\ucc98 \uc2dd\ub2f9)\n- 15:00 \ud504\ub85c\uc81d\ud2b8 \ubc1c\ud45c (\ub300\ud68c\uc758\uc2e4)\n\"\"\"\nbriefing = schedule_ai.remind_schedule(schedules)\nprint(\"\\n\ud83d\udce2 \uc624\ub298\uc758 \uc77c\uc815 \ube0c\ub9ac\ud551:\")\nprint(briefing)\n</code></pre>"},{"location":"examples/02-everyday-tasks/ai-assistant/#_4","title":"\ud83d\udcbe \ub300\ud654 \uae30\ub85d \uc800\uc7a5\ud558\uae30","text":"<pre><code>import json\nfrom datetime import datetime\n\nclass MemoryAssistant(SmartAssistant):\n    \"\"\"\ub300\ud654\ub97c \uae30\uc5b5\ud558\ub294 AI \ube44\uc11c\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.conversation_history = []\n        self.load_history()\n\n    def answer_with_memory(self, question):\n        \"\"\"\ub300\ud654 \uae30\ub85d\uc744 \ucc38\uace0\ud574\uc11c \ub2f5\ubcc0\ud569\ub2c8\ub2e4\"\"\"\n        # \ucd5c\uadfc \ub300\ud654 3\uac1c \uac00\uc838\uc624\uae30\n        recent = self.conversation_history[-3:] if self.conversation_history else []\n\n        context = \"\uc774\uc804 \ub300\ud654:\\n\"\n        for conv in recent:\n            context += f\"Q: {conv['question']}\\n\"\n            context += f\"A: {conv['answer'][:50]}...\\n\\n\"\n\n        # \ud604\uc7ac \uc9c8\ubb38 \ucd94\uac00\n        full_prompt = context + f\"\ud604\uc7ac \uc9c8\ubb38: {question}\"\n\n        response = self.ai.ask(full_prompt)\n\n        # \ub300\ud654 \uc800\uc7a5\n        self.conversation_history.append({\n            \"timestamp\": datetime.now().isoformat(),\n            \"question\": question,\n            \"answer\": response.text\n        })\n\n        self.save_history()\n        return response.text\n\n    def save_history(self):\n        \"\"\"\ub300\ud654 \uae30\ub85d\uc744 \ud30c\uc77c\ub85c \uc800\uc7a5\ud569\ub2c8\ub2e4\"\"\"\n        with open(\"conversation_history.json\", \"w\", encoding=\"utf-8\") as f:\n            json.dump(self.conversation_history, f, ensure_ascii=False, indent=2)\n\n    def load_history(self):\n        \"\"\"\uc800\uc7a5\ub41c \ub300\ud654 \uae30\ub85d\uc744 \ubd88\ub7ec\uc635\ub2c8\ub2e4\"\"\"\n        try:\n            with open(\"conversation_history.json\", \"r\", encoding=\"utf-8\") as f:\n                self.conversation_history = json.load(f)\n        except FileNotFoundError:\n            self.conversation_history = []\n\n    def search_history(self, keyword):\n        \"\"\"\ub300\ud654 \uae30\ub85d\uc5d0\uc11c \ud0a4\uc6cc\ub4dc\ub97c \uac80\uc0c9\ud569\ub2c8\ub2e4\"\"\"\n        results = []\n        for conv in self.conversation_history:\n            if keyword in conv[\"question\"] or keyword in conv[\"answer\"]:\n                results.append(conv)\n\n        return results\n\n# \uc0ac\uc6a9\ud558\uae30\nmemory_ai = MemoryAssistant()\n\n# \ub300\ud654\ud558\uae30\nquestions = [\n    \"\ud30c\uc774\uc36c\uc744 \ubc30\uc6b0\uace0 \uc2f6\uc5b4\",\n    \"\ucd08\ubcf4\uc790\uac00 \ubcf4\uba74 \uc88b\uc740 \ucc45 \ucd94\ucc9c\ud574\uc918\",\n    \"\uc544\uae4c \ucd94\ucc9c\ud574\uc900 \ucc45 \uc911\uc5d0 \uc5b4\ub5a4 \uac8c \uc81c\uc77c \uc88b\uc544?\"\n]\n\nfor q in questions:\n    print(f\"\\n\ud83d\udc64 You: {q}\")\n    answer = memory_ai.answer_with_memory(q)\n    print(f\"\ud83e\udd16 AI: {answer[:100]}...\")\n\n# \ub300\ud654 \uac80\uc0c9\nprint(\"\\n\ud83d\udd0d '\ucc45' \uad00\ub828 \ub300\ud654 \uac80\uc0c9:\")\nresults = memory_ai.search_history(\"\ucc45\")\nfor r in results:\n    print(f\"- {r['timestamp']}: {r['question']}\")\n</code></pre>"},{"location":"examples/02-everyday-tasks/ai-assistant/#_5","title":"\ud83c\udfaf \uc2e4\uc804 \ud65c\uc6a9 \uc608\uc81c","text":""},{"location":"examples/02-everyday-tasks/ai-assistant/#_6","title":"\ud558\ub8e8 \uc77c\uacfc \ub3c4\uc6b0\ubbf8","text":"<pre><code>def daily_assistant():\n    \"\"\"\ud558\ub8e8\ub97c \uc2dc\uc791\ud558\uace0 \ub9c8\ubb34\ub9ac\ud558\ub294 AI \ub3c4\uc6b0\ubbf8\"\"\"\n    assistant = SmartAssistant()\n\n    # \uc544\uce68 \ube0c\ub9ac\ud551\n    morning_prompt = \"\"\"\n    \uc88b\uc740 \uc544\uce68\uc785\ub2c8\ub2e4! \uc624\ub298 \ud558\ub8e8\ub97c \uc2dc\uc791\ud558\ub294 \uc0ac\ub78c\uc5d0\uac8c\n    \ub3d9\uae30\ubd80\uc5ec\uac00 \ub418\ub294 \uba54\uc2dc\uc9c0\uc640 \ud568\uaed8 \ub2e4\uc74c\uc744 \ud3ec\ud568\ud574 \ube0c\ub9ac\ud551\ud574\uc8fc\uc138\uc694:\n    - \uc624\ub298\uc758 \ub0a0\uc9dc\uc640 \uc694\uc77c\n    - \ud558\ub8e8\ub97c \uc2dc\uc791\ud558\ub294 \ud301 1\uac00\uc9c0\n    - \uae0d\uc815\uc801\uc778 \ud55c \ub9c8\ub514\n    \"\"\"\n\n    print(\"\u2600\ufe0f \uc544\uce68 \ube0c\ub9ac\ud551\")\n    print(assistant.answer(morning_prompt))\n\n    # \uc800\ub141 \uc815\ub9ac\n    evening_prompt = \"\"\"\n    \uc218\uace0\ud558\uc168\uc2b5\ub2c8\ub2e4! \ud558\ub8e8\ub97c \ub9c8\ubb34\ub9ac\ud558\ub294 \uc0ac\ub78c\uc5d0\uac8c\n    \ub2e4\uc74c\uc744 \ud3ec\ud568\ud55c \uba54\uc2dc\uc9c0\ub97c \uc804\ud574\uc8fc\uc138\uc694:\n    - \uc624\ub298 \ud558\ub8e8 \ub3cc\uc544\ubcf4\uae30 \uc720\ub3c4\n    - \ub0b4\uc77c\uc744 \uc704\ud55c \uc900\ube44 \ud301\n    - \ud3b8\uc548\ud55c \ubc24 \uc778\uc0ac\n    \"\"\"\n\n    print(\"\\n\ud83c\udf19 \uc800\ub141 \ub9c8\ubb34\ub9ac\")\n    print(assistant.answer(evening_prompt))\n\n# \uc2e4\ud589\ndaily_assistant()\n</code></pre>"},{"location":"examples/02-everyday-tasks/ai-assistant/#_7","title":"\u2705 \ud575\uc2ec \uc815\ub9ac","text":"<ol> <li>**AI \ube44\uc11c**\ub294 \uc77c\uc0c1 \uc5c5\ubb34\ub97c \ub3c4\uc640\uc8fc\ub294 \ub611\ub611\ud55c \ub3c4\uad6c</li> <li>**\ud074\ub798\uc2a4\ub85c \uad6c\uc870\ud654**\ud558\uba74 \uae30\ub2a5 \ud655\uc7a5\uc774 \uc26c\uc6c0</li> <li>**\ub300\ud654\ud615 \uc778\ud130\ud398\uc774\uc2a4**\ub85c \uc0ac\uc6a9\uc131 \ud5a5\uc0c1</li> <li>**\uba54\ubaa8\ub9ac \uae30\ub2a5**\uc73c\ub85c \ub9e5\ub77d \uc788\ub294 \ub300\ud654 \uac00\ub2a5</li> </ol>"},{"location":"examples/02-everyday-tasks/ai-assistant/#_8","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>AI \ube44\uc11c\ub97c \ub9cc\ub4e4\uc5c8\uc73c\ub2c8, \uc774\uc81c \ud14d\uc2a4\ud2b8 \uac1c\uc120 \ub3c4\uad6c\ub97c \ub9cc\ub4e4\uc5b4 \uae00\uc4f0\uae30\ub97c \ub3c4\uc640\uc8fc\ub294 AI\ub97c \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/02-everyday-tasks/summarizer/","title":"\ud83d\udcc4 \ub611\ub611\ud55c \uc694\uc57d\uae30 \ub9cc\ub4e4\uae30","text":"<p>\uae34 \ud14d\uc2a4\ud2b8\ub97c \ud575\uc2ec\ub9cc \ub2f4\uc544 \uac04\uacb0\ud558\uac8c \uc694\uc57d\ud558\ub294 AI \ub3c4\uad6c\ub97c \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/02-everyday-tasks/summarizer/#_2","title":"\ud83c\udfaf \ub9cc\ub4e4 \uac83","text":"<pre><code>\uc6d0\ubb38: (3000\uc790 \uae34 \uae30\uc0ac)\n\uc694\uc57d: \n\u2022 \ud575\uc2ec \ud3ec\uc778\ud2b8 1\n\u2022 \ud575\uc2ec \ud3ec\uc778\ud2b8 2  \n\u2022 \ud575\uc2ec \ud3ec\uc778\ud2b8 3\n</code></pre>"},{"location":"examples/02-everyday-tasks/summarizer/#_3","title":"\ud83d\udcdd \uae30\ubcf8 \uc694\uc57d\uae30","text":""},{"location":"examples/02-everyday-tasks/summarizer/#step-1","title":"Step 1: \uac04\ub2e8\ud55c \ud14d\uc2a4\ud2b8 \uc694\uc57d\uae30","text":"<pre><code># summarizer.py\nfrom pyhub.llm import LLM\n\nclass TextSummarizer:\n    \"\"\"\ud14d\uc2a4\ud2b8 \uc694\uc57d AI \ub3c4\uad6c\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.ai = LLM.create(model)\n\n    def summarize(self, text, max_length=200):\n        \"\"\"\ud14d\uc2a4\ud2b8\ub97c \uc694\uc57d\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c {max_length}\uc790 \uc774\ub0b4\ub85c \uc694\uc57d\ud574\uc8fc\uc138\uc694.\n        \ud575\uc2ec \ub0b4\uc6a9\ub9cc \ud3ec\ud568\ud558\uace0 \uba85\ud655\ud558\uac8c \uc791\uc131\ud574\uc8fc\uc138\uc694.\n\n        \uc6d0\ubb38:\n        {text}\n\n        \uc694\uc57d:\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def bullet_points(self, text, num_points=5):\n        \"\"\"\ud575\uc2ec \ud3ec\uc778\ud2b8\ub97c \ucd94\ucd9c\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\uc5d0\uc11c \uac00\uc7a5 \uc911\uc694\ud55c {num_points}\uac1c\uc758 \ud575\uc2ec \ud3ec\uc778\ud2b8\ub97c \ucd94\ucd9c\ud574\uc8fc\uc138\uc694.\n\n        \uc6d0\ubb38:\n        {text}\n\n        \uac01 \ud3ec\uc778\ud2b8\ub294 \ud55c \uc904\ub85c \uac04\ub2e8\uba85\ub8cc\ud558\uac8c \uc791\uc131\ud574\uc8fc\uc138\uc694:\n        \u2022 \ud3ec\uc778\ud2b8 1\n        \u2022 \ud3ec\uc778\ud2b8 2\n        ...\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def one_line_summary(self, text):\n        \"\"\"\ud55c \uc904 \uc694\uc57d\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c \ud55c \ubb38\uc7a5\uc73c\ub85c \uc694\uc57d\ud574\uc8fc\uc138\uc694.\n        \uac00\uc7a5 \ud575\uc2ec\uc801\uc778 \ub0b4\uc6a9\ub9cc \ub2f4\uc544\uc8fc\uc138\uc694.\n\n        \uc6d0\ubb38:\n        {text}\n\n        \ud55c \uc904 \uc694\uc57d:\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text.strip()\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nsummarizer = TextSummarizer()\n\n# \uc0d8\ud50c \ud14d\uc2a4\ud2b8\nlong_text = \"\"\"\n\uc778\uacf5\uc9c0\ub2a5(AI)\uc740 \uc778\uac04\uc758 \ud559\uc2b5\ub2a5\ub825, \ucd94\ub860\ub2a5\ub825, \uc9c0\uac01\ub2a5\ub825\uc744 \uc778\uacf5\uc801\uc73c\ub85c \uad6c\ud604\ud558\ub824\ub294 \n\ucef4\ud4e8\ud130 \uacfc\ud559\uc758 \ud55c \ubd84\uc57c\uc785\ub2c8\ub2e4. 1950\ub144\ub300\uc5d0 \ucc98\uc74c \ub4f1\uc7a5\ud55c \uc774\ud6c4, AI\ub294 \ub180\ub77c\uc6b4 \uc18d\ub3c4\ub85c \n\ubc1c\uc804\ud574\uc654\uc2b5\ub2c8\ub2e4. \ud2b9\ud788 \ucd5c\uadfc \ub525\ub7ec\ub2dd \uae30\uc220\uc758 \ubc1c\uc804\uc73c\ub85c \uc774\ubbf8\uc9c0 \uc778\uc2dd, \uc790\uc5f0\uc5b4 \ucc98\ub9ac, \n\uac8c\uc784 \ud50c\ub808\uc774 \ub4f1 \ub2e4\uc591\ud55c \ubd84\uc57c\uc5d0\uc11c \uc778\uac04 \uc218\uc900\uc744 \ub6f0\uc5b4\ub118\ub294 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\nAI\uc758 \ubc1c\uc804\uc740 \uc6b0\ub9ac \uc77c\uc0c1\uc0dd\ud65c\uc5d0\ub3c4 \ud070 \ubcc0\ud654\ub97c \uac00\uc838\uc654\uc2b5\ub2c8\ub2e4. \uc2a4\ub9c8\ud2b8\ud3f0\uc758 \uc74c\uc131 \ube44\uc11c, \n\ucd94\ucc9c \uc2dc\uc2a4\ud15c, \uc790\uc728\uc8fc\ud589 \uc790\ub3d9\ucc28 \ub4f1\uc774 \ub300\ud45c\uc801\uc778 \uc608\uc785\ub2c8\ub2e4. \uc758\ub8cc \ubd84\uc57c\uc5d0\uc11c\ub294 AI\uac00 \n\uc9c8\ubcd1 \uc9c4\ub2e8\uc744 \ub3d5\uace0, \uae08\uc735 \ubd84\uc57c\uc5d0\uc11c\ub294 \uc0ac\uae30 \ud0d0\uc9c0\uc640 \ud22c\uc790 \ubd84\uc11d\uc5d0 \ud65c\uc6a9\ub429\ub2c8\ub2e4.\n\n\uadf8\ub7ec\ub098 AI\uc758 \uae09\uc18d\ud55c \ubc1c\uc804\uc740 \uc0c8\ub85c\uc6b4 \uacfc\uc81c\ub3c4 \uac00\uc838\uc654\uc2b5\ub2c8\ub2e4. \uc77c\uc790\ub9ac \ub300\uccb4, \n\ud504\ub77c\uc774\ubc84\uc2dc \uce68\ud574, AI\uc758 \ud3b8\ud5a5\uc131 \ubb38\uc81c \ub4f1\uc774 \uc0ac\ud68c\uc801 \uc774\uc288\ub85c \ub300\ub450\ub418\uace0 \uc788\uc2b5\ub2c8\ub2e4. \n\ub530\ub77c\uc11c AI \uae30\uc220\uc744 \ubc1c\uc804\uc2dc\ud0a4\ub294 \ub3d9\uc2dc\uc5d0 \uc724\ub9ac\uc801\uc774\uace0 \ucc45\uc784\uac10 \uc788\ub294 AI \uac1c\ubc1c\uc774 \n\uc911\uc694\ud574\uc9c0\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\"\"\"\n\n# \ub2e4\uc591\ud55c \uc694\uc57d \ubc29\uc2dd\nprint(\"\ud83d\udcdd \uc77c\ubc18 \uc694\uc57d (200\uc790):\")\nprint(summarizer.summarize(long_text, max_length=200))\n\nprint(\"\\n\ud83c\udfaf \ud575\uc2ec \ud3ec\uc778\ud2b8:\")\nprint(summarizer.bullet_points(long_text, num_points=3))\n\nprint(\"\\n\ud83d\udccc \ud55c \uc904 \uc694\uc57d:\")\nprint(summarizer.one_line_summary(long_text))\n</code></pre>"},{"location":"examples/02-everyday-tasks/summarizer/#step-2","title":"Step 2: \uace0\uae09 \uc694\uc57d \uae30\ub2a5","text":"<pre><code>class AdvancedSummarizer(TextSummarizer):\n    \"\"\"\uace0\uae09 \uc694\uc57d \uae30\ub2a5\uc744 \uac16\ucd98 \ub3c4\uad6c\"\"\"\n\n    def summarize_by_sections(self, text, section_delimiter=\"\\n\\n\"):\n        \"\"\"\uc139\uc158\ubcc4\ub85c \uc694\uc57d\ud569\ub2c8\ub2e4\"\"\"\n        sections = text.split(section_delimiter)\n        summaries = []\n\n        for i, section in enumerate(sections, 1):\n            if section.strip():\n                summary = self.summarize(section, max_length=100)\n                summaries.append(f\"\uc139\uc158 {i}: {summary}\")\n\n        return \"\\n\".join(summaries)\n\n    def progressive_summary(self, text, levels=[500, 200, 50]):\n        \"\"\"\ub2e8\uacc4\ubcc4\ub85c \uc810\uc9c4\uc801\uc73c\ub85c \uc694\uc57d\ud569\ub2c8\ub2e4\"\"\"\n        results = {}\n        current_text = text\n\n        for level in levels:\n            summary = self.summarize(current_text, max_length=level)\n            results[f\"{level}\uc790 \uc694\uc57d\"] = summary\n            current_text = summary  # \ub2e4\uc74c \ub2e8\uacc4\uc758 \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\n\n        return results\n\n    def extract_key_information(self, text, info_types):\n        \"\"\"\ud2b9\uc815 \uc815\ubcf4\ub97c \ucd94\ucd9c\ud569\ub2c8\ub2e4\"\"\"\n        info_prompts = {\n            \"people\": \"\ub4f1\uc7a5\ud558\ub294 \uc778\ubb3c\uc774\ub098 \uc870\uc9c1\",\n            \"dates\": \"\ub0a0\uc9dc\ub098 \uc2dc\uac04 \uc815\ubcf4\",\n            \"numbers\": \"\uc22b\uc790\ub098 \ud1b5\uacc4 \ub370\uc774\ud130\",\n            \"locations\": \"\uc7a5\uc18c\ub098 \uc9c0\uc5ed \uc815\ubcf4\",\n            \"events\": \"\uc911\uc694\ud55c \uc0ac\uac74\uc774\ub098 \uc774\ubca4\ud2b8\",\n            \"conclusions\": \"\uacb0\ub860\uc774\ub098 \ud575\uc2ec \uba54\uc2dc\uc9c0\"\n        }\n\n        results = {}\n        for info_type in info_types:\n            if info_type in info_prompts:\n                prompt = f\"\"\"\n                \ub2e4\uc74c \ud14d\uc2a4\ud2b8\uc5d0\uc11c {info_prompts[info_type]}\ub9cc \ucd94\ucd9c\ud574\uc8fc\uc138\uc694:\n\n                {text}\n\n                \uc5c6\uc73c\uba74 \"\ud574\ub2f9 \uc5c6\uc74c\"\uc774\ub77c\uace0 \ub2f5\ud574\uc8fc\uc138\uc694.\n                \"\"\"\n\n                response = self.ai.ask(prompt)\n                results[info_type] = response.text\n\n        return results\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nadv_summarizer = AdvancedSummarizer()\n\n# \uc139\uc158\ubcc4 \uc694\uc57d\nprint(\"\ud83d\udcd1 \uc139\uc158\ubcc4 \uc694\uc57d:\")\nsection_summary = adv_summarizer.summarize_by_sections(long_text)\nprint(section_summary)\n\n# \ub2e8\uacc4\ubcc4 \uc694\uc57d\nprint(\"\\n\ud83d\udcca \ub2e8\uacc4\ubcc4 \uc694\uc57d:\")\nprogressive = adv_summarizer.progressive_summary(long_text)\nfor level, summary in progressive.items():\n    print(f\"\\n[{level}]\")\n    print(summary)\n\n# \uc815\ubcf4 \ucd94\ucd9c\nprint(\"\\n\ud83d\udd0d \ud575\uc2ec \uc815\ubcf4 \ucd94\ucd9c:\")\nextracted = adv_summarizer.extract_key_information(\n    long_text,\n    [\"numbers\", \"events\", \"conclusions\"]\n)\nfor info_type, content in extracted.items():\n    print(f\"\\n{info_type.upper()}:\")\n    print(content)\n</code></pre>"},{"location":"examples/02-everyday-tasks/summarizer/#_4","title":"\ud83c\udfa8 \ud2b9\ud654\ub41c \uc694\uc57d \ub3c4\uad6c","text":""},{"location":"examples/02-everyday-tasks/summarizer/#1","title":"1. \ub274\uc2a4 \uae30\uc0ac \uc694\uc57d\uae30","text":"<pre><code>class NewsArticleSummarizer(AdvancedSummarizer):\n    \"\"\"\ub274\uc2a4 \uae30\uc0ac \uc804\ubb38 \uc694\uc57d \ub3c4\uad6c\"\"\"\n\n    def summarize_news(self, article):\n        \"\"\"\ub274\uc2a4 \uae30\uc0ac\ub97c \uc694\uc57d\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ub274\uc2a4 \uae30\uc0ac\ub97c \uc694\uc57d\ud574\uc8fc\uc138\uc694.\n\n        \uae30\uc0ac:\n        {article}\n\n        \ub2e4\uc74c \ud615\uc2dd\uc73c\ub85c \uc694\uc57d\ud574\uc8fc\uc138\uc694:\n\n        \ud83d\udcf0 \ud5e4\ub4dc\ub77c\uc778: (\ud575\uc2ec \ub0b4\uc6a9\uc744 \ud55c \uc904\ub85c)\n\n        \ud83d\udccb \uc8fc\uc694 \ub0b4\uc6a9:\n        \u2022 (\ud575\uc2ec \uc0ac\uc2e4 1)\n        \u2022 (\ud575\uc2ec \uc0ac\uc2e4 2)\n        \u2022 (\ud575\uc2ec \uc0ac\uc2e4 3)\n\n        \ud83d\udd0d \ubc30\uacbd:\n        (\uac04\ub2e8\ud55c \ubc30\uacbd \uc124\uba85)\n\n        \ud83d\udca1 \uc2dc\uc0ac\uc810:\n        (\uc774 \ub274\uc2a4\uc758 \uc758\ubbf8\ub098 \uc601\ud5a5)\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def create_news_brief(self, articles):\n        \"\"\"\uc5ec\ub7ec \uae30\uc0ac\ub97c \ud558\ub098\uc758 \ube0c\ub9ac\ud551\uc73c\ub85c \ub9cc\ub4ed\ub2c8\ub2e4\"\"\"\n        prompt = \"\ub2e4\uc74c \ub274\uc2a4\ub4e4\uc744 \uc885\ud569\ud558\uc5ec \uc624\ub298\uc758 \uc8fc\uc694 \ub274\uc2a4 \ube0c\ub9ac\ud551\uc744 \uc791\uc131\ud574\uc8fc\uc138\uc694:\\n\\n\"\n\n        for i, article in enumerate(articles, 1):\n            prompt += f\"\uae30\uc0ac {i}:\\n{article[:500]}...\\n\\n\"\n\n        prompt += \"\"\"\n        \ube0c\ub9ac\ud551 \ud615\uc2dd:\n        \ud83d\uddde\ufe0f \uc624\ub298\uc758 \uc8fc\uc694 \ub274\uc2a4\n\n        1. [\uc81c\ubaa9] - \uc694\uc57d\n        2. [\uc81c\ubaa9] - \uc694\uc57d\n        ...\n\n        \ud83d\udcca \uc624\ub298\uc758 \ud2b8\ub80c\ub4dc:\n        (\uc804\uccb4\uc801\uc778 \ub3d9\ud5a5 \ubd84\uc11d)\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nnews_summarizer = NewsArticleSummarizer()\n\n# \ub274\uc2a4 \uae30\uc0ac \uc608\uc2dc\nnews_article = \"\"\"\n[\uc18d\ubcf4] \uc815\ubd80, AI \uc0b0\uc5c5 \uc721\uc131 \uc704\ud574 10\uc870\uc6d0 \ud22c\uc790 \uacc4\ud68d \ubc1c\ud45c\n\n\uc815\ubd80\uac00 \uc778\uacf5\uc9c0\ub2a5(AI) \uc0b0\uc5c5 \uc721\uc131\uc744 \uc704\ud574 \ud5a5\ud6c4 5\ub144\uac04 10\uc870\uc6d0\uc744 \ud22c\uc790\ud55c\ub2e4\uace0 \ubc1c\ud45c\ud588\ub2e4. \n\uc774\ubc88 \ud22c\uc790\ub294 AI \uc778\ud504\ub77c \uad6c\ucd95, \uc778\uc7ac \uc591\uc131, \uae30\uc5c5 \uc9c0\uc6d0 \ub4f1 \uc138 \uac00\uc9c0 \ucd95\uc744 \uc911\uc2ec\uc73c\ub85c \uc9c4\ud589\ub420 \uc608\uc815\uc774\ub2e4.\n\n\uacfc\ud559\uae30\uc220\uc815\ubcf4\ud1b5\uc2e0\ubd80\ub294 \uc624\ub298 'AI \uac15\uad6d \ub3c4\uc57d \uc804\ub7b5'\uc744 \ubc1c\ud45c\ud558\uba70, 2030\ub144\uae4c\uc9c0 \uae00\ub85c\ubc8c AI \n\uc120\ub3c4\uad6d\uac00\ub85c \ub3c4\uc57d\ud558\uaca0\ub2e4\ub294 \ubaa9\ud45c\ub97c \uc81c\uc2dc\ud588\ub2e4. \uc8fc\uc694 \ub0b4\uc6a9\uc73c\ub85c\ub294 AI \uc804\ubb38\uc778\ub825 10\ub9cc\uba85 \uc591\uc131, \nAI \uc2a4\ud0c0\ud2b8\uc5c5 1000\uac1c \uc721\uc131, \uacf5\uacf5 \ubd84\uc57c AI \ub3c4\uc785 \ud655\ub300 \ub4f1\uc774 \ud3ec\ud568\ub410\ub2e4.\n\n\uc5c5\uacc4\uc5d0\uc11c\ub294 \uc774\ubc88 \uc815\ubd80\uc758 \ub300\uaddc\ubaa8 \ud22c\uc790\uac00 \uad6d\ub0b4 AI \uc0dd\ud0dc\uacc4 \ud65c\uc131\ud654\uc5d0 \ud06c\uac8c \uae30\uc5ec\ud560 \uac83\uc73c\ub85c \n\uae30\ub300\ud558\uace0 \uc788\ub2e4. \ud2b9\ud788 \uc911\uc18c\uae30\uc5c5\uacfc \uc2a4\ud0c0\ud2b8\uc5c5\uc5d0 \ub300\ud55c \uc9c0\uc6d0\uc774 \ud655\ub300\ub418\uc5b4 AI \uae30\uc220 \uac1c\ubc1c\uacfc \n\uc0ac\uc5c5\ud654\uac00 \uac00\uc18d\ud654\ub420 \uc804\ub9dd\uc774\ub2e4.\n\"\"\"\n\nprint(\"\ud83d\udcf0 \ub274\uc2a4 \uc694\uc57d:\")\nnews_summary = news_summarizer.summarize_news(news_article)\nprint(news_summary)\n\n# \uc5ec\ub7ec \uae30\uc0ac \ube0c\ub9ac\ud551\nprint(\"\\n\ud83d\udce2 \uc885\ud569 \ub274\uc2a4 \ube0c\ub9ac\ud551:\")\narticles = [\n    \"AI \ud22c\uc790 10\uc870\uc6d0 \ubc1c\ud45c...\",\n    \"\uc0bc\uc131\uc804\uc790, \uc0c8\ub85c\uc6b4 AI \uce69 \uac1c\ubc1c...\",\n    \"\ub124\uc774\ubc84, AI \uac80\uc0c9 \uc11c\ube44\uc2a4 \ucd9c\uc2dc...\"\n]\nbrief = news_summarizer.create_news_brief(articles)\nprint(brief)\n</code></pre>"},{"location":"examples/02-everyday-tasks/summarizer/#2","title":"2. \ud68c\uc758\ub85d \uc694\uc57d\uae30","text":"<pre><code>class MeetingSummarizer(AdvancedSummarizer):\n    \"\"\"\ud68c\uc758\ub85d \uc694\uc57d \uc804\ubb38 \ub3c4\uad6c\"\"\"\n\n    def summarize_meeting(self, transcript):\n        \"\"\"\ud68c\uc758\ub85d\uc744 \uc694\uc57d\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud68c\uc758\ub85d\uc744 \uc694\uc57d\ud574\uc8fc\uc138\uc694:\n\n        {transcript}\n\n        \ub2e4\uc74c \ud615\uc2dd\uc73c\ub85c \uc815\ub9ac\ud574\uc8fc\uc138\uc694:\n\n        \ud83d\udcc5 \ud68c\uc758 \uac1c\uc694\n        - \uc8fc\uc81c:\n        - \ucc38\uc11d\uc790:\n        - \uc77c\uc2dc:\n\n        \ud83c\udfaf \uc8fc\uc694 \uc548\uac74\n        1. \n        2. \n\n        \ud83d\udcac \uc8fc\uc694 \ub17c\uc758\uc0ac\ud56d\n        \u2022 \n        \u2022 \n\n        \u2705 \uacb0\uc815\uc0ac\ud56d\n        \u2022 \n        \u2022 \n\n        \ud83d\udccb \uc561\uc158 \uc544\uc774\ud15c\n        \u2022 [\ub2f4\ub2f9\uc790] \ud560 \uc77c (\uae30\ud55c)\n        \u2022 [\ub2f4\ub2f9\uc790] \ud560 \uc77c (\uae30\ud55c)\n\n        \ud83d\udccc \ub2e4\uc74c \ud68c\uc758\n        - \uc77c\uc2dc:\n        - \uc548\uac74:\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def extract_action_items(self, transcript):\n        \"\"\"\uc561\uc158 \uc544\uc774\ud15c\ub9cc \ucd94\ucd9c\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud68c\uc758\ub85d\uc5d0\uc11c \uc561\uc158 \uc544\uc774\ud15c(\ud560 \uc77c)\ub9cc \ucd94\ucd9c\ud574\uc8fc\uc138\uc694:\n\n        {transcript}\n\n        \ud615\uc2dd:\n        1. [\ub2f4\ub2f9\uc790] \ud560 \uc77c \ub0b4\uc6a9 (\uae30\ud55c)\n        2. [\ub2f4\ub2f9\uc790] \ud560 \uc77c \ub0b4\uc6a9 (\uae30\ud55c)\n\n        \ub2f4\ub2f9\uc790\uac00 \uba85\ud655\ud558\uc9c0 \uc54a\uc73c\uba74 [\ubbf8\uc815]\uc73c\ub85c \ud45c\uc2dc\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def create_meeting_minutes(self, notes):\n        \"\"\"\uba54\ubaa8\ub97c \uc815\uc2dd \ud68c\uc758\ub85d\uc73c\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud68c\uc758 \uba54\ubaa8\ub97c \uc815\uc2dd \ud68c\uc758\ub85d \ud615\uc2dd\uc73c\ub85c \uc791\uc131\ud574\uc8fc\uc138\uc694:\n\n        \uba54\ubaa8:\n        {notes}\n\n        \uc804\ubb38\uc801\uc774\uace0 \uacf5\uc2dd\uc801\uc778 \ubb38\uccb4\ub85c \uc791\uc131\ud558\ub418,\n        \ud575\uc2ec \ub0b4\uc6a9\uc740 \ubaa8\ub450 \ud3ec\ud568\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nmeeting_summarizer = MeetingSummarizer()\n\n# \ud68c\uc758\ub85d \uc608\uc2dc\nmeeting_transcript = \"\"\"\n\uae40\ubd80\uc7a5: \uc774\ubc88 \ud504\ub85c\uc81d\ud2b8 \uc9c4\ud589 \uc0c1\ud669\uc744 \uacf5\uc720\ud558\uaca0\uc2b5\ub2c8\ub2e4. \ud604\uc7ac 1\ub2e8\uacc4\ub294 \uc644\ub8cc\ud588\uace0, 2\ub2e8\uacc4 \uc9c4\ud589 \uc911\uc785\ub2c8\ub2e4.\n\uc774\uacfc\uc7a5: 2\ub2e8\uacc4\uc5d0\uc11c \uc608\uc0c1\ubcf4\ub2e4 \uc2dc\uac04\uc774 \uac78\ub9ac\uace0 \uc788\ub294\ub370, \ucd94\uac00 \uc778\ub825\uc774 \ud544\uc694\ud560 \uac83 \uac19\uc2b5\ub2c8\ub2e4.\n\ubc15\ud300\uc7a5: \uac1c\ubc1c\ud300\uc5d0\uc11c 2\uba85 \uc9c0\uc6d0 \uac00\ub2a5\ud569\ub2c8\ub2e4. \ub2e4\uc74c \uc8fc\ubd80\ud130 \ud22c\uc785\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\uae40\ubd80\uc7a5: \uc88b\uc2b5\ub2c8\ub2e4. \uadf8\ub7fc \uc774\uacfc\uc7a5\ub2d8\uc740 \ub2e4\uc74c \uc8fc\uae4c\uc9c0 \uc0c1\uc138 \uacc4\ud68d\uc11c\ub97c \uc791\uc131\ud574 \uc8fc\uc138\uc694.\n\uc774\uacfc\uc7a5: \uc54c\uaca0\uc2b5\ub2c8\ub2e4. \uae08\uc694\uc77c\uae4c\uc9c0 \uc81c\ucd9c\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\ubc15\ud300\uc7a5: \uc800\ub294 \uac1c\ubc1c \ud658\uacbd \uc138\ud305\uc744 \ubbf8\ub9ac \uc900\ube44\ud574\ub450\uaca0\uc2b5\ub2c8\ub2e4.\n\uae40\ubd80\uc7a5: \ub2e4\uc74c \ud68c\uc758\ub294 \ub2e4\uc74c \uc8fc \uc218\uc694\uc77c \uc624\ud6c4 2\uc2dc\uc5d0 \ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\"\"\"\n\nprint(\"\ud83d\udccb \ud68c\uc758\ub85d \uc694\uc57d:\")\nmeeting_summary = meeting_summarizer.summarize_meeting(meeting_transcript)\nprint(meeting_summary)\n\nprint(\"\\n\u2705 \uc561\uc158 \uc544\uc774\ud15c:\")\nactions = meeting_summarizer.extract_action_items(meeting_transcript)\nprint(actions)\n</code></pre>"},{"location":"examples/02-everyday-tasks/summarizer/#3","title":"3. \ud559\uc220 \ub17c\ubb38 \uc694\uc57d\uae30","text":"<pre><code>class AcademicSummarizer(AdvancedSummarizer):\n    \"\"\"\ud559\uc220 \ub17c\ubb38 \uc694\uc57d \ub3c4\uad6c\"\"\"\n\n    def summarize_paper(self, paper_text):\n        \"\"\"\ub17c\ubb38\uc744 \uc694\uc57d\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud559\uc220 \ub17c\ubb38\uc744 \uc694\uc57d\ud574\uc8fc\uc138\uc694:\n\n        {paper_text}\n\n        \ub2e4\uc74c \uad6c\uc870\ub85c \uc694\uc57d\ud574\uc8fc\uc138\uc694:\n\n        \ud83d\udcda \uc81c\ubaa9:\n\n        \ud83c\udfaf \uc5f0\uad6c \ubaa9\uc801:\n        (\uc774 \uc5f0\uad6c\uac00 \ud574\uacb0\ud558\ub824\ub294 \ubb38\uc81c)\n\n        \ud83d\udd2c \ubc29\ubc95\ub860:\n        (\uc5b4\ub5bb\uac8c \uc5f0\uad6c\ud588\ub294\uc9c0)\n\n        \ud83d\udcca \uc8fc\uc694 \uacb0\uacfc:\n        \u2022 \ubc1c\uacac 1\n        \u2022 \ubc1c\uacac 2\n\n        \ud83d\udca1 \uacb0\ub860:\n        (\uc5f0\uad6c\uc758 \uc758\ubbf8\uc640 \uae30\uc5ec)\n\n        \ud83d\udd0d \ud55c\uacc4\uc810:\n        (\uc5f0\uad6c\uc758 \uc81c\ud55c\uc0ac\ud56d)\n\n        \ud83d\udcd6 \ud575\uc2ec \ud0a4\uc6cc\ub4dc:\n        #\ud0a4\uc6cc\ub4dc1 #\ud0a4\uc6cc\ub4dc2 #\ud0a4\uc6cc\ub4dc3\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def create_literature_review(self, papers):\n        \"\"\"\uc5ec\ub7ec \ub17c\ubb38\uc744 \uc885\ud569\ud55c \ubb38\ud5cc \uac80\ud1a0\ub97c \uc791\uc131\ud569\ub2c8\ub2e4\"\"\"\n        prompt = \"\ub2e4\uc74c \ub17c\ubb38\ub4e4\uc744 \uc885\ud569\ud558\uc5ec \ubb38\ud5cc \uac80\ud1a0\ub97c \uc791\uc131\ud574\uc8fc\uc138\uc694:\\n\\n\"\n\n        for i, paper in enumerate(papers, 1):\n            prompt += f\"\ub17c\ubb38 {i}:\\n{paper['title']}\\n{paper['summary']}\\n\\n\"\n\n        prompt += \"\"\"\n        \ubb38\ud5cc \uac80\ud1a0 \ud615\uc2dd:\n        1. \uc5f0\uad6c \ub3d9\ud5a5\n        2. \uc8fc\uc694 \ubc1c\uacac\uc0ac\ud56d\n        3. \uc5f0\uad6c \uac04 \uacf5\ud1b5\uc810\uacfc \ucc28\uc774\uc810\n        4. \ud5a5\ud6c4 \uc5f0\uad6c \ubc29\ud5a5\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nacademic_summarizer = AcademicSummarizer()\n\n# \ub17c\ubb38 \uc694\uc57d (\uc608\uc2dc)\npaper_abstract = \"\"\"\nThis study investigates the impact of artificial intelligence on workplace productivity. \nUsing a mixed-methods approach, we surveyed 500 companies and conducted in-depth \ninterviews with 50 managers. Our findings show that AI implementation led to an \naverage 25% increase in productivity, particularly in data analysis and customer \nservice tasks. However, we also identified challenges including employee resistance \nand the need for extensive training. The study concludes that successful AI adoption \nrequires careful change management and continuous learning programs.\n\"\"\"\n\nprint(\"\ud83c\udf93 \ub17c\ubb38 \uc694\uc57d:\")\npaper_summary = academic_summarizer.summarize_paper(paper_abstract)\nprint(paper_summary)\n</code></pre>"},{"location":"examples/02-everyday-tasks/summarizer/#_5","title":"\ud83d\udcca \uc694\uc57d \ud488\uc9c8 \ud3c9\uac00\uae30","text":"<pre><code>class SummaryEvaluator(TextSummarizer):\n    \"\"\"\uc694\uc57d \ud488\uc9c8\uc744 \ud3c9\uac00\ud558\ub294 \ub3c4\uad6c\"\"\"\n\n    def evaluate_summary(self, original, summary):\n        \"\"\"\uc694\uc57d\uc758 \ud488\uc9c8\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \uc6d0\ubb38\uacfc \uc694\uc57d\uc744 \ube44\uad50\ud558\uc5ec \uc694\uc57d\uc758 \ud488\uc9c8\uc744 \ud3c9\uac00\ud574\uc8fc\uc138\uc694.\n\n        \uc6d0\ubb38:\n        {original}\n\n        \uc694\uc57d:\n        {summary}\n\n        \ub2e4\uc74c \uae30\uc900\uc73c\ub85c \ud3c9\uac00\ud574\uc8fc\uc138\uc694 (\uac01 \ud56d\ubaa9 1-10\uc810):\n        1. \uc815\ud655\uc131: \uc6d0\ubb38\uc758 \ub0b4\uc6a9\uc744 \uc815\ud655\ud788 \ubc18\uc601\ud588\ub294\uac00?\n        2. \uc644\uc804\uc131: \uc911\uc694\ud55c \uc815\ubcf4\uac00 \ube60\uc9c0\uc9c0 \uc54a\uc558\ub294\uac00?\n        3. \uac04\uacb0\uc131: \ubd88\ud544\uc694\ud55c \ub0b4\uc6a9 \uc5c6\uc774 \uac04\uacb0\ud55c\uac00?\n        4. \uac00\ub3c5\uc131: \uc77d\uae30 \uc27d\uace0 \uc774\ud574\ud558\uae30 \uc26c\uc6b4\uac00?\n        5. \uc77c\uad00\uc131: \ub17c\ub9ac\uc801 \ud750\ub984\uc774 \uc77c\uad00\ub418\ub294\uac00?\n\n        \uac01 \uc810\uc218\uc640 \ucd1d\ud3c9\uc744 \uc81c\uacf5\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def compare_summaries(self, original, summaries):\n        \"\"\"\uc5ec\ub7ec \uc694\uc57d\uc744 \ube44\uad50\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\uc6d0\ubb38:\\n{original}\\n\\n\"\n\n        for i, summary in enumerate(summaries, 1):\n            prompt += f\"\uc694\uc57d {i}:\\n{summary}\\n\\n\"\n\n        prompt += \"\"\"\n        \uc704 \uc694\uc57d\ub4e4\uc744 \ube44\uad50\ud558\uc5ec \uc5b4\ub5a4 \uc694\uc57d\uc774 \uac00\uc7a5 \uc88b\uc740\uc9c0 \ud3c9\uac00\ud574\uc8fc\uc138\uc694.\n        \uac01 \uc694\uc57d\uc758 \uc7a5\ub2e8\uc810\uc744 \ubd84\uc11d\ud558\uace0 \uc21c\uc704\ub97c \ub9e4\uaca8\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nevaluator = SummaryEvaluator()\n\n# \uc6d0\ubb38\noriginal = \"AI\ub294 \uc778\uac04\uc758 \uc9c0\ub2a5\uc744 \ubaa8\ubc29\ud55c \uae30\uc220\ub85c, \ucd5c\uadfc \uae09\uc18d\ud788 \ubc1c\uc804\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4...\"\n\n# \ub2e4\uc591\ud55c \uc694\uc57d \uc0dd\uc131\nsummary1 = summarizer.summarize(original, 50)\nsummary2 = summarizer.one_line_summary(original)\n\n# \uc694\uc57d \ud3c9\uac00\nprint(\"\ud83d\udcca \uc694\uc57d \ud488\uc9c8 \ud3c9\uac00:\")\nevaluation = evaluator.evaluate_summary(original, summary1)\nprint(evaluation)\n\n# \uc694\uc57d \ube44\uad50\nprint(\"\\n\ud83d\udd0d \uc694\uc57d \ube44\uad50:\")\ncomparison = evaluator.compare_summaries(original, [summary1, summary2])\nprint(comparison)\n</code></pre>"},{"location":"examples/02-everyday-tasks/summarizer/#_6","title":"\ud83d\ude80 \ud1b5\ud569 \uc694\uc57d \uc2dc\uc2a4\ud15c","text":"<pre><code>class IntegratedSummarizer:\n    \"\"\"\ub2e4\uc591\ud55c \uc694\uc57d \uae30\ub2a5\uc744 \ud1b5\ud569\ud55c \uc2dc\uc2a4\ud15c\"\"\"\n\n    def __init__(self):\n        self.general = TextSummarizer()\n        self.news = NewsArticleSummarizer()\n        self.meeting = MeetingSummarizer()\n        self.academic = AcademicSummarizer()\n\n    def auto_summarize(self, text, text_type=\"auto\"):\n        \"\"\"\ud14d\uc2a4\ud2b8 \uc720\ud615\uc744 \uc790\ub3d9 \uac10\uc9c0\ud558\uc5ec \uc694\uc57d\ud569\ub2c8\ub2e4\"\"\"\n        if text_type == \"auto\":\n            # \ud14d\uc2a4\ud2b8 \uc720\ud615 \uc790\ub3d9 \uac10\uc9c0\n            text_type = self._detect_text_type(text)\n\n        # \uc720\ud615\ubcc4 \uc694\uc57d \uc218\ud589\n        if text_type == \"news\":\n            return self.news.summarize_news(text)\n        elif text_type == \"meeting\":\n            return self.meeting.summarize_meeting(text)\n        elif text_type == \"academic\":\n            return self.academic.summarize_paper(text)\n        else:\n            return self.general.summarize(text)\n\n    def _detect_text_type(self, text):\n        \"\"\"\ud14d\uc2a4\ud2b8 \uc720\ud615\uc744 \uac10\uc9c0\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\uc758 \uc720\ud615\uc744 \ud310\ub2e8\ud574\uc8fc\uc138\uc694:\n\n        {text[:500]}...\n\n        \ub2e4\uc74c \uc911 \ud558\ub098\ub85c\ub9cc \ub2f5\ud574\uc8fc\uc138\uc694:\n        - news (\ub274\uc2a4 \uae30\uc0ac)\n        - meeting (\ud68c\uc758\ub85d)\n        - academic (\ud559\uc220 \ub17c\ubb38)\n        - general (\uc77c\ubc18 \ud14d\uc2a4\ud2b8)\n        \"\"\"\n\n        response = self.general.ai.ask(prompt)\n        return response.text.strip().lower()\n\n    def batch_summarize(self, texts, output_format=\"markdown\"):\n        \"\"\"\uc5ec\ub7ec \ud14d\uc2a4\ud2b8\ub97c \uc77c\uad04 \uc694\uc57d\ud569\ub2c8\ub2e4\"\"\"\n        results = []\n\n        for i, text in enumerate(texts, 1):\n            print(f\"\uc694\uc57d \uc911... ({i}/{len(texts)})\")\n\n            # \uc790\ub3d9 \uc694\uc57d\n            summary = self.auto_summarize(text)\n\n            # \uacb0\uacfc \uc800\uc7a5\n            results.append({\n                \"index\": i,\n                \"original_length\": len(text),\n                \"summary\": summary,\n                \"reduction_rate\": f\"{(1 - len(summary)/len(text))*100:.1f}%\"\n            })\n\n        # \uacb0\uacfc \ud3ec\ub9f7\ud305\n        if output_format == \"markdown\":\n            return self._format_markdown(results)\n        else:\n            return results\n\n    def _format_markdown(self, results):\n        \"\"\"\uacb0\uacfc\ub97c \ub9c8\ud06c\ub2e4\uc6b4\uc73c\ub85c \ud3ec\ub9f7\ud305\ud569\ub2c8\ub2e4\"\"\"\n        output = \"# \uc694\uc57d \uacb0\uacfc\\n\\n\"\n\n        for r in results:\n            output += f\"## \ubb38\uc11c {r['index']}\\n\"\n            output += f\"- \uc6d0\ubb38 \uae38\uc774: {r['original_length']}\uc790\\n\"\n            output += f\"- \uc555\ucd95\ub960: {r['reduction_rate']}\\n\\n\"\n            output += f\"### \uc694\uc57d\\n{r['summary']}\\n\\n\"\n            output += \"---\\n\\n\"\n\n        return output\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nintegrated = IntegratedSummarizer()\n\n# \uc790\ub3d9 \uc694\uc57d\nprint(\"\ud83e\udd16 \uc790\ub3d9 \uc694\uc57d:\")\nauto_summary = integrated.auto_summarize(news_article)\nprint(auto_summary)\n\n# \uc77c\uad04 \uc694\uc57d\nprint(\"\\n\ud83d\udce6 \uc77c\uad04 \uc694\uc57d:\")\ntexts = [news_article, meeting_transcript, paper_abstract]\nbatch_results = integrated.batch_summarize(texts)\nprint(batch_results)\n</code></pre>"},{"location":"examples/02-everyday-tasks/summarizer/#_7","title":"\u2705 \ud575\uc2ec \uc815\ub9ac","text":"<ol> <li>\ub2e4\uc591\ud55c \uc694\uc57d \ubc29\uc2dd - \uc77c\ubc18, \ud575\uc2ec \ud3ec\uc778\ud2b8, \ud55c \uc904 \uc694\uc57d</li> <li>\ud2b9\ud654\ub41c \uc694\uc57d - \ub274\uc2a4, \ud68c\uc758\ub85d, \ub17c\ubb38\ubcc4 \uc804\ubb38 \uc694\uc57d</li> <li>\uc694\uc57d \ud488\uc9c8 \ud3c9\uac00 - \uc815\ud655\uc131, \uc644\uc804\uc131, \uac04\uacb0\uc131 \ud3c9\uac00</li> <li>\ud1b5\ud569 \uc2dc\uc2a4\ud15c - \uc790\ub3d9 \uac10\uc9c0 \ubc0f \uc77c\uad04 \ucc98\ub9ac</li> </ol>"},{"location":"examples/02-everyday-tasks/summarizer/#_8","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>\uc77c\uc0c1 \uc791\uc5c5 \uc790\ub3d9\ud654 \ub3c4\uad6c\ub4e4\uc744 \ubaa8\ub450 \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4! \uc774\uc81c \ub300\ud654 \uc774\uc5b4\uac00\uae30\ub85c \ub118\uc5b4\uac00 \ub354 \ubcf5\uc7a1\ud55c \ub300\ud654\ud615 AI\ub97c \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/02-everyday-tasks/text-improver/","title":"\u270f\ufe0f \ud14d\uc2a4\ud2b8 \uac1c\uc120 \ub3c4\uad6c \ub9cc\ub4e4\uae30","text":"<p>\ub9de\ucda4\ubc95 \uac80\uc0ac, \ubb38\ubc95 \uad50\uc815, \ubb38\uccb4 \uac1c\uc120\uae4c\uc9c0! AI\ub97c \ud65c\uc6a9\ud55c \uae00\uc4f0\uae30 \ub3c4\uc6b0\ubbf8\ub97c \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4.</p>"},{"location":"examples/02-everyday-tasks/text-improver/#_2","title":"\ud83c\udfaf \ub9cc\ub4e4 \uac83","text":"<pre><code>\uc6d0\ubb38: \uc624\ub298 \ud68c\uc758\uc5d0\uc11c \ub17c\uc758\ud55c \ub0b4\uc6a9\uc744 \uc815\ub9ac\ud558\uba74 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4 \ub9e4\ucd9c\uc774 \uc804\ub144\ub300\ube44 20% \uc99d\uac00\ud588\uad6c\uc694...\n\n\uac1c\uc120: \uc624\ub298 \ud68c\uc758\uc5d0\uc11c \ub17c\uc758\ud55c \ub0b4\uc6a9\uc744 \uc815\ub9ac\ud558\uba74 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4. \ub9e4\ucd9c\uc774 \uc804\ub144 \ub300\ube44 20% \uc99d\uac00\ud588\uace0...\n</code></pre>"},{"location":"examples/02-everyday-tasks/text-improver/#_3","title":"\ud83d\udcdd \uae30\ubcf8 \ud14d\uc2a4\ud2b8 \uac1c\uc120\uae30","text":""},{"location":"examples/02-everyday-tasks/text-improver/#step-1","title":"Step 1: \ub9de\ucda4\ubc95\uacfc \ubb38\ubc95 \uac80\uc0ac\uae30","text":"<pre><code># text_improver.py\nfrom pyhub.llm import LLM\n\nclass TextImprover:\n    \"\"\"\ud14d\uc2a4\ud2b8\ub97c \uac1c\uc120\ud558\ub294 AI \ub3c4\uad6c\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.ai = LLM.create(model)\n\n    def check_spelling_grammar(self, text):\n        \"\"\"\ub9de\ucda4\ubc95\uacfc \ubb38\ubc95\uc744 \uac80\uc0ac\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\uc758 \ub9de\ucda4\ubc95\uacfc \ubb38\ubc95\uc744 \uac80\uc0ac\ud574\uc8fc\uc138\uc694.\n        \ud2c0\ub9b0 \ubd80\ubd84\ub9cc \uc218\uc815\ud558\uace0, \uc6d0\ubb38\uc758 \uc758\ubbf8\uc640 \uc2a4\ud0c0\uc77c\uc740 \uc720\uc9c0\ud574\uc8fc\uc138\uc694.\n\n        \uc6d0\ubb38:\n        {text}\n\n        \uc218\uc815\ub41c \ud14d\uc2a4\ud2b8\ub9cc \ucd9c\ub825\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def show_corrections(self, text):\n        \"\"\"\uc218\uc815 \uc0ac\ud56d\uc744 \uc790\uc138\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\uc758 \ub9de\ucda4\ubc95\uacfc \ubb38\ubc95 \uc624\ub958\ub97c \ucc3e\uc544\uc8fc\uc138\uc694.\n        \uac01 \uc624\ub958\uc5d0 \ub300\ud574 \uc124\uba85\ub3c4 \ud568\uaed8 \uc81c\uacf5\ud574\uc8fc\uc138\uc694.\n\n        \ud14d\uc2a4\ud2b8:\n        {text}\n\n        \ub2e4\uc74c \ud615\uc2dd\uc73c\ub85c \ub2f5\ud574\uc8fc\uc138\uc694:\n        1. [\uc624\ub958 \ubd80\ubd84] \u2192 [\uc218\uc815\uc548]: \uc124\uba85\n        2. [\uc624\ub958 \ubd80\ubd84] \u2192 [\uc218\uc815\uc548]: \uc124\uba85\n        ...\n\n        \uc624\ub958\uac00 \uc5c6\ub2e4\uba74 \"\uc624\ub958\uac00 \uc5c6\uc2b5\ub2c8\ub2e4\"\ub77c\uace0 \ub2f5\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nimprover = TextImprover()\n\n# \ud14c\uc2a4\ud2b8 \ud14d\uc2a4\ud2b8\ntext = \"\"\"\n\uc548\ub155\ud558\uc138\uc694 \uc5ec\ub7ec\ubd84 \uc624\ub298\uc740 \ud30c\uc774\uc36c\uc73c\ub85c \ud14d\uc2a4\ud2b8\ub97c \uac1c\uc120\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud574 \uc54c\uc544\ubcf4\uaca0\uc2b5\ub2c8\ub2e4\n\ub9ce\uc740 \ubd84\ub4e4\uc774 \uae00\uc4f0\uae30\ub97c \uc5b4\ub824\uc6cc \ud558\uc2dc\ub294\ub300 AI\ub97c \ud65c\uc6a9\ud558\uba74 \uc27d\uac8c \uac1c\uc120\ud560\uc218 \uc788\uc2b5\ub2c8\ub2e4\n\"\"\"\n\n# \ub9de\ucda4\ubc95 \uac80\uc0ac\nprint(\"\ud83d\udcdd \uc6d0\ubb38:\")\nprint(text)\n\nprint(\"\\n\u2705 \uc218\uc815\ub41c \ud14d\uc2a4\ud2b8:\")\ncorrected = improver.check_spelling_grammar(text)\nprint(corrected)\n\nprint(\"\\n\ud83d\udd0d \uc218\uc815 \uc0ac\ud56d \uc124\uba85:\")\ncorrections = improver.show_corrections(text)\nprint(corrections)\n</code></pre>"},{"location":"examples/02-everyday-tasks/text-improver/#step-2","title":"Step 2: \ubb38\uccb4 \uac1c\uc120\uae30","text":"<pre><code>class StyleImprover(TextImprover):\n    \"\"\"\ubb38\uccb4\ub97c \uac1c\uc120\ud558\ub294 AI \ub3c4\uad6c\"\"\"\n\n    def improve_style(self, text, style=\"formal\"):\n        \"\"\"\ubb38\uccb4\ub97c \uac1c\uc120\ud569\ub2c8\ub2e4\"\"\"\n        style_guides = {\n            \"formal\": \"\uaca9\uc2dd\uc788\uace0 \uc804\ubb38\uc801\uc778 \ubb38\uccb4\",\n            \"casual\": \"\uce5c\uadfc\ud558\uace0 \ud3b8\uc548\ud55c \ubb38\uccb4\",\n            \"academic\": \"\ud559\uc220\uc801\uc774\uace0 \uac1d\uad00\uc801\uc778 \ubb38\uccb4\",\n            \"business\": \"\ube44\uc988\ub2c8\uc2a4\uc5d0 \uc801\ud569\ud55c \uac04\uacb0\ud55c \ubb38\uccb4\"\n        }\n\n        style_desc = style_guides.get(style, style)\n\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c {style_desc}\ub85c \uac1c\uc120\ud574\uc8fc\uc138\uc694.\n        \ub0b4\uc6a9\uc740 \uc720\uc9c0\ud558\ub418 \ud45c\ud604 \ubc29\uc2dd\ub9cc \ubc14\uafd4\uc8fc\uc138\uc694.\n\n        \uc6d0\ubb38:\n        {text}\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def simplify(self, text):\n        \"\"\"\ubcf5\uc7a1\ud55c \ubb38\uc7a5\uc744 \uc27d\uac8c \ub9cc\ub4ed\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c \ub354 \uc27d\uace0 \uba85\ud655\ud558\uac8c \ub2e4\uc2dc \uc368\uc8fc\uc138\uc694.\n        - \uae34 \ubb38\uc7a5\uc740 \uc9e7\uac8c \ub098\ub204\uae30\n        - \uc5b4\ub824\uc6b4 \ub2e8\uc5b4\ub294 \uc26c\uc6b4 \ub2e8\uc5b4\ub85c\n        - \ubcf5\uc7a1\ud55c \uad6c\uc870\ub294 \ub2e8\uc21c\ud558\uac8c\n\n        \uc6d0\ubb38:\n        {text}\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def make_concise(self, text):\n        \"\"\"\uac04\uacb0\ud558\uac8c \ub9cc\ub4ed\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c \ub354 \uac04\uacb0\ud558\uac8c \ub9cc\ub4e4\uc5b4\uc8fc\uc138\uc694.\n        \ud575\uc2ec \ub0b4\uc6a9\uc740 \ubaa8\ub450 \uc720\uc9c0\ud558\uba74\uc11c \ubd88\ud544\uc694\ud55c \ud45c\ud604\ub9cc \uc81c\uac70\ud574\uc8fc\uc138\uc694.\n\n        \uc6d0\ubb38:\n        {text}\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nstyle_improver = StyleImprover()\n\n# \uc6d0\ubcf8 \ud14d\uc2a4\ud2b8\noriginal = \"\"\"\n\uc81c\uac00 \uc0dd\uac01\ud558\uae30\uc5d0\ub294 \uc774\ubc88 \ud504\ub85c\uc81d\ud2b8\uac00 \uc131\uacf5\uc801\uc73c\ub85c \uc644\ub8cc\ub418\uae30 \uc704\ud574\uc11c\ub294 \n\ud300\uc6d0\ub4e4 \uac04\uc758 \uc6d0\ud65c\ud55c \uc18c\ud1b5\uc774 \ub9e4\uc6b0 \uc911\uc694\ud558\ub2e4\uace0 \ubd05\ub2c8\ub2e4. \n\uac01\uc790\uc758 \uc758\uacac\uc744 \uc790\uc720\ub86d\uac8c \ud45c\ud604\ud560 \uc218 \uc788\ub294 \ubd84\uc704\uae30\ub97c \ub9cc\ub4e4\uc5b4\uc57c \ud560 \uac83 \uac19\uc2b5\ub2c8\ub2e4.\n\"\"\"\n\nprint(\"\ud83c\udfa8 \ubb38\uccb4 \ubcc0\ud658 \uc608\uc2dc:\\n\")\n\n# \ub2e4\uc591\ud55c \ubb38\uccb4\ub85c \ubcc0\ud658\nstyles = [\"formal\", \"casual\", \"business\"]\nfor style in styles:\n    print(f\"### {style.upper()} \uc2a4\ud0c0\uc77c:\")\n    result = style_improver.improve_style(original, style)\n    print(result)\n    print()\n\n# \ubb38\uc7a5 \ub2e8\uc21c\ud654\nprint(\"### \ub2e8\uc21c\ud654:\")\nsimplified = style_improver.simplify(original)\nprint(simplified)\n\n# \uac04\uacb0\ud654\nprint(\"\\n### \uac04\uacb0\ud654:\")\nconcise = style_improver.make_concise(original)\nprint(concise)\n</code></pre>"},{"location":"examples/02-everyday-tasks/text-improver/#_4","title":"\ud83c\udfaf \uc2e4\uc6a9\uc801\uc778 \uae00\uc4f0\uae30 \ub3c4\uad6c","text":""},{"location":"examples/02-everyday-tasks/text-improver/#1","title":"1. \uc774\uba54\uc77c \uc791\uc131 \ub3c4\uc6b0\ubbf8","text":"<pre><code>class EmailWriter(TextImprover):\n    \"\"\"\uc774\uba54\uc77c \uc791\uc131\uc744 \ub3c4\uc640\uc8fc\ub294 AI\"\"\"\n\n    def write_email(self, purpose, key_points, tone=\"professional\"):\n        \"\"\"\uc774\uba54\uc77c \ucd08\uc548\uc744 \uc791\uc131\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \uc815\ubcf4\ub97c \ubc14\ud0d5\uc73c\ub85c \uc774\uba54\uc77c\uc744 \uc791\uc131\ud574\uc8fc\uc138\uc694:\n\n        \ubaa9\uc801: {purpose}\n        \uc8fc\uc694 \ub0b4\uc6a9: {key_points}\n        \ud1a4: {tone}\n\n        \ud55c\uad6d \ube44\uc988\ub2c8\uc2a4 \uc774\uba54\uc77c \ud615\uc2dd\uc5d0 \ub9de\ucdb0 \uc791\uc131\ud574\uc8fc\uc138\uc694.\n        (\uc778\uc0ac\ub9d0 - \ubcf8\ubb38 - \ub9c8\ubb34\ub9ac \uc778\uc0ac)\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def improve_email(self, draft):\n        \"\"\"\uc774\uba54\uc77c \ucd08\uc548\uc744 \uac1c\uc120\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \uc774\uba54\uc77c \ucd08\uc548\uc744 \uac1c\uc120\ud574\uc8fc\uc138\uc694:\n        - \ub354 \uba85\ud655\ud558\uace0 \uc804\ubb38\uc801\uc73c\ub85c\n        - \uc608\uc758\ubc14\ub974\uace0 \uc815\uc911\ud558\uac8c\n        - \ud575\uc2ec \uba54\uc2dc\uc9c0\uac00 \uc798 \uc804\ub2ec\ub418\ub3c4\ub85d\n\n        \ucd08\uc548:\n        {draft}\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def create_response(self, original_email, response_type=\"accept\"):\n        \"\"\"\uc774\uba54\uc77c \ub2f5\uc7a5\uc744 \uc791\uc131\ud569\ub2c8\ub2e4\"\"\"\n        response_guides = {\n            \"accept\": \"\uae0d\uc815\uc801\uc73c\ub85c \uc218\ub77d\ud558\ub294\",\n            \"decline\": \"\uc815\uc911\ud558\uac8c \uac70\uc808\ud558\ub294\",\n            \"request_info\": \"\ucd94\uac00 \uc815\ubcf4\ub97c \uc694\uccad\ud558\ub294\",\n            \"follow_up\": \"\ud6c4\uc18d \uc870\uce58\ub97c \uc548\ub0b4\ud558\ub294\"\n        }\n\n        guide = response_guides.get(response_type, response_type)\n\n        prompt = f\"\"\"\n        \ub2e4\uc74c \uc774\uba54\uc77c\uc5d0 \ub300\ud574 {guide} \ub2f5\uc7a5\uc744 \uc791\uc131\ud574\uc8fc\uc138\uc694:\n\n        \uc6d0\ubcf8 \uc774\uba54\uc77c:\n        {original_email}\n\n        \uc815\uc911\ud558\uace0 \uc804\ubb38\uc801\uc778 \ud1a4\uc73c\ub85c \uc791\uc131\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nemail_writer = EmailWriter()\n\n# \uc774\uba54\uc77c \uc791\uc131\nprint(\"\ud83d\udce7 \uc774\uba54\uc77c \ucd08\uc548 \uc791\uc131:\")\nemail = email_writer.write_email(\n    purpose=\"\ud504\ub85c\uc81d\ud2b8 \uc9c4\ud589 \uc0c1\ud669 \ubcf4\uace0\",\n    key_points=\"1\ub2e8\uacc4 \uc644\ub8cc, 2\ub2e8\uacc4 \uc9c4\ud589 \uc911 (70%), \uc608\uc0c1 \uc644\ub8cc\uc77c 12\uc6d4 15\uc77c\",\n    tone=\"professional\"\n)\nprint(email)\n\n# \uc774\uba54\uc77c \uac1c\uc120\nprint(\"\\n\ud83d\udcdd \uc774\uba54\uc77c \uac1c\uc120:\")\ndraft = \"\"\"\n\uc548\ub155\ud558\uc138\uc694 \uae40\ubd80\uc7a5\ub2d8\n\ud504\ub85c\uc81d\ud2b8 \uad00\ub828\ud574\uc11c \ub9d0\uc500\ub4dc\ub9bd\ub2c8\ub2e4\n1\ub2e8\uacc4\ub294 \ub05d\ub0ac\uace0 2\ub2e8\uacc4 \ud558\uace0\uc788\uc2b5\ub2c8\ub2e4\n12\uc6d4 15\uc77c\ucbe4 \ub05d\ub0a0\uac83 \uac19\uc2b5\ub2c8\ub2e4\n\"\"\"\nimproved = email_writer.improve_email(draft)\nprint(improved)\n\n# \ub2f5\uc7a5 \uc791\uc131\nprint(\"\\n\ud83d\udc8c \ub2f5\uc7a5 \uc791\uc131:\")\noriginal = \"\"\"\n\uc548\ub155\ud558\uc138\uc694,\n\ub2e4\uc74c \uc8fc \ud654\uc694\uc77c \uc624\ud6c4 2\uc2dc\uc5d0 \ubbf8\ud305\uc774 \uac00\ub2a5\ud558\uc2e0\uc9c0 \ud655\uc778 \ubd80\ud0c1\ub4dc\ub9bd\ub2c8\ub2e4.\n\ud504\ub85c\uc81d\ud2b8 \uc9c4\ud589 \uc0c1\ud669\uc5d0 \ub300\ud574 \ub17c\uc758\ud558\uace0\uc790 \ud569\ub2c8\ub2e4.\n\"\"\"\nreply = email_writer.create_response(original, \"accept\")\nprint(reply)\n</code></pre>"},{"location":"examples/02-everyday-tasks/text-improver/#2","title":"2. \ubcf4\uace0\uc11c \uc791\uc131 \ub3c4\uc6b0\ubbf8","text":"<pre><code>class ReportWriter(TextImprover):\n    \"\"\"\ubcf4\uace0\uc11c \uc791\uc131\uc744 \ub3c4\uc640\uc8fc\ub294 AI\"\"\"\n\n    def create_outline(self, topic, report_type=\"general\"):\n        \"\"\"\ubcf4\uace0\uc11c \uac1c\uc694\ub97c \uc791\uc131\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        '{topic}'\uc5d0 \ub300\ud55c {report_type} \ubcf4\uace0\uc11c\uc758 \uac1c\uc694\ub97c \uc791\uc131\ud574\uc8fc\uc138\uc694.\n\n        \ub2e4\uc74c \ud615\uc2dd\uc73c\ub85c \uc791\uc131\ud574\uc8fc\uc138\uc694:\n        1. \uc81c\ubaa9\n        2. \ubaa9\ucc28 (\ub300\uc81c\ubaa9\uacfc \uc18c\uc81c\ubaa9)\n        3. \uac01 \uc139\uc158\ubcc4 \uc8fc\uc694 \ub0b4\uc6a9 \uc694\uc57d\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def write_summary(self, content, max_length=200):\n        \"\"\"\uc694\uc57d\ubb38\uc744 \uc791\uc131\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ub0b4\uc6a9\uc744 {max_length}\uc790 \uc774\ub0b4\ub85c \uc694\uc57d\ud574\uc8fc\uc138\uc694.\n        \ud575\uc2ec \uc815\ubcf4\ub9cc \ud3ec\ud568\ud558\uace0 \uba85\ud655\ud558\uac8c \uc791\uc131\ud574\uc8fc\uc138\uc694.\n\n        \ub0b4\uc6a9:\n        {content}\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def improve_paragraph(self, paragraph, focus=\"clarity\"):\n        \"\"\"\ubb38\ub2e8\uc744 \uac1c\uc120\ud569\ub2c8\ub2e4\"\"\"\n        focus_guides = {\n            \"clarity\": \"\uba85\ud655\uc131\uc744 \ub192\uc774\ub3c4\ub85d\",\n            \"flow\": \"\ubb38\uc7a5 \ud750\ub984\uc774 \uc790\uc5f0\uc2a4\ub7fd\ub3c4\ub85d\",\n            \"evidence\": \"\uadfc\uac70\uc640 \uc608\uc2dc\ub97c \ucd94\uac00\ud558\ub3c4\ub85d\",\n            \"impact\": \"\uc124\ub4dd\ub825\uc744 \ub192\uc774\ub3c4\ub85d\"\n        }\n\n        guide = focus_guides.get(focus, focus)\n\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ubb38\ub2e8\uc744 {guide} \uac1c\uc120\ud574\uc8fc\uc138\uc694:\n\n        {paragraph}\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nreport_writer = ReportWriter()\n\n# \ubcf4\uace0\uc11c \uac1c\uc694 \uc791\uc131\nprint(\"\ud83d\udccb \ubcf4\uace0\uc11c \uac1c\uc694:\")\noutline = report_writer.create_outline(\n    topic=\"\uc6d0\uaca9 \uadfc\ubb34\uc758 \uc0dd\uc0b0\uc131 \uc601\ud5a5\",\n    report_type=\"\ubd84\uc11d\"\n)\nprint(outline)\n\n# \uc694\uc57d\ubb38 \uc791\uc131\nprint(\"\\n\ud83d\udcc4 \uc694\uc57d\ubb38 \uc791\uc131:\")\nlong_content = \"\"\"\n\ucd5c\uadfc 3\uac1c\uc6d4\uac04\uc758 \uc6d0\uaca9 \uadfc\ubb34 \uc2e4\uc2dc \uacb0\uacfc, \uc9c1\uc6d0\ub4e4\uc758 \ub9cc\uc871\ub3c4\ub294 85%\ub85c \ub9e4\uc6b0 \ub192\uac8c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4.\n\uc0dd\uc0b0\uc131 \uc9c0\ud45c\ub97c \ubd84\uc11d\ud55c \uacb0\uacfc, \uac1c\uc778 \uc5c5\ubb34\uc758 \uacbd\uc6b0 \ud3c9\uade0 15% \ud5a5\uc0c1\ub418\uc5c8\uc73c\ub098,\n\ud300 \ud611\uc5c5\uc774 \ud544\uc694\ud55c \ud504\ub85c\uc81d\ud2b8\uc758 \uacbd\uc6b0 \uc57d 10% \uac10\uc18c\ud55c \uac83\uc73c\ub85c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4.\n\uc774\ub294 \ub300\uba74 \uc18c\ud1b5\uc758 \ubd80\uc7ac\ub85c \uc778\ud55c \uac83\uc73c\ub85c \ubd84\uc11d\ub418\uba70, \n\uc628\ub77c\uc778 \ud611\uc5c5 \ub3c4\uad6c\uc758 \uc801\uadf9\uc801\uc778 \ud65c\uc6a9\uacfc \uc8fc\uae30\uc801\uc778 \ud300 \ubbf8\ud305\uc744 \ud1b5\ud574 \uac1c\uc120\uc774 \uac00\ub2a5\ud560 \uac83\uc73c\ub85c \ubcf4\uc785\ub2c8\ub2e4.\n\"\"\"\nsummary = report_writer.write_summary(long_content, max_length=100)\nprint(summary)\n\n# \ubb38\ub2e8 \uac1c\uc120\nprint(\"\\n\u2728 \ubb38\ub2e8 \uac1c\uc120:\")\noriginal_paragraph = \"\"\"\n\uc6d0\uaca9 \uadfc\ubb34\ub294 \uc88b\uc740 \uc810\ub3c4 \uc788\uace0 \ub098\uc05c \uc810\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \n\uc9d1\uc5d0\uc11c \uc77c\ud558\ub2c8\uae4c \ud3b8\ud558\uae34 \ud55c\ub370 \uac00\ub054 \uc678\ub86d\uae30\ub3c4 \ud569\ub2c8\ub2e4.\n\"\"\"\nimproved = report_writer.improve_paragraph(original_paragraph, \"impact\")\nprint(improved)\n</code></pre>"},{"location":"examples/02-everyday-tasks/text-improver/#_5","title":"\ud83d\udd27 \uace0\uae09 \uae30\ub2a5","text":""},{"location":"examples/02-everyday-tasks/text-improver/#1_1","title":"1. \ub2e4\uad6d\uc5b4 \uae00\uc4f0\uae30 \ub3c4\uc6b0\ubbf8","text":"<pre><code>class MultilingualWriter(TextImprover):\n    \"\"\"\ub2e4\uad6d\uc5b4 \uae00\uc4f0\uae30\ub97c \uc9c0\uc6d0\ud558\ub294 AI\"\"\"\n\n    def translate_and_improve(self, text, target_lang=\"English\"):\n        \"\"\"\ubc88\uc5ed\ud558\uba74\uc11c \uac1c\uc120\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c {target_lang}\ub85c \ubc88\uc5ed\ud558\uba74\uc11c\n        \ub354 \uc790\uc5f0\uc2a4\ub7fd\uace0 \ud574\ub2f9 \uc5b8\uc5b4\uc758 \uad00\uc6a9\uad6c\ub97c \uc0ac\uc6a9\ud574 \uac1c\uc120\ud574\uc8fc\uc138\uc694:\n\n        {text}\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def check_translation(self, original, translated, source_lang=\"Korean\", target_lang=\"English\"):\n        \"\"\"\ubc88\uc5ed\uc758 \uc815\ud655\uc131\uc744 \uac80\ud1a0\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c {source_lang} \uc6d0\ubb38\uacfc {target_lang} \ubc88\uc5ed\uc744 \ube44\uad50\ud574\uc8fc\uc138\uc694:\n\n        \uc6d0\ubb38: {original}\n        \ubc88\uc5ed: {translated}\n\n        \ud3c9\uac00 \ud56d\ubaa9:\n        1. \uc758\ubbf8 \uc804\ub2ec\uc758 \uc815\ud655\uc131 (1-10\uc810)\n        2. \uc790\uc5f0\uc2a4\ub7ec\uc6c0 (1-10\uc810)\n        3. \uac1c\uc120 \uc81c\uc548\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nmultilingual = MultilingualWriter()\n\nkorean_text = \"\uc774\ubc88 \ud504\ub85c\uc81d\ud2b8\ub97c \ud1b5\ud574 \ub9ce\uc740 \uac83\uc744 \ubc30\uc6e0\uc2b5\ub2c8\ub2e4. \ud2b9\ud788 \ud300\uc6cc\ud06c\uc758 \uc911\uc694\uc131\uc744 \uae68\ub2ec\uc558\uc2b5\ub2c8\ub2e4.\"\n\n# \ubc88\uc5ed \ubc0f \uac1c\uc120\nprint(\"\ud83c\udf0d \ubc88\uc5ed \ubc0f \uac1c\uc120:\")\nenglish = multilingual.translate_and_improve(korean_text, \"English\")\nprint(f\"English: {english}\")\n\njapanese = multilingual.translate_and_improve(korean_text, \"Japanese\")\nprint(f\"\u65e5\u672c\u8a9e: {japanese}\")\n\n# \ubc88\uc5ed \uac80\ud1a0\nprint(\"\\n\ud83d\udd0d \ubc88\uc5ed \ud488\uc9c8 \uac80\ud1a0:\")\nreview = multilingual.check_translation(korean_text, english)\nprint(review)\n</code></pre>"},{"location":"examples/02-everyday-tasks/text-improver/#2-seo","title":"2. SEO \ucd5c\uc801\ud654 \ub3c4\uc6b0\ubbf8","text":"<pre><code>class SEOWriter(TextImprover):\n    \"\"\"SEO\uc5d0 \ucd5c\uc801\ud654\ub41c \uae00\uc4f0\uae30 \ub3c4\uc6b0\ubbf8\"\"\"\n\n    def optimize_for_seo(self, content, keywords):\n        \"\"\"SEO\ub97c \uc704\ud574 \ucf58\ud150\uce20\ub97c \ucd5c\uc801\ud654\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ucf58\ud150\uce20\ub97c SEO\uc5d0 \ucd5c\uc801\ud654\ud574\uc8fc\uc138\uc694:\n\n        \ucf58\ud150\uce20: {content}\n        \ud0c0\uac9f \ud0a4\uc6cc\ub4dc: {keywords}\n\n        \uc694\uad6c\uc0ac\ud56d:\n        - \ud0a4\uc6cc\ub4dc\ub97c \uc790\uc5f0\uc2a4\ub7fd\uac8c \ud3ec\ud568\n        - \uac00\ub3c5\uc131 \uc720\uc9c0\n        - \uc81c\ubaa9\uacfc \uc18c\uc81c\ubaa9 \uad6c\uc870\ud654\n        - \uba54\ud0c0 \uc124\uba85 \uc81c\uc548\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def create_meta_description(self, content, max_length=155):\n        \"\"\"\uba54\ud0c0 \uc124\uba85\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ucf58\ud150\uce20\uc758 \uba54\ud0c0 \uc124\uba85\uc744 {max_length}\uc790 \uc774\ub0b4\ub85c \uc791\uc131\ud574\uc8fc\uc138\uc694.\n        \uac80\uc0c9 \uacb0\uacfc\uc5d0\uc11c \ud074\ub9ad\uc744 \uc720\ub3c4\ud560 \uc218 \uc788\ub3c4\ub85d \ub9e4\ub825\uc801\uc73c\ub85c \uc791\uc131\ud574\uc8fc\uc138\uc694:\n\n        {content}\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nseo_writer = SEOWriter()\n\ncontent = \"\"\"\n\ud30c\uc774\uc36c\uc740 \ubc30\uc6b0\uae30 \uc27d\uace0 \uac15\ub825\ud55c \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\uc785\ub2c8\ub2e4.\n\ucd08\ubcf4\uc790\ub3c4 \uc27d\uac8c \uc2dc\uc791\ud560 \uc218 \uc788\uc73c\uba70, \uc6f9 \uac1c\ubc1c, \ub370\uc774\ud130 \ubd84\uc11d, AI \ub4f1 \ub2e4\uc591\ud55c \ubd84\uc57c\uc5d0\uc11c \ud65c\uc6a9\ub429\ub2c8\ub2e4.\n\"\"\"\n\n# SEO \ucd5c\uc801\ud654\nprint(\"\ud83d\udd0d SEO \ucd5c\uc801\ud654:\")\noptimized = seo_writer.optimize_for_seo(\n    content,\n    keywords=[\"\ud30c\uc774\uc36c \ud504\ub85c\uadf8\ub798\ubc0d\", \"\ud30c\uc774\uc36c \uc785\ubb38\", \"\ud30c\uc774\uc36c \ubc30\uc6b0\uae30\"]\n)\nprint(optimized)\n\n# \uba54\ud0c0 \uc124\uba85 \uc0dd\uc131\nprint(\"\\n\ud83d\udcdd \uba54\ud0c0 \uc124\uba85:\")\nmeta = seo_writer.create_meta_description(content)\nprint(meta)\n</code></pre>"},{"location":"examples/02-everyday-tasks/text-improver/#_6","title":"\ud83d\udcca \uc885\ud569 \ud14d\uc2a4\ud2b8 \ubd84\uc11d\uae30","text":"<pre><code>class TextAnalyzer(TextImprover):\n    \"\"\"\ud14d\uc2a4\ud2b8\ub97c \uc885\ud569\uc801\uc73c\ub85c \ubd84\uc11d\ud558\ub294 \ub3c4\uad6c\"\"\"\n\n    def analyze_text(self, text):\n        \"\"\"\ud14d\uc2a4\ud2b8\ub97c \ub2e4\uac01\ub3c4\ub85c \ubd84\uc11d\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c \ubd84\uc11d\ud574\uc8fc\uc138\uc694:\n\n        {text}\n\n        \ubd84\uc11d \ud56d\ubaa9:\n        1. \ubb38\uccb4\uc640 \ud1a4\n        2. \uac00\ub3c5\uc131 \uc218\uc900 (\ucd08\uae09/\uc911\uae09/\uace0\uae09)\n        3. \uc8fc\uc694 \ud0a4\uc6cc\ub4dc 3\uac1c\n        4. \uac1c\uc120\uc774 \ud544\uc694\ud55c \ubd80\ubd84\n        5. \uc804\uccb4\uc801\uc778 \ud3c9\uac00 (1-10\uc810)\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def compare_texts(self, text1, text2):\n        \"\"\"\ub450 \ud14d\uc2a4\ud2b8\ub97c \ube44\uad50\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ub450 \ud14d\uc2a4\ud2b8\ub97c \ube44\uad50 \ubd84\uc11d\ud574\uc8fc\uc138\uc694:\n\n        \ud14d\uc2a4\ud2b8 1:\n        {text1}\n\n        \ud14d\uc2a4\ud2b8 2:\n        {text2}\n\n        \ube44\uad50 \ud56d\ubaa9:\n        - \ubb38\uccb4\uc640 \ud1a4\uc758 \ucc28\uc774\n        - \uc815\ubcf4 \uc804\ub2ec\uc758 \uba85\ud655\uc131\n        - \uc124\ub4dd\ub825\n        - \uac01\uac01\uc758 \uc7a5\ub2e8\uc810\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nanalyzer = TextAnalyzer()\n\n# \ud14d\uc2a4\ud2b8 \ubd84\uc11d\nsample_text = \"\"\"\n\uc778\uacf5\uc9c0\ub2a5 \uae30\uc220\uc758 \ubc1c\uc804\uc73c\ub85c \uc6b0\ub9ac\uc758 \uc77c\uc0c1\uc0dd\ud65c\uc774 \ud06c\uac8c \ubcc0\ud654\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\uc2a4\ub9c8\ud2b8\ud3f0\uc758 \uc74c\uc131 \ube44\uc11c\ubd80\ud130 \uc790\uc728\uc8fc\ud589 \uc790\ub3d9\ucc28\uae4c\uc9c0, \nAI\ub294 \uc774\ubbf8 \uc6b0\ub9ac \uc0dd\ud65c \uacf3\uacf3\uc5d0 \uc2a4\uba70\ub4e4\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\n\uc774\ub7ec\ud55c \ubcc0\ud654\ub294 \ud3b8\ub9ac\ud568\uc744 \uac00\uc838\ub2e4\uc8fc\uc9c0\ub9cc, \n\ub3d9\uc2dc\uc5d0 \uc77c\uc790\ub9ac \uac10\uc18c\uc640 \uac19\uc740 \uc6b0\ub824\ub3c4 \uc81c\uae30\ub418\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\"\"\"\n\nprint(\"\ud83d\udcca \ud14d\uc2a4\ud2b8 \ubd84\uc11d \uacb0\uacfc:\")\nanalysis = analyzer.analyze_text(sample_text)\nprint(analysis)\n\n# \ud14d\uc2a4\ud2b8 \ube44\uad50\ntext_a = \"AI\ub294 \uc778\ub958\uc5d0\uac8c \ud070 \ub3c4\uc6c0\uc774 \ub420 \uac83\uc785\ub2c8\ub2e4.\"\ntext_b = \"AI \uae30\uc220\uc774 \uac00\uc838\uc62c \ud61c\ud0dd\uc740 \ubb34\uad81\ubb34\uc9c4\ud558\uba70, \uc778\ub958 \ubc1c\uc804\uc5d0 \ud575\uc2ec\uc801\uc778 \uc5ed\ud560\uc744 \ud560 \uac83\uc73c\ub85c \uc608\uc0c1\ub429\ub2c8\ub2e4.\"\n\nprint(\"\\n\ud83d\udd0d \ud14d\uc2a4\ud2b8 \ube44\uad50:\")\ncomparison = analyzer.compare_texts(text_a, text_b)\nprint(comparison)\n</code></pre>"},{"location":"examples/02-everyday-tasks/text-improver/#_7","title":"\u2705 \ud575\uc2ec \uc815\ub9ac","text":"<ol> <li>**\ub9de\ucda4\ubc95/\ubb38\ubc95 \uac80\uc0ac**\ub85c \uae30\ubcf8\uc801\uc778 \uc624\ub958 \uc218\uc815</li> <li>**\ubb38\uccb4 \uac1c\uc120**\uc73c\ub85c \ubaa9\uc801\uc5d0 \ub9de\ub294 \uae00\uc4f0\uae30</li> <li>\ud2b9\uc218 \ubaa9\uc801 \uae00\uc4f0\uae30 (\uc774\uba54\uc77c, \ubcf4\uace0\uc11c, SEO)</li> <li>**\ud14d\uc2a4\ud2b8 \ubd84\uc11d**\uc73c\ub85c \uae00\uc758 \ud488\uc9c8 \ud3c9\uac00</li> </ol>"},{"location":"examples/02-everyday-tasks/text-improver/#_8","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>\ud14d\uc2a4\ud2b8 \uac1c\uc120 \ub3c4\uad6c\ub97c \ub9cc\ub4e4\uc5c8\uc73c\ub2c8, \uc774\uc81c \ub2e4\uad6d\uc5b4 \ubc88\uc5ed\uae30\ub97c \ub9cc\ub4e4\uc5b4 \uc5b8\uc5b4\uc758 \uc7a5\ubcbd\uc744 \ub118\uc5b4\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/02-everyday-tasks/translator/","title":"\ud83c\udf0d \ub2e4\uad6d\uc5b4 \ubc88\uc5ed\uae30 \ub9cc\ub4e4\uae30","text":"<p>AI\ub97c \ud65c\uc6a9\ud574 \uc804\ubb38 \ubc88\uc5ed\uac00 \uc218\uc900\uc758 \ubc88\uc5ed \ub3c4\uad6c\ub97c \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/02-everyday-tasks/translator/#_2","title":"\ud83c\udfaf \ub9cc\ub4e4 \uac83","text":"<pre><code>\ud55c\uad6d\uc5b4: \uc548\ub155\ud558\uc138\uc694, \ub9cc\ub098\uc11c \ubc18\uac11\uc2b5\ub2c8\ub2e4.\n\uc601\uc5b4: Hello, nice to meet you.\n\uc77c\ubcf8\uc5b4: \u3053\u3093\u306b\u3061\u306f\u3001\u304a\u4f1a\u3044\u3067\u304d\u3066\u5b09\u3057\u3044\u3067\u3059\u3002\n\uc911\uad6d\uc5b4: \u4f60\u597d\uff0c\u5f88\u9ad8\u5174\u89c1\u5230\u4f60\u3002\n</code></pre>"},{"location":"examples/02-everyday-tasks/translator/#_3","title":"\ud83d\udcdd \uae30\ubcf8 \ubc88\uc5ed\uae30","text":""},{"location":"examples/02-everyday-tasks/translator/#step-1","title":"Step 1: \uac04\ub2e8\ud55c \ubc88\uc5ed\uae30","text":"<pre><code># translator.py\nfrom pyhub.llm import LLM\n\nclass Translator:\n    \"\"\"AI \ubc88\uc5ed\uae30\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.ai = LLM.create(model)\n\n    def translate(self, text, target_language=\"English\", source_language=\"auto\"):\n        \"\"\"\ud14d\uc2a4\ud2b8\ub97c \ubc88\uc5ed\ud569\ub2c8\ub2e4\"\"\"\n        if source_language == \"auto\":\n            # \uc5b8\uc5b4 \uc790\ub3d9 \uac10\uc9c0\n            source_prompt = \"\uc6d0\ubb38\uc758 \uc5b8\uc5b4\ub97c \uac10\uc9c0\ud574\uc11c\"\n        else:\n            source_prompt = f\"{source_language}\ub97c\"\n\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c {source_prompt} {target_language}\ub85c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\n        \uc790\uc5f0\uc2a4\ub7fd\uace0 \uc815\ud655\ud558\uac8c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\n\n        \uc6d0\ubb38:\n        {text}\n\n        \ubc88\uc5ed\ubb38\ub9cc \ucd9c\ub825\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def detect_language(self, text):\n        \"\"\"\uc5b8\uc5b4\ub97c \uac10\uc9c0\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\uac00 \uc5b4\ub5a4 \uc5b8\uc5b4\uc778\uc9c0 \uc54c\ub824\uc8fc\uc138\uc694:\n        \"{text}\"\n\n        \uc5b8\uc5b4 \uc774\ub984\ub9cc \ub2f5\ud574\uc8fc\uc138\uc694. (\uc608: Korean, English, Japanese)\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text.strip()\n\n# \uc0ac\uc6a9 \uc608\uc2dc\ntranslator = Translator()\n\n# \uae30\ubcf8 \ubc88\uc5ed\ntext = \"\uc778\uacf5\uc9c0\ub2a5\uc740 \uc6b0\ub9ac\uc758 \ubbf8\ub798\ub97c \ubc14\uafc0 \uac83\uc785\ub2c8\ub2e4.\"\nprint(\"\ud83c\uddf0\ud83c\uddf7 \uc6d0\ubb38:\", text)\nprint(\"\ud83c\uddfa\ud83c\uddf8 \uc601\uc5b4:\", translator.translate(text, \"English\"))\nprint(\"\ud83c\uddef\ud83c\uddf5 \uc77c\ubcf8\uc5b4:\", translator.translate(text, \"Japanese\"))\nprint(\"\ud83c\udde8\ud83c\uddf3 \uc911\uad6d\uc5b4:\", translator.translate(text, \"Chinese\"))\nprint(\"\ud83c\uddeb\ud83c\uddf7 \ud504\ub791\uc2a4\uc5b4:\", translator.translate(text, \"French\"))\n\n# \uc5b8\uc5b4 \uac10\uc9c0\nprint(\"\\n\ud83d\udd0d \uc5b8\uc5b4 \uac10\uc9c0:\")\ntexts = [\n    \"Hello, world!\",\n    \"\uc548\ub155\ud558\uc138\uc694\",\n    \"\u3053\u3093\u306b\u3061\u306f\",\n    \"Bonjour\"\n]\n\nfor t in texts:\n    lang = translator.detect_language(t)\n    print(f\"'{t}' \u2192 {lang}\")\n</code></pre>"},{"location":"examples/02-everyday-tasks/translator/#step-2","title":"Step 2: \uace0\uae09 \ubc88\uc5ed\uae30","text":"<pre><code>class AdvancedTranslator(Translator):\n    \"\"\"\uace0\uae09 \uae30\ub2a5\uc744 \uac16\ucd98 \ubc88\uc5ed\uae30\"\"\"\n\n    def translate_with_context(self, text, target_language, context=\"general\"):\n        \"\"\"\ubb38\ub9e5\uc744 \uace0\ub824\ud55c \ubc88\uc5ed\"\"\"\n        context_guides = {\n            \"formal\": \"\uaca9\uc2dd\uc788\ub294 \uacf5\uc2dd\uc801\uc778 \uc0c1\ud669\",\n            \"casual\": \"\uce5c\uadfc\ud55c \uc77c\uc0c1 \ub300\ud654\",\n            \"business\": \"\ube44\uc988\ub2c8\uc2a4 \uc0c1\ud669\",\n            \"technical\": \"\uae30\uc220/\uc804\ubb38 \uc6a9\uc5b4\",\n            \"academic\": \"\ud559\uc220\uc801\uc778 \ub0b4\uc6a9\"\n        }\n\n        context_desc = context_guides.get(context, context)\n\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c {target_language}\ub85c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\n        \uc0c1\ud669: {context_desc}\n\n        \uc6d0\ubb38:\n        {text}\n\n        \ud574\ub2f9 \uc0c1\ud669\uc5d0 \ub9de\ub294 \uc801\uc808\ud55c \ud45c\ud604\uc73c\ub85c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def translate_with_alternatives(self, text, target_language):\n        \"\"\"\uc5ec\ub7ec \ubc88\uc5ed \uc635\uc158 \uc81c\uacf5\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c {target_language}\ub85c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\n        3\uac00\uc9c0 \ub2e4\ub978 \ubc84\uc804\uc73c\ub85c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694:\n\n        \uc6d0\ubb38: {text}\n\n        \ud615\uc2dd:\n        1. [\uc815\ud655\ud55c \uc9c1\uc5ed]\n        2. [\uc790\uc5f0\uc2a4\ub7ec\uc6b4 \uc758\uc5ed]\n        3. [\uc0c1\ud669\uc5d0 \ub9de\ub294 \uad00\uc6a9\uad6c \uc0ac\uc6a9]\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def translate_with_explanation(self, text, target_language):\n        \"\"\"\ubc88\uc5ed\uacfc \uc124\uba85\uc744 \ud568\uaed8 \uc81c\uacf5\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c {target_language}\ub85c \ubc88\uc5ed\ud558\uace0 \uc124\uba85\ud574\uc8fc\uc138\uc694:\n\n        \uc6d0\ubb38: {text}\n\n        \ub2e4\uc74c \ud615\uc2dd\uc73c\ub85c \ub2f5\ud574\uc8fc\uc138\uc694:\n        \ubc88\uc5ed: [\ubc88\uc5ed\ubb38]\n\n        \uc124\uba85:\n        - \uc8fc\uc694 \ub2e8\uc5b4/\ud45c\ud604 \uc124\uba85\n        - \ubb38\ud654\uc801 \ucc28\uc774\ub098 \ub258\uc559\uc2a4\n        - \uc8fc\uc758\ud560 \uc810\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nadv_translator = AdvancedTranslator()\n\n# \ubb38\ub9e5\ubcc4 \ubc88\uc5ed\nkorean_text = \"\uc798 \ubd80\ud0c1\ub4dc\ub9bd\ub2c8\ub2e4\"\nprint(\"\ud83c\udfaf \ubb38\ub9e5\ubcc4 \ubc88\uc5ed - '\uc798 \ubd80\ud0c1\ub4dc\ub9bd\ub2c8\ub2e4':\\n\")\n\ncontexts = [\"formal\", \"casual\", \"business\"]\nfor ctx in contexts:\n    result = adv_translator.translate_with_context(\n        korean_text, \n        \"English\", \n        context=ctx\n    )\n    print(f\"{ctx.upper()}: {result}\")\n\n# \ub2e4\uc591\ud55c \ubc88\uc5ed \uc635\uc158\nprint(\"\\n\ud83d\udd04 \ubc88\uc5ed \uc635\uc158\ub4e4:\")\noptions = adv_translator.translate_with_alternatives(\n    \"\uc2dc\uac04\uc774 \uc57d\uc774\ub2e4\",\n    \"English\"\n)\nprint(options)\n\n# \ubc88\uc5ed \uc124\uba85\nprint(\"\\n\ud83d\udcda \ubc88\uc5ed \uc124\uba85:\")\nexplanation = adv_translator.translate_with_explanation(\n    \"\uc815\uc774 \ub9ce\ub2e4\",\n    \"English\"\n)\nprint(explanation)\n</code></pre>"},{"location":"examples/02-everyday-tasks/translator/#_4","title":"\ud83c\udfa8 \uc2e4\uc6a9\uc801\uc778 \ubc88\uc5ed \ub3c4\uad6c","text":""},{"location":"examples/02-everyday-tasks/translator/#1","title":"1. \ubb38\uc11c \ubc88\uc5ed\uae30","text":"<pre><code>class DocumentTranslator(AdvancedTranslator):\n    \"\"\"\ubb38\uc11c \ubc88\uc5ed \uc804\ubb38 \ub3c4\uad6c\"\"\"\n\n    def translate_document(self, document, target_language, preserve_format=True):\n        \"\"\"\ubb38\uc11c \uc804\uccb4\ub97c \ubc88\uc5ed\ud569\ub2c8\ub2e4\"\"\"\n        # \ubb38\ub2e8\ubcc4\ub85c \ubd84\ub9ac\n        paragraphs = document.strip().split('\\n\\n')\n        translated_paragraphs = []\n\n        for i, para in enumerate(paragraphs, 1):\n            print(f\"\ubc88\uc5ed \uc911... ({i}/{len(paragraphs)})\")\n\n            if preserve_format:\n                # \ud2b9\uc218 \ud615\uc2dd \ubcf4\uc874\n                if para.startswith('#'):  # \uc81c\ubaa9\n                    title = para.lstrip('#').strip()\n                    trans_title = self.translate(title, target_language)\n                    translated_paragraphs.append(f\"{'#' * para.count('#')} {trans_title}\")\n                elif para.startswith('-') or para.startswith('*'):  # \ubaa9\ub85d\n                    lines = para.split('\\n')\n                    trans_lines = []\n                    for line in lines:\n                        text = line.lstrip('-*').strip()\n                        trans_text = self.translate(text, target_language)\n                        trans_lines.append(f\"{line[:line.find(text)]}{trans_text}\")\n                    translated_paragraphs.append('\\n'.join(trans_lines))\n                else:\n                    # \uc77c\ubc18 \ubb38\ub2e8\n                    translated_paragraphs.append(\n                        self.translate(para, target_language)\n                    )\n            else:\n                translated_paragraphs.append(\n                    self.translate(para, target_language)\n                )\n\n        return '\\n\\n'.join(translated_paragraphs)\n\n    def create_bilingual_document(self, document, target_language):\n        \"\"\"\uc6d0\ubb38\uacfc \ubc88\uc5ed\ubb38\uc744 \ub098\ub780\ud788 \ud45c\uc2dc\"\"\"\n        paragraphs = document.strip().split('\\n\\n')\n        bilingual_doc = []\n\n        for para in paragraphs:\n            # \uc6d0\ubb38\n            bilingual_doc.append(f\"[\uc6d0\ubb38]\\n{para}\")\n\n            # \ubc88\uc5ed\n            translation = self.translate(para, target_language)\n            bilingual_doc.append(f\"[{target_language}]\\n{translation}\")\n\n            bilingual_doc.append(\"-\" * 50)\n\n        return '\\n\\n'.join(bilingual_doc)\n\n# \uc0ac\uc6a9 \uc608\uc2dc\ndoc_translator = DocumentTranslator()\n\n# \uc0d8\ud50c \ubb38\uc11c\ndocument = \"\"\"\n# AI\uc640 \ubbf8\ub798\n\n\uc778\uacf5\uc9c0\ub2a5\uc740 21\uc138\uae30\uc758 \uac00\uc7a5 \uc911\uc694\ud55c \uae30\uc220 \uc911 \ud558\ub098\uc785\ub2c8\ub2e4.\n\n## \uc8fc\uc694 \uc751\uc6a9 \ubd84\uc57c\n\n- \uc758\ub8cc: \uc9c8\ubcd1 \uc9c4\ub2e8\uacfc \uc2e0\uc57d \uac1c\ubc1c\n- \uad50\uc721: \ub9de\ucda4\ud615 \ud559\uc2b5 \uc2dc\uc2a4\ud15c\n- \uad50\ud1b5: \uc790\uc728\uc8fc\ud589 \uc790\ub3d9\ucc28\n\nAI\ub294 \uc6b0\ub9ac\uc758 \uc77c\uc0c1\uc744 \ubcc0\ud654\uc2dc\ud0a4\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\"\"\"\n\n# \ubb38\uc11c \ubc88\uc5ed\nprint(\"\ud83d\udcc4 \ubb38\uc11c \ubc88\uc5ed:\")\ntranslated = doc_translator.translate_document(document, \"English\")\nprint(translated)\n\n# \ub300\uc5ed \ubb38\uc11c\nprint(\"\\n\ud83d\udcd1 \ub300\uc5ed \ubb38\uc11c:\")\nbilingual = doc_translator.create_bilingual_document(\n    \"AI\ub294 \ubbf8\ub798\ub2e4.\\n\\n\uc6b0\ub9ac\ub294 \uc900\ube44\ud574\uc57c \ud55c\ub2e4.\",\n    \"English\"\n)\nprint(bilingual)\n</code></pre>"},{"location":"examples/02-everyday-tasks/translator/#2","title":"2. \ub300\ud654 \ubc88\uc5ed\uae30","text":"<pre><code>class ConversationTranslator(AdvancedTranslator):\n    \"\"\"\ub300\ud654 \ubc88\uc5ed \uc804\ubb38 \ub3c4\uad6c\"\"\"\n\n    def translate_conversation(self, messages, target_language):\n        \"\"\"\ub300\ud654\ub97c \ubc88\uc5ed\ud569\ub2c8\ub2e4\"\"\"\n        translated_messages = []\n\n        for msg in messages:\n            speaker = msg.get(\"speaker\", \"Unknown\")\n            text = msg.get(\"text\", \"\")\n\n            # \ub300\ud654\uccb4 \ubc88\uc5ed\n            prompt = f\"\"\"\n            \ub300\ud654\uc5d0\uc11c \ub098\uc628 \ub2e4\uc74c \ub9d0\uc744 {target_language}\ub85c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\n            \uad6c\uc5b4\uccb4\ub85c \uc790\uc5f0\uc2a4\ub7fd\uac8c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\n\n            \ud654\uc790: {speaker}\n            \uc6d0\ubb38: {text}\n            \"\"\"\n\n            response = self.ai.ask(prompt)\n\n            translated_messages.append({\n                \"speaker\": speaker,\n                \"original\": text,\n                \"translated\": response.text\n            })\n\n        return translated_messages\n\n    def real_time_translate(self, text, target_language, previous_context=\"\"):\n        \"\"\"\uc2e4\uc2dc\uac04 \ub300\ud654 \ubc88\uc5ed (\ubb38\ub9e5 \uace0\ub824)\"\"\"\n        prompt = f\"\"\"\n        \uc2e4\uc2dc\uac04 \ub300\ud654 \ubc88\uc5ed\uc785\ub2c8\ub2e4.\n\n        \uc774\uc804 \ub300\ud654:\n        {previous_context}\n\n        \ud604\uc7ac \ubc1c\uc5b8: {text}\n\n        {target_language}\ub85c \uc790\uc5f0\uc2a4\ub7fd\uac8c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\n        \uc9e7\uace0 \uad6c\uc5b4\uccb4\ub85c \ubc88\uc5ed\ud558\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nconv_translator = ConversationTranslator()\n\n# \ub300\ud654 \ubc88\uc5ed\nconversation = [\n    {\"speaker\": \"A\", \"text\": \"\uc548\ub155! \uc624\ub79c\ub9cc\uc774\uc57c\"},\n    {\"speaker\": \"B\", \"text\": \"\uc815\ub9d0 \uc624\ub79c\ub9cc\uc774\ub124. \uc798 \uc9c0\ub0c8\uc5b4?\"},\n    {\"speaker\": \"A\", \"text\": \"\uc751, \uc694\uc998 \uc0c8 \ud504\ub85c\uc81d\ud2b8 \ub54c\ubb38\uc5d0 \ubc14\ube74\uc5b4\"},\n    {\"speaker\": \"B\", \"text\": \"\uc5b4\ub5a4 \ud504\ub85c\uc81d\ud2b8\uc57c?\"}\n]\n\nprint(\"\ud83d\udcac \ub300\ud654 \ubc88\uc5ed:\")\ntranslated_conv = conv_translator.translate_conversation(conversation, \"English\")\n\nfor msg in translated_conv:\n    print(f\"\\n{msg['speaker']}: {msg['original']}\")\n    print(f\"\u2192 {msg['translated']}\")\n\n# \uc2e4\uc2dc\uac04 \ubc88\uc5ed\nprint(\"\\n\u26a1 \uc2e4\uc2dc\uac04 \ubc88\uc5ed:\")\ncontext = \"A: \uc548\ub155\ud558\uc138\uc694 / B: Hello\"\nnew_message = \"\uc624\ub298 \ub0a0\uc528 \uc88b\ub124\uc694\"\nreal_time = conv_translator.real_time_translate(\n    new_message, \n    \"English\", \n    context\n)\nprint(f\"\uc6d0\ubb38: {new_message}\")\nprint(f\"\ubc88\uc5ed: {real_time}\")\n</code></pre>"},{"location":"examples/02-everyday-tasks/translator/#3","title":"3. \uc804\ubb38 \ubd84\uc57c \ubc88\uc5ed\uae30","text":"<pre><code>class SpecializedTranslator(AdvancedTranslator):\n    \"\"\"\uc804\ubb38 \ubd84\uc57c \ubc88\uc5ed\uae30\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.domains = {\n            \"medical\": \"\uc758\ud559/\uc758\ub8cc\",\n            \"legal\": \"\ubc95\ub960\",\n            \"technical\": \"\uae30\uc220/IT\",\n            \"financial\": \"\uae08\uc735/\uacbd\uc81c\",\n            \"scientific\": \"\uacfc\ud559/\uc5f0\uad6c\"\n        }\n\n    def translate_specialized(self, text, target_language, domain):\n        \"\"\"\uc804\ubb38 \uc6a9\uc5b4\ub97c \uc815\ud655\ud788 \ubc88\uc5ed\ud569\ub2c8\ub2e4\"\"\"\n        domain_desc = self.domains.get(domain, domain)\n\n        prompt = f\"\"\"\n        \ub2e4\uc74c\uc740 {domain_desc} \ubd84\uc57c\uc758 \uc804\ubb38 \ud14d\uc2a4\ud2b8\uc785\ub2c8\ub2e4.\n        {target_language}\ub85c \uc815\ud655\ud558\uac8c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\n\n        \uc8fc\uc758\uc0ac\ud56d:\n        - \uc804\ubb38 \uc6a9\uc5b4\ub294 \ud574\ub2f9 \ubd84\uc57c\uc758 \ud45c\uc900 \ubc88\uc5ed \uc0ac\uc6a9\n        - \ud544\uc694\uc2dc \uc6d0\uc5b4\ub97c \uad04\ud638 \uc548\uc5d0 \ubcd1\uae30\n        - \uc815\ud655\uc131\uc774 \ucd5c\uc6b0\uc120\n\n        \uc6d0\ubb38:\n        {text}\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def create_glossary(self, terms, source_lang, target_lang, domain):\n        \"\"\"\uc6a9\uc5b4\uc9d1\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4\"\"\"\n        domain_desc = self.domains.get(domain, domain)\n\n        prompt = f\"\"\"\n        {domain_desc} \ubd84\uc57c\uc758 \uc6a9\uc5b4\ub97c {source_lang}\uc5d0\uc11c {target_lang}\ub85c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\n\n        \uc6a9\uc5b4 \ubaa9\ub85d:\n        {', '.join(terms)}\n\n        \ub2e4\uc74c \ud615\uc2dd\uc73c\ub85c \uc791\uc131\ud574\uc8fc\uc138\uc694:\n        1. [\uc6d0\uc5b4] \u2192 [\ubc88\uc5ed] (\uc124\uba85)\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def translate_with_terminology(self, text, target_language, glossary):\n        \"\"\"\uc6a9\uc5b4\uc9d1\uc744 \ud65c\uc6a9\ud55c \ubc88\uc5ed\"\"\"\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c {target_language}\ub85c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694.\n\n        \uc81c\uacf5\ub41c \uc6a9\uc5b4\uc9d1\uc744 \ubc18\ub4dc\uc2dc \ub530\ub77c\uc8fc\uc138\uc694:\n        {glossary}\n\n        \uc6d0\ubb38:\n        {text}\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nspec_translator = SpecializedTranslator()\n\n# \uc804\ubb38 \ubd84\uc57c \ubc88\uc5ed\nmedical_text = \"The patient presented with acute myocardial infarction and was immediately administered thrombolytic therapy.\"\n\nprint(\"\ud83c\udfe5 \uc758\ud559 \ubc88\uc5ed:\")\nmedical_trans = spec_translator.translate_specialized(\n    medical_text,\n    \"Korean\",\n    \"medical\"\n)\nprint(f\"\uc6d0\ubb38: {medical_text}\")\nprint(f\"\ubc88\uc5ed: {medical_trans}\")\n\n# \uc6a9\uc5b4\uc9d1 \uc0dd\uc131\nprint(\"\\n\ud83d\udcd6 IT \uc6a9\uc5b4\uc9d1:\")\nit_terms = [\"machine learning\", \"neural network\", \"deep learning\", \"algorithm\"]\nglossary = spec_translator.create_glossary(\n    it_terms,\n    \"English\",\n    \"Korean\",\n    \"technical\"\n)\nprint(glossary)\n\n# \uc6a9\uc5b4\uc9d1 \ud65c\uc6a9 \ubc88\uc5ed\nprint(\"\\n\ud83d\udd27 \uc6a9\uc5b4\uc9d1 \ud65c\uc6a9 \ubc88\uc5ed:\")\ntech_glossary = \"\"\"\n- API \u2192 \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8 \uc778\ud130\ud398\uc774\uc2a4\n- framework \u2192 \ud504\ub808\uc784\uc6cc\ud06c\n- deployment \u2192 \ubc30\ud3ec\n\"\"\"\n\ntech_text = \"We need to update the API framework before deployment.\"\nterm_trans = spec_translator.translate_with_terminology(\n    tech_text,\n    \"Korean\",\n    tech_glossary\n)\nprint(f\"\uc6d0\ubb38: {tech_text}\")\nprint(f\"\ubc88\uc5ed: {term_trans}\")\n</code></pre>"},{"location":"examples/02-everyday-tasks/translator/#_5","title":"\ud83c\udf10 \ub2e4\uad6d\uc5b4 \ub3d9\uc2dc \ubc88\uc5ed\uae30","text":"<pre><code>class MultiLanguageTranslator(AdvancedTranslator):\n    \"\"\"\uc5ec\ub7ec \uc5b8\uc5b4\ub85c \ub3d9\uc2dc\uc5d0 \ubc88\uc5ed\ud558\ub294 \ub3c4\uad6c\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.common_languages = {\n            \"en\": \"English\",\n            \"ja\": \"Japanese\", \n            \"zh\": \"Chinese\",\n            \"es\": \"Spanish\",\n            \"fr\": \"French\",\n            \"de\": \"German\",\n            \"ru\": \"Russian\",\n            \"ar\": \"Arabic\"\n        }\n\n    def translate_to_multiple(self, text, target_languages):\n        \"\"\"\uc5ec\ub7ec \uc5b8\uc5b4\ub85c \ub3d9\uc2dc\uc5d0 \ubc88\uc5ed\ud569\ub2c8\ub2e4\"\"\"\n        translations = {}\n\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ud14d\uc2a4\ud2b8\ub97c {', '.join(target_languages)}\ub85c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694:\n\n        \uc6d0\ubb38: {text}\n\n        \uac01 \uc5b8\uc5b4\ubcc4\ub85c \ubc88\uc5ed\uc744 \uc81c\uacf5\ud574\uc8fc\uc138\uc694:\n        \"\"\"\n\n        for lang in target_languages:\n            prompt += f\"\\n{lang}:\"\n\n        response = self.ai.ask(prompt)\n\n        # \uacb0\uacfc \ud30c\uc2f1\n        lines = response.text.strip().split('\\n')\n        for line in lines:\n            for lang in target_languages:\n                if line.startswith(f\"{lang}:\"):\n                    translations[lang] = line.replace(f\"{lang}:\", \"\").strip()\n\n        return translations\n\n    def create_multilingual_card(self, phrase):\n        \"\"\"\ub2e4\uad6d\uc5b4 \uce74\ub4dc\ub97c \ub9cc\ub4ed\ub2c8\ub2e4\"\"\"\n        languages = [\"English\", \"Japanese\", \"Chinese\", \"Spanish\", \"French\"]\n\n        prompt = f\"\"\"\n        '{phrase}'\ub97c \ub2e4\uc74c \uc5b8\uc5b4\ub85c \ubc88\uc5ed\ud558\uace0 \ubc1c\uc74c\ub3c4 \ud568\uaed8 \uc81c\uacf5\ud574\uc8fc\uc138\uc694:\n        {', '.join(languages)}\n\n        \ud615\uc2dd:\n        \uc5b8\uc5b4: \ubc88\uc5ed (\ubc1c\uc74c)\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def compare_translations(self, text, languages):\n        \"\"\"\ubc88\uc5ed\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4\"\"\"\n        translations = self.translate_to_multiple(text, languages)\n\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ubc88\uc5ed\ub4e4\uc744 \ube44\uad50 \ubd84\uc11d\ud574\uc8fc\uc138\uc694:\n\n        \uc6d0\ubb38: {text}\n\n        \ubc88\uc5ed\ub4e4:\n        \"\"\"\n\n        for lang, trans in translations.items():\n            prompt += f\"\\n{lang}: {trans}\"\n\n        prompt += \"\"\"\n\n        \uac01 \ubc88\uc5ed\uc758 \ud2b9\uc9d5\uacfc \ub258\uc559\uc2a4 \ucc28\uc774\ub97c \uc124\uba85\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nmulti_translator = MultiLanguageTranslator()\n\n# \ub2e4\uad6d\uc5b4 \ub3d9\uc2dc \ubc88\uc5ed\ntext = \"\ud3c9\ud654\ub294 \ubaa8\ub4e0 \uc778\ub958\uc758 \uafc8\uc785\ub2c8\ub2e4\"\nprint(\"\ud83c\udf0d \ub2e4\uad6d\uc5b4 \ubc88\uc5ed:\")\n\nlanguages = [\"English\", \"Japanese\", \"Chinese\", \"Spanish\", \"French\"]\ntranslations = multi_translator.translate_to_multiple(text, languages)\n\nfor lang, trans in translations.items():\n    print(f\"{lang}: {trans}\")\n\n# \ub2e4\uad6d\uc5b4 \uce74\ub4dc\nprint(\"\\n\ud83c\udfb4 \ub2e4\uad6d\uc5b4 \uce74\ub4dc - '\uac10\uc0ac\ud569\ub2c8\ub2e4':\")\ncard = multi_translator.create_multilingual_card(\"\uac10\uc0ac\ud569\ub2c8\ub2e4\")\nprint(card)\n\n# \ubc88\uc5ed \ube44\uad50\nprint(\"\\n\ud83d\udd0d \ubc88\uc5ed \ube44\uad50 \ubd84\uc11d:\")\ncomparison = multi_translator.compare_translations(\n    \"\uc2dc\uac04\uc740 \uae08\uc774\ub2e4\",\n    [\"English\", \"Japanese\", \"Chinese\"]\n)\nprint(comparison)\n</code></pre>"},{"location":"examples/02-everyday-tasks/translator/#_6","title":"\ud83d\udcf1 \ubc88\uc5ed \ub3c4\uc6b0\ubbf8 \uc571","text":"<pre><code>class TranslationApp:\n    \"\"\"\ud1b5\ud569 \ubc88\uc5ed \uc560\ud50c\ub9ac\ucf00\uc774\uc158\"\"\"\n\n    def __init__(self):\n        self.translator = AdvancedTranslator()\n        self.history = []\n\n    def interactive_mode(self):\n        \"\"\"\ub300\ud654\ud615 \ubc88\uc5ed \ubaa8\ub4dc\"\"\"\n        print(\"\ud83c\udf10 AI \ubc88\uc5ed\uae30\uc5d0 \uc624\uc2e0 \uac83\uc744 \ud658\uc601\ud569\ub2c8\ub2e4!\")\n        print(\"\uc0ac\uc6a9\ubc95: [\uc6d0\ubb38] \u2192 [\ubaa9\ud45c \uc5b8\uc5b4]\")\n        print(\"\uc608\uc2dc: \uc548\ub155\ud558\uc138\uc694 \u2192 English\")\n        print(\"\uc885\ub8cc: quit\\n\")\n\n        while True:\n            user_input = input(\"\ubc88\uc5ed\ud560 \ud14d\uc2a4\ud2b8: \").strip()\n\n            if user_input.lower() in ['quit', '\uc885\ub8cc']:\n                self.show_summary()\n                break\n\n            if '\u2192' in user_input:\n                text, lang = user_input.split('\u2192')\n                text = text.strip()\n                lang = lang.strip()\n            else:\n                text = user_input\n                lang = \"English\"  # \uae30\ubcf8\uac12\n\n            # \ubc88\uc5ed \uc218\ud589\n            translation = self.translator.translate(text, lang)\n\n            # \uacb0\uacfc \ud45c\uc2dc\n            print(f\"\\n\ud83d\udcdd \uc6d0\ubb38: {text}\")\n            print(f\"\ud83c\udf0f {lang}: {translation}\\n\")\n\n            # \uae30\ub85d \uc800\uc7a5\n            self.history.append({\n                \"original\": text,\n                \"target_lang\": lang,\n                \"translation\": translation,\n                \"timestamp\": datetime.now()\n            })\n\n    def show_summary(self):\n        \"\"\"\uc0ac\uc6a9 \uc694\uc57d\uc744 \ud45c\uc2dc\ud569\ub2c8\ub2e4\"\"\"\n        if not self.history:\n            return\n\n        print(\"\\n\ud83d\udcca \ubc88\uc5ed \uc694\uc57d:\")\n        print(f\"\ucd1d \ubc88\uc5ed \uc218: {len(self.history)}\")\n\n        # \uc5b8\uc5b4\ubcc4 \ud1b5\uacc4\n        lang_stats = {}\n        for item in self.history:\n            lang = item[\"target_lang\"]\n            lang_stats[lang] = lang_stats.get(lang, 0) + 1\n\n        print(\"\\n\uc5b8\uc5b4\ubcc4 \ubc88\uc5ed:\")\n        for lang, count in lang_stats.items():\n            print(f\"- {lang}: {count}\ud68c\")\n\n        print(\"\\n\ucd5c\uadfc \ubc88\uc5ed 3\uac1c:\")\n        for item in self.history[-3:]:\n            print(f\"- {item['original'][:20]}... \u2192 {item['target_lang']}\")\n\n# \uc571 \uc2e4\ud589\nif __name__ == \"__main__\":\n    app = TranslationApp()\n    app.interactive_mode()\n</code></pre>"},{"location":"examples/02-everyday-tasks/translator/#_7","title":"\u2705 \ud575\uc2ec \uc815\ub9ac","text":"<ol> <li>**\uae30\ubcf8 \ubc88\uc5ed**\ubd80\ud130 **\uc804\ubb38 \ubc88\uc5ed**\uae4c\uc9c0 \ub2e8\uacc4\ubcc4 \uad6c\ud604</li> <li>**\ubb38\ub9e5\uacfc \ub3c4\uba54\uc778**\uc744 \uace0\ub824\ud55c \uc815\ud655\ud55c \ubc88\uc5ed</li> <li>**\ub2e4\uad6d\uc5b4 \ub3d9\uc2dc \ubc88\uc5ed**\uc73c\ub85c \ud6a8\uc728\uc131 \ud5a5\uc0c1</li> <li>**\ub300\ud654\ud615 \uc778\ud130\ud398\uc774\uc2a4**\ub85c \uc0ac\uc6a9\uc131 \uac1c\uc120</li> </ol>"},{"location":"examples/02-everyday-tasks/translator/#_8","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>\ubc88\uc5ed\uae30\ub97c \uc644\uc131\ud588\uc73c\ub2c8, \uc774\uc81c \ub611\ub611\ud55c \uc694\uc57d\uae30\ub97c \ub9cc\ub4e4\uc5b4 \uae34 \ud14d\uc2a4\ud2b8\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \ucc98\ub9ac\ud574\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/03-conversations/","title":"\ud83d\udcac \ub300\ud654 \uc774\uc5b4\uac00\uae30","text":"<p>AI\uc640 \uc5f0\uc18d\uc801\uc778 \ub300\ud654\ub97c \ub098\ub204\ub294 \ucc57\ubd07\uc744 \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4! \uc774\uc804 \ub300\ud654\ub97c \uae30\uc5b5\ud558\uace0 \ub9e5\ub77d\uc744 \uc774\ud574\ud558\ub294 AI\ub97c \uad6c\ud604\ud569\ub2c8\ub2e4.</p>"},{"location":"examples/03-conversations/#_2","title":"\ud83c\udfaf \uc774 \uc139\uc158\uc5d0\uc11c \ubc30\uc6b8 \ub0b4\uc6a9","text":"<ul> <li>\u2705 \ub300\ud654 \ub9e5\ub77d(Context) \uc774\ud574\ud558\uae30</li> <li>\u2705 \ub300\ud654 \uae30\ub85d \uad00\ub9ac\ud558\uae30</li> <li>\u2705 \uac04\ub2e8\ud55c \ucc57\ubd07 \ub9cc\ub4e4\uae30</li> <li>\u2705 \ub300\ud654\ud615 AI \ud65c\uc6a9 \ud301</li> </ul>"},{"location":"examples/03-conversations/#_3","title":"\ud83d\udcda \uc139\uc158 \uad6c\uc131","text":""},{"location":"examples/03-conversations/#1","title":"1. \uc65c \ub300\ud654\uac00 \uc911\uc694\ud55c\uac00\uc694?","text":"<ul> <li>\ub2e8\ubc1c\uc131 \uc9c8\ubb38 vs \uc5f0\uc18d \ub300\ud654</li> <li>\ub9e5\ub77d\uc758 \uc911\uc694\uc131</li> <li>\uc2e4\uc81c \ud65c\uc6a9 \uc0ac\ub840</li> </ul>"},{"location":"examples/03-conversations/#2","title":"2. \ub300\ud654 \uae30\uc5b5\ud558\uae30","text":"<ul> <li>AI\uac00 \ub300\ud654\ub97c \uae30\uc5b5\ud558\ub294 \ubc29\ubc95</li> <li>\ub300\ud654 \uae30\ub85d \uad00\ub9ac</li> <li>\uba54\ubaa8\ub9ac \ucd5c\uc801\ud654</li> </ul>"},{"location":"examples/03-conversations/#3","title":"3. \ucc57\ubd07 \ub9cc\ub4e4\uae30","text":"<ul> <li>\uae30\ubcf8 \ucc57\ubd07 \uad6c\ud604</li> <li>\ub300\ud654 \ud750\ub984 \uc81c\uc5b4</li> <li>\uc0ac\uc6a9\uc790 \uacbd\ud5d8 \uac1c\uc120</li> </ul>"},{"location":"examples/03-conversations/#4","title":"4. \ub300\ud654 \uc798\ud558\ub294 \ubc95","text":"<ul> <li>\ud6a8\uacfc\uc801\uc778 \ud504\ub86c\ud504\ud2b8 \uc791\uc131</li> <li>\ub300\ud654 \ud488\uc9c8 \ud5a5\uc0c1</li> <li>\ubb38\uc81c \ud574\uacb0 \ubc29\ubc95</li> </ul>"},{"location":"examples/03-conversations/#_4","title":"\ud83d\udca1 \uc774\ub7f0 \ubd84\ub4e4\uc5d0\uac8c \ucd94\ucc9c\ud574\uc694","text":"<ul> <li>\ud83d\udcac \uace0\uac1d \uc0c1\ub2f4 \ucc57\ubd07\uc744 \ub9cc\ub4e4\uace0 \uc2f6\uc740 \ubd84</li> <li>\ud83c\udfae \ub300\ud654\ud615 \uac8c\uc784\uc744 \uac1c\ubc1c\ud558\ub294 \ubd84</li> <li>\ud83d\udcda \uad50\uc721\uc6a9 AI \ud29c\ud130\ub97c \ub9cc\ub4dc\ub294 \ubd84</li> <li>\ud83e\udd16 \uac1c\uc778 \ube44\uc11c AI\ub97c \uc6d0\ud558\ub294 \ubd84</li> </ul>"},{"location":"examples/03-conversations/#_5","title":"\ud83d\ude80 \uc2dc\uc791\ud558\uae30 \uc804\uc5d0","text":"<p>\ub300\ud654\ud615 AI\uc758 \ud575\uc2ec\uc740 \"\uae30\uc5b5\"\uc785\ub2c8\ub2e4:</p> <pre><code># \u274c \uae30\uc5b5\ud558\uc9c0 \ubabb\ud558\ub294 AI\nai.ask(\"\ub0b4 \uc774\ub984\uc740 \ucca0\uc218\uc57c\")  # \"\uc548\ub155\ud558\uc138\uc694, \ucca0\uc218\ub2d8!\"\nai.ask(\"\ub0b4 \uc774\ub984\uc774 \ubb50\uc57c?\")    # \"\uc8c4\uc1a1\ud558\uc9c0\ub9cc \ubaa8\ub974\uaca0\uc2b5\ub2c8\ub2e4.\"\n\n# \u2705 \uae30\uc5b5\ud558\ub294 AI\nchat.send(\"\ub0b4 \uc774\ub984\uc740 \ucca0\uc218\uc57c\")  # \"\uc548\ub155\ud558\uc138\uc694, \ucca0\uc218\ub2d8!\"\nchat.send(\"\ub0b4 \uc774\ub984\uc774 \ubb50\uc57c?\")    # \"\ucca0\uc218\ub2d8\uc774\ub77c\uace0 \ud558\uc168\uc8e0!\"\n</code></pre>"},{"location":"examples/03-conversations/#ai","title":"\ud83d\udcca \ub300\ud654\ud615 AI\uc758 \uc7a5\uc810","text":"\ub2e8\ubc1c\uc131 \uc9c8\ubb38 \ub300\ud654\ud615 AI \ub9e4\ubc88 \uc0c8\ub85c\uc6b4 \uc2dc\uc791 \uc774\uc804 \ub300\ud654 \uae30\uc5b5 \ub9e5\ub77d \uc5c6\uc74c \ub9e5\ub77d \uc774\ud574 \ub2e8\uc21c Q&amp;A \uc790\uc5f0\uc2a4\ub7ec\uc6b4 \ub300\ud654 \uc81c\ud55c\uc801 \ud65c\uc6a9 \ub2e4\uc591\ud55c \ud65c\uc6a9"},{"location":"examples/03-conversations/#_6","title":"\ud83c\udf89 \uc644\uc131 \uc608\uc2dc","text":"<p>\uc774 \uc139\uc158\uc744 \ub05d\ub0b4\uba74 \uc774\ub7f0 \ucc57\ubd07\uc744 \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code>\ud83d\udc64 You: \uc548\ub155! \ub098\ub294 \ud504\ub85c\uadf8\ub798\ubc0d\uc744 \ubc30\uc6b0\uace0 \uc788\uc5b4\n\ud83e\udd16 Bot: \uc548\ub155\ud558\uc138\uc694! \ud504\ub85c\uadf8\ub798\ubc0d\uc744 \ubc30\uc6b0\uace0 \uacc4\uc2dc\ub294\uad70\uc694. \uc5b4\ub5a4 \uc5b8\uc5b4\ub97c \ubc30\uc6b0\uace0 \uacc4\uc2e0\uac00\uc694?\n\n\ud83d\udc64 You: \ud30c\uc774\uc36c\uc744 \ubc30\uc6b0\uace0 \uc788\uc5b4. \ud2b9\ud788 \uc6f9 \uac1c\ubc1c\uc5d0 \uad00\uc2ec\uc774 \uc788\uc5b4\n\ud83e\udd16 Bot: \ud30c\uc774\uc36c\uc73c\ub85c \uc6f9 \uac1c\ubc1c\uc774\ub77c\ub2c8 \uc88b\uc740 \uc120\ud0dd\uc774\uc138\uc694! Django\ub098 Flask \uac19\uc740 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc0ac\uc6a9\ud558\uc2dc\ub098\uc694?\n\n\ud83d\udc64 You: \uc544\uc9c1 \ud504\ub808\uc784\uc6cc\ud06c\ub294 \ubaa8\ub974\uaca0\uc5b4. \ucd94\ucc9c\ud574\uc904 \uc218 \uc788\uc5b4?\n\ud83e\udd16 Bot: \ud30c\uc774\uc36c \uc6f9 \uac1c\ubc1c\uc744 \ucc98\uc74c \uc2dc\uc791\ud558\uc2e0\ub2e4\uba74 Flask\ub97c \ucd94\ucc9c\ub4dc\ub824\uc694! Django\ubcf4\ub2e4 \uac04\ub2e8\ud558\uace0 \ubc30\uc6b0\uae30 \uc27d\uac70\ub4e0\uc694.\n</code></pre>"},{"location":"examples/03-conversations/#_7","title":"\ud83d\udd27 \uc900\ube44\ubb3c","text":"<ul> <li>\u2705 \uae30\ubcf8\uc801\uc778 AI \uc0ac\uc6a9\ubc95 \uc774\ud574</li> <li>\u2705 Python \ub9ac\uc2a4\ud2b8\uc640 \ub515\uc154\ub108\ub9ac \uc774\ud574</li> <li>\u2705 \uac04\ub2e8\ud55c \ubc18\ubcf5\ubb38 \uc791\uc131 \ub2a5\ub825</li> </ul>"},{"location":"examples/03-conversations/#_8","title":"\ud83c\udfaf \ud559\uc2b5 \ubaa9\ud45c","text":"<p>\uc774 \uc139\uc158\uc744 \ub9c8\uce58\uba74: - \ub300\ud654\uc758 \ub9e5\ub77d\uc744 \uc720\uc9c0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4 - \uac04\ub2e8\ud55c \ucc57\ubd07\uc744 \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4 - \ub300\ud654\ud615 AI\uc758 \ud65c\uc6a9\ubc95\uc744 \uc774\ud574\ud569\ub2c8\ub2e4</p> <p>\uc900\ube44\ub418\uc168\ub098\uc694? \uc65c \ub300\ud654\uac00 \uc911\uc694\ud55c\uac00\uc694?\ubd80\ud130 \uc2dc\uc791\ud574\ubd05\uc2dc\ub2e4! \ud83d\ude80</p>"},{"location":"examples/03-conversations/chatbot-basics/","title":"\ud83e\udd16 \uac04\ub2e8\ud55c \ucc57\ubd07 \ub9cc\ub4e4\uae30","text":"<p>\uc774\uc81c \ubcf8\uaca9\uc801\uc73c\ub85c \ub300\ud654\ud615 \ucc57\ubd07\uc744 \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4! \uae30\ubcf8\ubd80\ud130 \uace0\uae09 \uae30\ub2a5\uae4c\uc9c0 \ub2e8\uacc4\ubcc4\ub85c \uad6c\ud604\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.</p>"},{"location":"examples/03-conversations/chatbot-basics/#_2","title":"\ud83c\udfaf \ub9cc\ub4e4 \uac83","text":"<pre><code>\ud83e\udd16 \uc548\ub155\ud558\uc138\uc694! \ubb34\uc5c7\uc744 \ub3c4\uc640\ub4dc\ub9b4\uae4c\uc694?\n\ud83d\udc64 \ud30c\uc774\uc36c \uacf5\ubd80\ud558\ub294 \ubc29\ubc95\uc744 \uc54c\ub824\uc918\n\ud83e\udd16 \ud30c\uc774\uc36c\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \uacf5\ubd80\ud558\ub294 \ubc29\ubc95\uc744 \uc54c\ub824\ub4dc\ub9b4\uac8c\uc694!\n   1. \uae30\ucd08 \ubb38\ubc95\ubd80\ud130 \uc2dc\uc791\ud558\uc138\uc694...\n</code></pre>"},{"location":"examples/03-conversations/chatbot-basics/#_3","title":"\ud83d\udcdd \uae30\ubcf8 \ucc57\ubd07 \uad6c\ud604","text":""},{"location":"examples/03-conversations/chatbot-basics/#step-1","title":"Step 1: \uac00\uc7a5 \uac04\ub2e8\ud55c \ucc57\ubd07","text":"<pre><code># simple_chatbot.py\nfrom pyhub.llm import LLM\n\nclass SimpleChatbot:\n    \"\"\"\uac00\uc7a5 \uae30\ubcf8\uc801\uc778 \ucc57\ubd07\"\"\"\n\n    def __init__(self, name=\"\ub3c4\uc6b0\ubbf8\"):\n        self.name = name\n        self.ai = LLM.create(\"gpt-4o-mini\")\n        self.messages = []\n\n    def greet(self):\n        \"\"\"\uc778\uc0ac\ub9d0\uc744 \ucd9c\ub825\ud569\ub2c8\ub2e4\"\"\"\n        greeting = f\"\"\"\n\ud83e\udd16 \uc548\ub155\ud558\uc138\uc694! \uc800\ub294 {self.name}\uc785\ub2c8\ub2e4.\n\ubb34\uc5c7\uc774\ub4e0 \ubb3c\uc5b4\ubcf4\uc138\uc694. \ub3c4\uc640\ub4dc\ub9ac\uaca0\uc2b5\ub2c8\ub2e4!\n(\uc885\ub8cc\ud558\ub824\uba74 'quit' \ub610\ub294 '\uc885\ub8cc'\ub97c \uc785\ub825\ud558\uc138\uc694)\n        \"\"\"\n        print(greeting)\n\n    def chat(self, user_input):\n        \"\"\"\uc0ac\uc6a9\uc790 \uc785\ub825\uc744 \ubc1b\uc544 \uc751\ub2f5\ud569\ub2c8\ub2e4\"\"\"\n        # \ub300\ud654 \uae30\ub85d\uc5d0 \ucd94\uac00\n        self.messages.append({\"role\": \"user\", \"content\": user_input})\n\n        # \uc804\uccb4 \ub300\ud654 \ub9e5\ub77d \uc0dd\uc131\n        context = self._build_context()\n\n        # AI \uc751\ub2f5 \uc0dd\uc131\n        response = self.ai.ask(context)\n        ai_message = response.text\n\n        # \uc751\ub2f5\uc744 \ub300\ud654 \uae30\ub85d\uc5d0 \ucd94\uac00\n        self.messages.append({\"role\": \"assistant\", \"content\": ai_message})\n\n        return ai_message\n\n    def _build_context(self):\n        \"\"\"\ub300\ud654 \ub9e5\ub77d\uc744 \uad6c\uc131\ud569\ub2c8\ub2e4\"\"\"\n        context = f\"\ub2f9\uc2e0\uc740 \uce5c\uc808\ud55c AI \uc5b4\uc2dc\uc2a4\ud134\ud2b8 {self.name}\uc785\ub2c8\ub2e4.\\n\\n\"\n\n        for msg in self.messages:\n            if msg[\"role\"] == \"user\":\n                context += f\"\uc0ac\uc6a9\uc790: {msg['content']}\\n\"\n            else:\n                context += f\"{self.name}: {msg['content']}\\n\"\n\n        context += f\"{self.name}:\"\n        return context\n\n    def run(self):\n        \"\"\"\ucc57\ubd07\uc744 \uc2e4\ud589\ud569\ub2c8\ub2e4\"\"\"\n        self.greet()\n\n        while True:\n            # \uc0ac\uc6a9\uc790 \uc785\ub825 \ubc1b\uae30\n            user_input = input(\"\\n\ud83d\udc64 You: \").strip()\n\n            # \uc885\ub8cc \uc870\uac74\n            if user_input.lower() in ['quit', '\uc885\ub8cc', 'exit']:\n                print(f\"\\n\ud83e\udd16 {self.name}: \uc548\ub155\ud788 \uac00\uc138\uc694! \uc88b\uc740 \ud558\ub8e8 \ub418\uc138\uc694! \ud83d\udc4b\")\n                break\n\n            # \uc751\ub2f5 \uc0dd\uc131 \ubc0f \ucd9c\ub825\n            response = self.chat(user_input)\n            print(f\"\\n\ud83e\udd16 {self.name}: {response}\")\n\n# \uc2e4\ud589\nif __name__ == \"__main__\":\n    bot = SimpleChatbot(\"\ud30c\uc774\uc36c \ub3c4\uc6b0\ubbf8\")\n    bot.run()\n</code></pre>"},{"location":"examples/03-conversations/chatbot-basics/#step-2","title":"Step 2: \uae30\ub2a5\uc774 \ucd94\uac00\ub41c \ucc57\ubd07","text":"<pre><code>class FeatureRichChatbot(SimpleChatbot):\n    \"\"\"\ub2e4\uc591\ud55c \uae30\ub2a5\uc744 \uac00\uc9c4 \ucc57\ubd07\"\"\"\n\n    def __init__(self, name=\"\uc2a4\ub9c8\ud2b8 \ubd07\"):\n        super().__init__(name)\n        self.commands = {\n            \"/help\": self.show_help,\n            \"/clear\": self.clear_history,\n            \"/save\": self.save_conversation,\n            \"/stats\": self.show_stats\n        }\n\n    def chat(self, user_input):\n        \"\"\"\uba85\ub839\uc5b4\ub97c \ucc98\ub9ac\ud558\uac70\ub098 \uc77c\ubc18 \ub300\ud654\ub97c \uc9c4\ud589\ud569\ub2c8\ub2e4\"\"\"\n        # \uba85\ub839\uc5b4 \ud655\uc778\n        if user_input.startswith(\"/\"):\n            return self.handle_command(user_input)\n\n        # \uc77c\ubc18 \ub300\ud654\n        return super().chat(user_input)\n\n    def handle_command(self, command):\n        \"\"\"\uba85\ub839\uc5b4\ub97c \ucc98\ub9ac\ud569\ub2c8\ub2e4\"\"\"\n        cmd = command.split()[0]\n        if cmd in self.commands:\n            return self.commands[cmd]()\n        else:\n            return f\"\uc54c \uc218 \uc5c6\ub294 \uba85\ub839\uc5b4\uc785\ub2c8\ub2e4. /help\ub97c \uc785\ub825\ud574 \ub3c4\uc6c0\ub9d0\uc744 \ud655\uc778\ud558\uc138\uc694.\"\n\n    def show_help(self):\n        \"\"\"\ub3c4\uc6c0\ub9d0\uc744 \ud45c\uc2dc\ud569\ub2c8\ub2e4\"\"\"\n        return \"\"\"\n\ud83d\udccb \uc0ac\uc6a9 \uac00\ub2a5\ud55c \uba85\ub839\uc5b4:\n/help - \uc774 \ub3c4\uc6c0\ub9d0 \ud45c\uc2dc\n/clear - \ub300\ud654 \uae30\ub85d \ucd08\uae30\ud654\n/save - \ub300\ud654 \uc800\uc7a5\n/stats - \ub300\ud654 \ud1b5\uacc4 \ubcf4\uae30\n        \"\"\"\n\n    def clear_history(self):\n        \"\"\"\ub300\ud654 \uae30\ub85d\uc744 \ucd08\uae30\ud654\ud569\ub2c8\ub2e4\"\"\"\n        self.messages = []\n        return \"\ub300\ud654 \uae30\ub85d\uc774 \ucd08\uae30\ud654\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ud83d\uddd1\ufe0f\"\n\n    def save_conversation(self):\n        \"\"\"\ub300\ud654\ub97c \ud30c\uc77c\ub85c \uc800\uc7a5\ud569\ub2c8\ub2e4\"\"\"\n        from datetime import datetime\n\n        filename = f\"chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n\n        with open(filename, 'w', encoding='utf-8') as f:\n            f.write(f\"=== {self.name} \ub300\ud654 \uae30\ub85d ===\\n\")\n            f.write(f\"\uc77c\uc2dc: {datetime.now()}\\n\\n\")\n\n            for msg in self.messages:\n                role = \"You\" if msg[\"role\"] == \"user\" else self.name\n                f.write(f\"{role}: {msg['content']}\\n\\n\")\n\n        return f\"\ub300\ud654\uac00 {filename}\uc5d0 \uc800\uc7a5\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ud83d\udcbe\"\n\n    def show_stats(self):\n        \"\"\"\ub300\ud654 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4\"\"\"\n        user_messages = [m for m in self.messages if m[\"role\"] == \"user\"]\n        bot_messages = [m for m in self.messages if m[\"role\"] == \"assistant\"]\n\n        total_user_chars = sum(len(m[\"content\"]) for m in user_messages)\n        total_bot_chars = sum(len(m[\"content\"]) for m in bot_messages)\n\n        return f\"\"\"\n\ud83d\udcca \ub300\ud654 \ud1b5\uacc4:\n- \ucd1d \uba54\uc2dc\uc9c0: {len(self.messages)}\uac1c\n- \uc0ac\uc6a9\uc790 \uba54\uc2dc\uc9c0: {len(user_messages)}\uac1c ({total_user_chars}\uc790)\n- \ubd07 \uba54\uc2dc\uc9c0: {len(bot_messages)}\uac1c ({total_bot_chars}\uc790)\n- \ud3c9\uade0 \uc751\ub2f5 \uae38\uc774: {total_bot_chars // max(len(bot_messages), 1)}\uc790\n        \"\"\"\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nbot = FeatureRichChatbot()\n# bot.run()  # \uc2e4\ud589\ud558\uba74 \ub300\ud654\ud615 \ubaa8\ub4dc\ub85c \uc9c4\uc785\n</code></pre>"},{"location":"examples/03-conversations/chatbot-basics/#_4","title":"\ud83c\udfa8 \ud2b9\ud654\ub41c \ucc57\ubd07 \ub9cc\ub4e4\uae30","text":""},{"location":"examples/03-conversations/chatbot-basics/#1","title":"1. \ud559\uc2b5 \ub3c4\uc6b0\ubbf8 \ucc57\ubd07","text":"<pre><code>class StudyBuddyBot(SimpleChatbot):\n    \"\"\"\ud559\uc2b5\uc744 \ub3c4\uc640\uc8fc\ub294 \ucc57\ubd07\"\"\"\n\n    def __init__(self):\n        super().__init__(\"\ud559\uc2b5 \ub3c4\uc6b0\ubbf8\")\n        self.subject = None\n        self.study_mode = None\n\n    def greet(self):\n        \"\"\"\ud559\uc2b5 \ubaa8\ub4dc \uc120\ud0dd\"\"\"\n        print(f\"\"\"\n\ud83d\udcda \uc548\ub155\ud558\uc138\uc694! {self.name}\uc785\ub2c8\ub2e4.\n\uc5b4\ub5a4 \uacf5\ubd80\ub97c \ub3c4\uc640\ub4dc\ub9b4\uae4c\uc694?\n\n1. \uac1c\ub150 \uc124\uba85\n2. \ubb38\uc81c \ud480\uc774\n3. \uc694\uc57d \uc815\ub9ac\n4. \ud034\uc988 \ub9cc\ub4e4\uae30\n\n\uc6d0\ud558\ub294 \ubc88\ud638\ub97c \uc120\ud0dd\ud558\uac70\ub098 \uc790\uc720\ub86d\uac8c \uc9c8\ubb38\ud558\uc138\uc694!\n        \"\"\")\n\n    def chat(self, user_input):\n        \"\"\"\ud559\uc2b5 \ubaa8\ub4dc\uc5d0 \ub530\ub77c \ub2e4\ub974\uac8c \uc751\ub2f5\"\"\"\n        # \ubaa8\ub4dc \uc120\ud0dd\n        if user_input in [\"1\", \"2\", \"3\", \"4\"]:\n            modes = {\n                \"1\": \"\uac1c\ub150 \uc124\uba85\",\n                \"2\": \"\ubb38\uc81c \ud480\uc774\", \n                \"3\": \"\uc694\uc57d \uc815\ub9ac\",\n                \"4\": \"\ud034\uc988\"\n            }\n            self.study_mode = modes[user_input]\n            return f\"{self.study_mode} \ubaa8\ub4dc\ub97c \uc120\ud0dd\ud558\uc168\uc2b5\ub2c8\ub2e4. \ubb34\uc5c7\uc744 \uacf5\ubd80\ud558\uc2dc\ub098\uc694?\"\n\n        # \ud559\uc2b5 \ubaa8\ub4dc\ubcc4 \ud504\ub86c\ud504\ud2b8 \uc870\uc815\n        if self.study_mode:\n            context_addon = f\"\\n\ud604\uc7ac {self.study_mode} \ubaa8\ub4dc\uc785\ub2c8\ub2e4. \uc774\uc5d0 \ub9de\uac8c \ub2f5\ubcc0\ud574\uc8fc\uc138\uc694.\"\n        else:\n            context_addon = \"\"\n\n        # \uae30\ubcf8 \ub300\ud654 + \ud559\uc2b5 \ucee8\ud14d\uc2a4\ud2b8\n        self.messages.append({\"role\": \"user\", \"content\": user_input})\n\n        context = f\"\"\"\ub2f9\uc2e0\uc740 \uce5c\uc808\ud55c \ud559\uc2b5 \ub3c4\uc6b0\ubbf8\uc785\ub2c8\ub2e4.\n\ud559\uc0dd\uc774 \uc774\ud574\ud558\uae30 \uc27d\uac8c \uc124\uba85\ud558\uace0, \uaca9\ub824\ud558\uba70 \ub3c4\uc640\uc8fc\uc138\uc694.{context_addon}\n\n\"\"\"\n\n        for msg in self.messages:\n            if msg[\"role\"] == \"user\":\n                context += f\"\ud559\uc0dd: {msg['content']}\\n\"\n            else:\n                context += f\"\ub3c4\uc6b0\ubbf8: {msg['content']}\\n\"\n\n        context += \"\ub3c4\uc6b0\ubbf8:\"\n\n        response = self.ai.ask(context)\n        self.messages.append({\"role\": \"assistant\", \"content\": response.text})\n\n        return response.text\n\n    def create_quiz(self, topic, num_questions=5):\n        \"\"\"\uc8fc\uc81c\uc5d0 \ub300\ud55c \ud034\uc988\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n{topic}\uc5d0 \ub300\ud55c \ud034\uc988 {num_questions}\uac1c\ub97c \ub9cc\ub4e4\uc5b4\uc8fc\uc138\uc694.\n\n\ud615\uc2dd:\nQ1. \uc9c8\ubb38\nA1. \ub2f5\ubcc0\n\nQ2. \uc9c8\ubb38  \nA2. \ub2f5\ubcc0\n\n\ub09c\uc774\ub3c4\ub294 \ucd08\uae09\uc5d0\uc11c \uc911\uae09 \uc218\uc900\uc73c\ub85c \ub9cc\ub4e4\uc5b4\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def explain_concept(self, concept, level=\"beginner\"):\n        \"\"\"\uac1c\ub150\uc744 \uc124\uba85\ud569\ub2c8\ub2e4\"\"\"\n        levels = {\n            \"beginner\": \"\ucd08\ub4f1\ud559\uc0dd\ub3c4 \uc774\ud574\ud560 \uc218 \uc788\uac8c\",\n            \"intermediate\": \"\uc911\uace0\ub4f1\ud559\uc0dd \uc218\uc900\uc73c\ub85c\",\n            \"advanced\": \"\ub300\ud559\uc0dd \uc218\uc900\uc73c\ub85c\"\n        }\n\n        level_desc = levels.get(level, level)\n\n        prompt = f\"{concept}\uc744 {level_desc} \uc124\uba85\ud574\uc8fc\uc138\uc694. \uc608\uc2dc\ub97c \ud3ec\ud568\ud574\uc8fc\uc138\uc694.\"\n        response = self.ai.ask(prompt)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nstudy_bot = StudyBuddyBot()\n\n# \uac1c\ub150 \uc124\uba85\nprint(\"\ud83d\udcd6 \uac1c\ub150 \uc124\uba85:\")\nprint(study_bot.explain_concept(\"\uc7ac\uadc0\ud568\uc218\", \"beginner\"))\n\n# \ud034\uc988 \uc0dd\uc131\nprint(\"\\n\ud83d\udcdd \ud034\uc988:\")\nprint(study_bot.create_quiz(\"\ud30c\uc774\uc36c \ub9ac\uc2a4\ud2b8\", 3))\n</code></pre>"},{"location":"examples/03-conversations/chatbot-basics/#2","title":"2. \uace0\uac1d \uc11c\ube44\uc2a4 \ucc57\ubd07","text":"<pre><code>class CustomerServiceBot(SimpleChatbot):\n    \"\"\"\uace0\uac1d \uc11c\ube44\uc2a4 \ucc57\ubd07\"\"\"\n\n    def __init__(self, company_name=\"\uc6b0\ub9ac \ud68c\uc0ac\"):\n        super().__init__(f\"{company_name} \uace0\uac1d\uc13c\ud130\")\n        self.company_name = company_name\n        self.customer_info = {}\n        self.ticket_number = None\n\n    def greet(self):\n        \"\"\"\uace0\uac1d \uc11c\ube44\uc2a4 \uc778\uc0ac\ub9d0\"\"\"\n        print(f\"\"\"\n\ud83c\udfe2 {self.company_name} \uace0\uac1d\uc13c\ud130\uc785\ub2c8\ub2e4.\n\uc5b4\ub5a4 \ub3c4\uc6c0\uc774 \ud544\uc694\ud558\uc2e0\uac00\uc694?\n\n\uc790\uc8fc \ubb3b\ub294 \uc9c8\ubb38:\n1. \uc8fc\ubb38 \uc870\ud68c\n2. \ud658\ubd88/\uad50\ud658\n3. \uc81c\ud488 \ubb38\uc758\n4. \uae30\ud0c0 \ubb38\uc758\n\n\ubc88\ud638\ub97c \uc120\ud0dd\ud558\uac70\ub098 \uc9c1\uc811 \ubb38\uc758\uc0ac\ud56d\uc744 \uc785\ub825\ud574\uc8fc\uc138\uc694.\n        \"\"\")\n\n    def chat(self, user_input):\n        \"\"\"\uace0\uac1d \uc751\ub300\"\"\"\n        # \ucd08\uae30 \uc815\ubcf4 \uc218\uc9d1\n        if not self.customer_info.get(\"name\"):\n            self.customer_info[\"name\"] = user_input\n            return \"\uac10\uc0ac\ud569\ub2c8\ub2e4. \uc5f0\ub77d \uac00\ub2a5\ud55c \uc804\ud654\ubc88\ud638\ub97c \uc54c\ub824\uc8fc\uc138\uc694.\"\n\n        if not self.customer_info.get(\"phone\"):\n            self.customer_info[\"phone\"] = user_input\n            return f\"\"\"\n{self.customer_info['name']}\ub2d8, \ud655\uc778\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\uc5b4\ub5a4 \ubb38\uc81c\ub85c \uc5f0\ub77d\uc8fc\uc168\ub098\uc694? \uc790\uc138\ud788 \uc124\uba85\ud574\uc8fc\uc138\uc694.\n            \"\"\"\n\n        # \uc77c\ubc18 \uc0c1\ub2f4 \uc9c4\ud589\n        self.messages.append({\"role\": \"user\", \"content\": user_input})\n\n        context = f\"\"\"\ub2f9\uc2e0\uc740 {self.company_name}\uc758 \uce5c\uc808\ud55c \uace0\uac1d \uc11c\ube44\uc2a4 \uc0c1\ub2f4\uc6d0\uc785\ub2c8\ub2e4.\n\uace0\uac1d \uc815\ubcf4:\n- \uc774\ub984: {self.customer_info.get('name', '\ubbf8\ud655\uc778')}\n- \uc804\ud654: {self.customer_info.get('phone', '\ubbf8\ud655\uc778')}\n\n\uacf5\uc190\ud558\uace0 \uc804\ubb38\uc801\uc73c\ub85c \uc751\ub300\ud558\uba70, \uace0\uac1d\uc758 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub3c4\ub85d \ub3c4\uc640\uc8fc\uc138\uc694.\n\n\ub300\ud654 \ub0b4\uc6a9:\n\"\"\"\n\n        for msg in self.messages:\n            if msg[\"role\"] == \"user\":\n                context += f\"\uace0\uac1d: {msg['content']}\\n\"\n            else:\n                context += f\"\uc0c1\ub2f4\uc6d0: {msg['content']}\\n\"\n\n        context += \"\uc0c1\ub2f4\uc6d0:\"\n\n        response = self.ai.ask(context)\n        self.messages.append({\"role\": \"assistant\", \"content\": response.text})\n\n        # \ud2f0\ucf13 \uc0dd\uc131 \uc81c\uc548\n        if len(self.messages) &gt; 6 and not self.ticket_number:\n            self.ticket_number = self._generate_ticket()\n            response.text += f\"\\n\\n\ud83d\udccb \uc0c1\ub2f4 \ub0b4\uc6a9\uc744 \uc811\uc218\ud588\uc2b5\ub2c8\ub2e4. \uc811\uc218\ubc88\ud638: {self.ticket_number}\"\n\n        return response.text\n\n    def _generate_ticket(self):\n        \"\"\"\ud2f0\ucf13 \ubc88\ud638\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4\"\"\"\n        from datetime import datetime\n        import random\n\n        date = datetime.now().strftime(\"%Y%m%d\")\n        rand = random.randint(1000, 9999)\n        return f\"TK{date}{rand}\"\n\n    def escalate_to_human(self):\n        \"\"\"\uc0c1\ub2f4\uc6d0 \uc5f0\uacb0\"\"\"\n        return \"\"\"\n\ud83d\ude4b \uc2e4\uc81c \uc0c1\ub2f4\uc6d0\uacfc \uc5f0\uacb0\ud574\ub4dc\ub9ac\uaca0\uc2b5\ub2c8\ub2e4.\n\uc608\uc0c1 \ub300\uae30 \uc2dc\uac04: \uc57d 5\ubd84\n\uc5f0\uacb0\ub418\uba74 \uc54c\ub9bc\uc744 \ubcf4\ub0b4\ub4dc\ub9ac\uaca0\uc2b5\ub2c8\ub2e4.\n\ub300\uae30 \uc911\uc5d0\ub3c4 \uacc4\uc18d \ubb38\uc758\uc0ac\ud56d\uc744 \uc785\ub825\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n        \"\"\"\n\n# \uc0ac\uc6a9 \uc608\uc2dc\ncs_bot = CustomerServiceBot(\"\ud14c\ud06c\uc0f5\")\n# cs_bot.run()  # \uc2e4\ud589\ud558\uba74 \uace0\uac1d \uc11c\ube44\uc2a4 \ubaa8\ub4dc\ub85c \uc9c4\uc785\n</code></pre>"},{"location":"examples/03-conversations/chatbot-basics/#3","title":"3. \ucc3d\uc758\uc801 \ub300\ud654 \ucc57\ubd07","text":"<pre><code>class CreativeChatbot(SimpleChatbot):\n    \"\"\"\ucc3d\uc758\uc801\uc778 \ub300\ud654\ub97c \ud558\ub294 \ucc57\ubd07\"\"\"\n\n    def __init__(self):\n        super().__init__(\"\ucc3d\uc758\ubd07\")\n        self.personality_traits = {\n            \"humor\": 0.7,      # \uc720\uba38 \uc218\uc900\n            \"creativity\": 0.9,  # \ucc3d\uc758\uc131\n            \"formality\": 0.3   # \uaca9\uc2dd\n        }\n\n    def chat(self, user_input):\n        \"\"\"\ucc3d\uc758\uc801\uc778 \uc751\ub2f5\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4\"\"\"\n        self.messages.append({\"role\": \"user\", \"content\": user_input})\n\n        # \uc131\uaca9 \ud2b9\uc131\uc744 \ud504\ub86c\ud504\ud2b8\uc5d0 \ubc18\uc601\n        personality_prompt = f\"\"\"\n\ub2f9\uc2e0\uc740 \ub2e4\uc74c\uacfc \uac19\uc740 \uc131\uaca9\uc744 \uac00\uc9c4 AI\uc785\ub2c8\ub2e4:\n- \uc720\uba38 \uac10\uac01: {'\ub192\uc74c' if self.personality_traits['humor'] &gt; 0.6 else '\ubcf4\ud1b5'}\n- \ucc3d\uc758\uc131: {'\ub9e4\uc6b0 \ub192\uc74c' if self.personality_traits['creativity'] &gt; 0.8 else '\ub192\uc74c'}\n- \uaca9\uc2dd: {'\uce90\uc8fc\uc5bc' if self.personality_traits['formality'] &lt; 0.5 else '\uaca9\uc2dd\uc788\uc74c'}\n\n\uc774\ub7f0 \uc131\uaca9\uc5d0 \ub9de\uac8c \uc7ac\ubbf8\uc788\uace0 \ucc3d\uc758\uc801\uc73c\ub85c \ub300\ub2f5\ud558\uc138\uc694.\n\uac00\ub054 \uc740\uc720\ub098 \ube44\uc720\ub97c \uc0ac\uc6a9\ud558\uace0, \uc0c1\uc0c1\ub825\uc744 \ubc1c\ud718\ud558\uc138\uc694.\n        \"\"\"\n\n        context = personality_prompt + \"\\n\\n\ub300\ud654:\\n\"\n\n        for msg in self.messages[-10:]:  # \ucd5c\uadfc 10\uac1c\ub9cc\n            if msg[\"role\"] == \"user\":\n                context += f\"\uc0ac\uc6a9\uc790: {msg['content']}\\n\"\n            else:\n                context += f\"\ucc3d\uc758\ubd07: {msg['content']}\\n\"\n\n        context += \"\ucc3d\uc758\ubd07:\"\n\n        # \ucc3d\uc758\uc131 \uc628\ub3c4 \uc124\uc815\n        response = self.ai.ask(\n            context, \n            temperature=self.personality_traits['creativity']\n        )\n\n        self.messages.append({\"role\": \"assistant\", \"content\": response.text})\n        return response.text\n\n    def tell_story(self, theme):\n        \"\"\"\uc8fc\uc81c\uc5d0 \ub9de\ub294 \uc9e7\uc740 \uc774\uc57c\uae30\ub97c \ub9cc\ub4ed\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n'{theme}'\ub97c \uc8fc\uc81c\ub85c \uc9e7\uace0 \uc7ac\ubbf8\uc788\ub294 \uc774\uc57c\uae30\ub97c \ub9cc\ub4e4\uc5b4\uc8fc\uc138\uc694.\n200\uc790 \uc774\ub0b4\ub85c \ucc3d\uc758\uc801\uc774\uace0 \uc608\uc0c1\uce58 \ubabb\ud55c \uc804\uac1c\ub97c \ud3ec\ud568\ud558\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt, temperature=0.9)\n        return f\"\ud83d\udcd6 \uc989\uc11d \uc774\uc57c\uae30: {theme}\\n\\n{response.text}\"\n\n    def play_word_game(self, start_word):\n        \"\"\"\ub05d\ub9d0\uc787\uae30\ub098 \uc5f0\uc0c1 \uac8c\uc784\uc744 \ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n'{start_word}'\ub85c \uc2dc\uc791\ud558\ub294 \ucc3d\uc758\uc801\uc778 \ub2e8\uc5b4 \uc5f0\uc0c1 \uac8c\uc784\uc744 \ud574\ubd05\uc2dc\ub2e4.\n5\uac1c\uc758 \uc5f0\uad00 \ub2e8\uc5b4\ub97c \uc81c\uc2dc\ud558\uace0 \uac01\uac01 \uc7ac\ubbf8\uc788\uac8c \uc124\uba85\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt, temperature=0.8)\n        return response.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\ncreative_bot = CreativeChatbot()\n\n# \uc774\uc57c\uae30 \ub9cc\ub4e4\uae30\nprint(\"\ud83d\udcda \uc989\uc11d \uc774\uc57c\uae30:\")\nprint(creative_bot.tell_story(\"AI\uc640 \uace0\uc591\uc774\"))\n\n# \ub2e8\uc5b4 \uac8c\uc784\nprint(\"\\n\ud83c\udfae \ub2e8\uc5b4 \uc5f0\uc0c1 \uac8c\uc784:\")\nprint(creative_bot.play_word_game(\"\ud30c\uc774\uc36c\"))\n</code></pre>"},{"location":"examples/03-conversations/chatbot-basics/#_5","title":"\ud83d\udd27 \ucc57\ubd07 \uac1c\uc120 \uae30\ubc95","text":""},{"location":"examples/03-conversations/chatbot-basics/#1_1","title":"1. \uc751\ub2f5 \uc2dc\uac04 \ud45c\uc2dc","text":"<pre><code>import time\n\nclass TimedChatbot(SimpleChatbot):\n    \"\"\"\uc751\ub2f5 \uc2dc\uac04\uc744 \uce21\uc815\ud558\ub294 \ucc57\ubd07\"\"\"\n\n    def chat(self, user_input):\n        start_time = time.time()\n\n        # \ud0c0\uc774\ud551 \ud6a8\uacfc\n        print(\"\ud83e\udd16 \uc0dd\uac01 \uc911\", end=\"\", flush=True)\n        for _ in range(3):\n            time.sleep(0.5)\n            print(\".\", end=\"\", flush=True)\n        print()\n\n        # \uc2e4\uc81c \uc751\ub2f5 \uc0dd\uc131\n        response = super().chat(user_input)\n\n        # \uc751\ub2f5 \uc2dc\uac04 \uacc4\uc0b0\n        elapsed = time.time() - start_time\n        print(f\"\u23f1\ufe0f \uc751\ub2f5 \uc2dc\uac04: {elapsed:.2f}\ucd08\")\n\n        return response\n</code></pre>"},{"location":"examples/03-conversations/chatbot-basics/#2_1","title":"2. \uac10\uc815 \ubd84\uc11d \ucc57\ubd07","text":"<pre><code>class EmotionalChatbot(SimpleChatbot):\n    \"\"\"\uc0ac\uc6a9\uc790\uc758 \uac10\uc815\uc744 \uc778\uc2dd\ud558\ub294 \ucc57\ubd07\"\"\"\n\n    def analyze_emotion(self, text):\n        \"\"\"\ud14d\uc2a4\ud2b8\uc758 \uac10\uc815\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n\ub2e4\uc74c \ud14d\uc2a4\ud2b8\uc758 \uac10\uc815\uc744 \ubd84\uc11d\ud574\uc8fc\uc138\uc694:\n\"{text}\"\n\n\ub2e4\uc74c \uc911 \ud558\ub098\ub85c\ub9cc \ub2f5\ud558\uc138\uc694: \uae0d\uc815\uc801, \ubd80\uc815\uc801, \uc911\ub9bd\uc801\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text.strip()\n\n    def chat(self, user_input):\n        # \uac10\uc815 \ubd84\uc11d\n        emotion = self.analyze_emotion(user_input)\n\n        # \uac10\uc815\uc5d0 \ub530\ub978 \uc774\ubaa8\ud2f0\ucf58\n        emotion_emoji = {\n            \"\uae0d\uc815\uc801\": \"\ud83d\ude0a\",\n            \"\ubd80\uc815\uc801\": \"\ud83d\ude14\", \n            \"\uc911\ub9bd\uc801\": \"\ud83d\ude10\"\n        }\n\n        # \uac10\uc815 \ud45c\uc2dc\n        print(f\"\uac10\uc9c0\ub41c \uac10\uc815: {emotion} {emotion_emoji.get(emotion, '')}\")\n\n        # \uac10\uc815\uc744 \uace0\ub824\ud55c \uc751\ub2f5\n        self.messages.append({\n            \"role\": \"user\",\n            \"content\": user_input,\n            \"emotion\": emotion\n        })\n\n        context = f\"\"\"\n\uc0ac\uc6a9\uc790\uc758 \ud604\uc7ac \uac10\uc815 \uc0c1\ud0dc\ub294 '{emotion}'\uc785\ub2c8\ub2e4.\n\uc774\ub97c \uace0\ub824\ud558\uc5ec \uacf5\uac10\ud558\uba70 \uc801\uc808\ud788 \uc751\ub2f5\ud558\uc138\uc694.\n\n\ub300\ud654:\n\"\"\"\n\n        for msg in self.messages[-5:]:\n            if msg[\"role\"] == \"user\":\n                context += f\"\uc0ac\uc6a9\uc790: {msg['content']}\\n\"\n            else:\n                context += f\"\ubd07: {msg['content']}\\n\"\n\n        context += \"\ubd07:\"\n\n        response = self.ai.ask(context)\n        self.messages.append({\"role\": \"assistant\", \"content\": response.text})\n\n        return response.text\n</code></pre>"},{"location":"examples/03-conversations/chatbot-basics/#3_1","title":"3. \ub2e4\uad6d\uc5b4 \uc9c0\uc6d0 \ucc57\ubd07","text":"<pre><code>class MultilingualChatbot(SimpleChatbot):\n    \"\"\"\ub2e4\uad6d\uc5b4\ub97c \uc9c0\uc6d0\ud558\ub294 \ucc57\ubd07\"\"\"\n\n    def __init__(self):\n        super().__init__(\"\uae00\ub85c\ubc8c \ubd07\")\n        self.language = \"Korean\"\n        self.supported_languages = {\n            \"Korean\": \"\ud55c\uad6d\uc5b4\",\n            \"English\": \"\uc601\uc5b4\",\n            \"Japanese\": \"\uc77c\ubcf8\uc5b4\",\n            \"Chinese\": \"\uc911\uad6d\uc5b4\"\n        }\n\n    def detect_language(self, text):\n        \"\"\"\uc5b8\uc5b4\ub97c \uac10\uc9c0\ud569\ub2c8\ub2e4\"\"\"\n        prompt = f\"\"\"\n\ub2e4\uc74c \ud14d\uc2a4\ud2b8\uc758 \uc5b8\uc5b4\ub97c \uac10\uc9c0\ud574\uc8fc\uc138\uc694: \"{text}\"\nKorean, English, Japanese, Chinese \uc911 \ud558\ub098\ub85c\ub9cc \ub2f5\ud558\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        detected = response.text.strip()\n\n        if detected in self.supported_languages:\n            self.language = detected\n\n        return detected\n\n    def chat(self, user_input):\n        # \uc5b8\uc5b4 \uac10\uc9c0\n        detected_lang = self.detect_language(user_input)\n\n        # \uc5b8\uc5b4\ubcc4 \uc751\ub2f5\n        self.messages.append({\"role\": \"user\", \"content\": user_input})\n\n        context = f\"\"\"\n{self.supported_languages[self.language]}\ub85c \uc751\ub2f5\ud558\uc138\uc694.\n\uc0ac\uc6a9\uc790\uac00 \uc0ac\uc6a9\ud55c \uc5b8\uc5b4\uc640 \uac19\uc740 \uc5b8\uc5b4\ub85c \ub2f5\ubcc0\ud558\uc138\uc694.\n\n\ub300\ud654:\n\"\"\"\n\n        for msg in self.messages[-5:]:\n            if msg[\"role\"] == \"user\":\n                context += f\"User: {msg['content']}\\n\"\n            else:\n                context += f\"Bot: {msg['content']}\\n\"\n\n        context += \"Bot:\"\n\n        response = self.ai.ask(context)\n        self.messages.append({\"role\": \"assistant\", \"content\": response.text})\n\n        return f\"[{self.supported_languages[self.language]}] {response.text}\"\n</code></pre>"},{"location":"examples/03-conversations/chatbot-basics/#_6","title":"\ud83d\udcca \ucc57\ubd07 \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1","text":"<pre><code>class MonitoredChatbot(SimpleChatbot):\n    \"\"\"\uc131\ub2a5\uc744 \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \ucc57\ubd07\"\"\"\n\n    def __init__(self):\n        super().__init__(\"\ubaa8\ub2c8\ud130\ubd07\")\n        self.metrics = {\n            \"total_messages\": 0,\n            \"total_tokens\": 0,\n            \"response_times\": [],\n            \"user_satisfaction\": []\n        }\n\n    def chat(self, user_input):\n        import time\n\n        start = time.time()\n        response = super().chat(user_input)\n        elapsed = time.time() - start\n\n        # \uba54\ud2b8\ub9ad \uc5c5\ub370\uc774\ud2b8\n        self.metrics[\"total_messages\"] += 2  # \uc0ac\uc6a9\uc790 + \ubd07\n        self.metrics[\"response_times\"].append(elapsed)\n\n        # \ud1a0\ud070 \ucd94\uc815 (\uc2e4\uc81c\ub85c\ub294 API \uc751\ub2f5\uc5d0\uc11c \uac00\uc838\uc640\uc57c \ud568)\n        estimated_tokens = len(user_input + response) // 4\n        self.metrics[\"total_tokens\"] += estimated_tokens\n\n        return response\n\n    def ask_satisfaction(self):\n        \"\"\"\ub9cc\uc871\ub3c4\ub97c \ubb3b\uc2b5\ub2c8\ub2e4\"\"\"\n        print(\"\\n\uc774\ubc88 \ub300\ud654\ub294 \ub9cc\uc871\uc2a4\ub7ec\uc6b0\uc168\ub098\uc694? (1-5\uc810)\")\n        try:\n            score = int(input(\"\uc810\uc218: \"))\n            if 1 &lt;= score &lt;= 5:\n                self.metrics[\"user_satisfaction\"].append(score)\n                return \"\ud53c\ub4dc\ubc31 \uac10\uc0ac\ud569\ub2c8\ub2e4!\"\n        except:\n            pass\n        return \"\ub2e4\uc74c\uc5d0 \ud3c9\uac00\ud574\uc8fc\uc138\uc694!\"\n\n    def show_metrics(self):\n        \"\"\"\uc131\ub2a5 \uc9c0\ud45c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4\"\"\"\n        avg_response = sum(self.metrics[\"response_times\"]) / max(len(self.metrics[\"response_times\"]), 1)\n        avg_satisfaction = sum(self.metrics[\"user_satisfaction\"]) / max(len(self.metrics[\"user_satisfaction\"]), 1)\n\n        return f\"\"\"\n\ud83d\udcca \ucc57\ubd07 \uc131\ub2a5 \uc9c0\ud45c:\n- \ucd1d \uba54\uc2dc\uc9c0: {self.metrics['total_messages']}\uac1c\n- \ucd1d \ud1a0\ud070 \uc0ac\uc6a9: {self.metrics['total_tokens']}\uac1c\n- \ud3c9\uade0 \uc751\ub2f5 \uc2dc\uac04: {avg_response:.2f}\ucd08\n- \ud3c9\uade0 \ub9cc\uc871\ub3c4: {avg_satisfaction:.1f}/5.0\n- \uc608\uc0c1 \ube44\uc6a9: ${self.metrics['total_tokens'] * 0.000002:.4f}\n        \"\"\"\n</code></pre>"},{"location":"examples/03-conversations/chatbot-basics/#_7","title":"\u2705 \ud575\uc2ec \uc815\ub9ac","text":"<ol> <li>\uae30\ubcf8 \uad6c\uc870 - \uba54\uc2dc\uc9c0 \uad00\ub9ac, \ub9e5\ub77d \uad6c\uc131, \uc751\ub2f5 \uc0dd\uc131</li> <li>\ud2b9\ud654 \uae30\ub2a5 - \ubaa9\uc801\uc5d0 \ub9de\ub294 \ucc57\ubd07 \uc124\uacc4</li> <li>\uc0ac\uc6a9\uc790 \uacbd\ud5d8 - \uba85\ub839\uc5b4, \uac10\uc815 \uc778\uc2dd, \ub2e4\uad6d\uc5b4 \uc9c0\uc6d0</li> <li>\uc131\ub2a5 \uad00\ub9ac - \uba54\ud2b8\ub9ad \ucd94\uc801, \ucd5c\uc801\ud654</li> </ol>"},{"location":"examples/03-conversations/chatbot-basics/#_8","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>\ucc57\ubd07\uc744 \ub9cc\ub4e4\uc5c8\uc73c\ub2c8, \uc774\uc81c \ub300\ud654 \uc798\ud558\ub294 \ubc95\uc5d0\uc11c \ub354 \ub098\uc740 \ub300\ud654\ub97c \uc704\ud55c \ud301\uc744 \uc54c\uc544\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/03-conversations/remembering-context/","title":"\ud83e\udde0 AI\uac00 \ub300\ud654\ub97c \uae30\uc5b5\ud558\ub294 \ubc29\ubc95","text":"<p>AI\uac00 \uc5b4\ub5bb\uac8c \uc774\uc804 \ub300\ud654\ub97c \uae30\uc5b5\ud558\uace0 \ub9e5\ub77d\uc744 \uc774\ud574\ud558\ub294\uc9c0 \uc54c\uc544\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/03-conversations/remembering-context/#_1","title":"\ud83c\udfaf \ub300\ud654 \uae30\uc5b5\uc758 \uc6d0\ub9ac","text":""},{"location":"examples/03-conversations/remembering-context/#ai_1","title":"AI\ub294 \uc0ac\uc2e4 \uae30\uc5b5\ud558\uc9c0 \ubabb\ud569\ub2c8\ub2e4!","text":"<pre><code>from pyhub.llm import LLM\n\nai = LLM.create(\"gpt-4o-mini\")\n\n# \uccab \ubc88\uc9f8 \ub300\ud654\nresponse1 = ai.ask(\"\ub0b4 \uc774\ub984\uc740 \uae40\ucca0\uc218\uc785\ub2c8\ub2e4\")\nprint(response1.text)  # \"\uc548\ub155\ud558\uc138\uc694, \uae40\ucca0\uc218\ub2d8!\"\n\n# \ub450 \ubc88\uc9f8 \ub300\ud654 - AI\ub294 \uc774\uc804 \ub300\ud654\ub97c \ubaa8\ub985\ub2c8\ub2e4!\nresponse2 = ai.ask(\"\ub0b4 \uc774\ub984\uc774 \ubb50\ub77c\uace0 \ud588\uc8e0?\")\nprint(response2.text)  # \"\uc8c4\uc1a1\ud558\uc9c0\ub9cc, \uc774\ub984\uc744 \uc54c\ub824\uc8fc\uc9c0 \uc54a\uc73c\uc168\uc2b5\ub2c8\ub2e4.\"\n</code></pre>"},{"location":"examples/03-conversations/remembering-context/#_2","title":"\uadf8\ub7fc \uc5b4\ub5bb\uac8c \uae30\uc5b5\ud558\uac8c \ub9cc\ub4e4\uae4c\uc694?","text":"<p>\ube44\ubc00\uc740 \"\ub300\ud654 \uae30\ub85d\uc744 \ud568\uaed8 \ubcf4\ub0b4\uae30\"\uc785\ub2c8\ub2e4!</p> <pre><code># \ub300\ud654 \uae30\ub85d\uc744 \ub9cc\ub4e4\uc5b4\uc11c \ud568\uaed8 \ubcf4\ub0c5\ub2c8\ub2e4\nconversation = \"\"\"\n\uc0ac\uc6a9\uc790: \ub0b4 \uc774\ub984\uc740 \uae40\ucca0\uc218\uc785\ub2c8\ub2e4\nAI: \uc548\ub155\ud558\uc138\uc694, \uae40\ucca0\uc218\ub2d8!\n\uc0ac\uc6a9\uc790: \ub0b4 \uc774\ub984\uc774 \ubb50\ub77c\uace0 \ud588\uc8e0?\n\"\"\"\n\nresponse = ai.ask(conversation + \"\\nAI:\")\nprint(response.text)  # \"\uae40\ucca0\uc218\ub2d8\uc774\ub77c\uace0 \ub9d0\uc500\ud558\uc168\uc2b5\ub2c8\ub2e4.\"\n</code></pre>"},{"location":"examples/03-conversations/remembering-context/#_3","title":"\ud83d\udcdd \ub300\ud654 \uae30\ub85d \uad00\ub9ac\ud558\uae30","text":""},{"location":"examples/03-conversations/remembering-context/#step-1","title":"Step 1: \uac04\ub2e8\ud55c \ub300\ud654 \uae30\ub85d \uc2dc\uc2a4\ud15c","text":"<pre><code>class SimpleChat:\n    \"\"\"\uac04\ub2e8\ud55c \ub300\ud654 \uae30\ub85d \uad00\ub9ac \uc2dc\uc2a4\ud15c\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.ai = LLM.create(model)\n        self.history = []  # \ub300\ud654 \uae30\ub85d\uc744 \uc800\uc7a5\ud560 \ub9ac\uc2a4\ud2b8\n\n    def chat(self, user_message):\n        \"\"\"\uc0ac\uc6a9\uc790 \uba54\uc2dc\uc9c0\ub97c \ubc1b\uc544 AI \uc751\ub2f5\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4\"\"\"\n\n        # 1. \uc0ac\uc6a9\uc790 \uba54\uc2dc\uc9c0\ub97c \uae30\ub85d\uc5d0 \ucd94\uac00\n        self.history.append(f\"\uc0ac\uc6a9\uc790: {user_message}\")\n\n        # 2. \uc804\uccb4 \ub300\ud654 \uae30\ub85d\uc744 \ub9cc\ub4e4\uae30\n        full_conversation = \"\\n\".join(self.history)\n\n        # 3. AI\uc5d0\uac8c \uc804\uccb4 \ub300\ud654\ub97c \ubcf4\ub0b4\uae30\n        prompt = f\"{full_conversation}\\nAI:\"\n        response = self.ai.ask(prompt)\n\n        # 4. AI \uc751\ub2f5\uc744 \uae30\ub85d\uc5d0 \ucd94\uac00\n        self.history.append(f\"AI: {response.text}\")\n\n        return response.text\n\n    def show_history(self):\n        \"\"\"\ub300\ud654 \uae30\ub85d\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4\"\"\"\n        print(\"\\n=== \ub300\ud654 \uae30\ub85d ===\")\n        for message in self.history:\n            print(message)\n        print(\"================\\n\")\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nchat = SimpleChat()\n\n# \ub300\ud654\ud558\uae30\nprint(\"\ud83e\udd16:\", chat.chat(\"\uc548\ub155! \ub098\ub294 \ud30c\uc774\uc36c\uc744 \ubc30\uc6b0\ub294 \ud559\uc0dd\uc774\uc57c\"))\nprint(\"\ud83e\udd16:\", chat.chat(\"\ub0b4\uac00 \ubb58 \ubc30\uc6b4\ub2e4\uace0 \ud588\uc9c0?\"))\nprint(\"\ud83e\udd16:\", chat.chat(\"\ud30c\uc774\uc36c\uc73c\ub85c \ubb58 \ub9cc\ub4e4 \uc218 \uc788\uc5b4?\"))\n\n# \ub300\ud654 \uae30\ub85d \ud655\uc778\nchat.show_history()\n</code></pre>"},{"location":"examples/03-conversations/remembering-context/#step-2","title":"Step 2: \uba54\uc2dc\uc9c0 \ud615\uc2dd \uac1c\uc120\ud558\uae30","text":"<pre><code>from datetime import datetime\n\nclass ImprovedChat:\n    \"\"\"\uac1c\uc120\ub41c \ub300\ud654 \uc2dc\uc2a4\ud15c\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.ai = LLM.create(model)\n        self.messages = []  # \uad6c\uc870\ud654\ub41c \uba54\uc2dc\uc9c0 \uc800\uc7a5\n\n    def add_message(self, role, content):\n        \"\"\"\uba54\uc2dc\uc9c0\ub97c \ucd94\uac00\ud569\ub2c8\ub2e4\"\"\"\n        self.messages.append({\n            \"role\": role,  # \"user\" \ub610\ub294 \"assistant\"\n            \"content\": content,\n            \"timestamp\": datetime.now()\n        })\n\n    def chat(self, user_message):\n        \"\"\"\ub300\ud654\ub97c \uc9c4\ud589\ud569\ub2c8\ub2e4\"\"\"\n        # \uc0ac\uc6a9\uc790 \uba54\uc2dc\uc9c0 \ucd94\uac00\n        self.add_message(\"user\", user_message)\n\n        # OpenAI \ud615\uc2dd\uc73c\ub85c \ubcc0\ud658\n        formatted_messages = []\n        for msg in self.messages:\n            if msg[\"role\"] == \"user\":\n                formatted_messages.append(f\"Human: {msg['content']}\")\n            else:\n                formatted_messages.append(f\"Assistant: {msg['content']}\")\n\n        # \ub300\ud654 \uc0dd\uc131\n        conversation = \"\\n\".join(formatted_messages)\n        prompt = f\"{conversation}\\nAssistant:\"\n\n        # AI \uc751\ub2f5 \ubc1b\uae30\n        response = self.ai.ask(prompt)\n\n        # \uc751\ub2f5 \uc800\uc7a5\n        self.add_message(\"assistant\", response.text)\n\n        return response.text\n\n    def get_context_summary(self):\n        \"\"\"\ub300\ud654 \ub9e5\ub77d\uc744 \uc694\uc57d\ud569\ub2c8\ub2e4\"\"\"\n        if len(self.messages) &lt; 2:\n            return \"\ub300\ud654\uac00 \ub9c9 \uc2dc\uc791\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\"\n\n        # \ucd5c\uadfc 5\uac1c \uba54\uc2dc\uc9c0\ub9cc \uc0ac\uc6a9\n        recent = self.messages[-5:]\n        summary_prompt = \"\ub2e4\uc74c \ub300\ud654\ub97c \ud55c \uc904\ub85c \uc694\uc57d\ud574\uc8fc\uc138\uc694:\\n\"\n\n        for msg in recent:\n            summary_prompt += f\"{msg['role']}: {msg['content']}\\n\"\n\n        summary = self.ai.ask(summary_prompt)\n        return summary.text\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nchat = ImprovedChat()\n\n# \ub300\ud654 \uc9c4\ud589\nresponses = [\n    chat.chat(\"\uc548\ub155! \uc624\ub298 \ub0a0\uc528\uac00 \uc815\ub9d0 \uc88b\ub124\"),\n    chat.chat(\"\uc0b0\ucc45\ud558\uae30 \uc88b\uc740 \uacf3 \ucd94\ucc9c\ud574\uc904 \uc218 \uc788\uc5b4?\"),\n    chat.chat(\"\uc11c\uc6b8\uc5d0 \uc788\ub294 \uacf3\uc73c\ub85c \ubd80\ud0c1\ud574\")\n]\n\nfor i, response in enumerate(responses, 1):\n    print(f\"\uc751\ub2f5 {i}: {response}\\n\")\n\n# \ub300\ud654 \uc694\uc57d\nprint(\"\ud83d\udcdd \ub300\ud654 \uc694\uc57d:\", chat.get_context_summary())\n</code></pre>"},{"location":"examples/03-conversations/remembering-context/#_4","title":"\ud83c\udfa8 \uace0\uae09 \uba54\ubaa8\ub9ac \uad00\ub9ac","text":""},{"location":"examples/03-conversations/remembering-context/#1","title":"1. \uba54\ubaa8\ub9ac \ud06c\uae30 \uc81c\ud55c\ud558\uae30","text":"<pre><code>class MemoryLimitedChat:\n    \"\"\"\uba54\ubaa8\ub9ac \ud06c\uae30\ub97c \uc81c\ud55c\ud558\ub294 \ucc57\ubd07\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\", max_messages=10):\n        self.ai = LLM.create(model)\n        self.messages = []\n        self.max_messages = max_messages  # \ucd5c\ub300 \uba54\uc2dc\uc9c0 \uc218\n\n    def chat(self, user_message):\n        \"\"\"\uba54\ubaa8\ub9ac \ud06c\uae30\ub97c \uc81c\ud55c\ud558\uba74\uc11c \ub300\ud654\ud569\ub2c8\ub2e4\"\"\"\n        # \uba54\uc2dc\uc9c0 \ucd94\uac00\n        self.messages.append({\"role\": \"user\", \"content\": user_message})\n\n        # \uba54\ubaa8\ub9ac \ud06c\uae30 \ucd08\uacfc \uc2dc \uc624\ub798\ub41c \uba54\uc2dc\uc9c0 \uc81c\uac70\n        if len(self.messages) &gt; self.max_messages:\n            # \uccab \ubc88\uc9f8 \uc2dc\uc2a4\ud15c \uba54\uc2dc\uc9c0\ub294 \uc720\uc9c0\ud558\uace0 \ub098\uba38\uc9c0 \uc81c\uac70\n            self.messages = self.messages[-(self.max_messages):]\n\n        # \ub300\ud654 \uc0dd\uc131\n        conversation = self._format_conversation()\n        response = self.ai.ask(conversation)\n\n        # \uc751\ub2f5 \uc800\uc7a5\n        self.messages.append({\"role\": \"assistant\", \"content\": response.text})\n\n        return response.text\n\n    def _format_conversation(self):\n        \"\"\"\ub300\ud654\ub97c \ud3ec\ub9f7\ud305\ud569\ub2c8\ub2e4\"\"\"\n        formatted = []\n        for msg in self.messages:\n            role = \"Human\" if msg[\"role\"] == \"user\" else \"Assistant\"\n            formatted.append(f\"{role}: {msg['content']}\")\n\n        return \"\\n\".join(formatted) + \"\\nAssistant:\"\n\n    def get_memory_usage(self):\n        \"\"\"\ud604\uc7ac \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc744 \ud655\uc778\ud569\ub2c8\ub2e4\"\"\"\n        total_chars = sum(len(msg[\"content\"]) for msg in self.messages)\n        return {\n            \"messages\": len(self.messages),\n            \"characters\": total_chars,\n            \"estimated_tokens\": total_chars // 4  # \ub300\ub7b5\uc801\uc778 \ud1a0\ud070 \uc218\n        }\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nchat = MemoryLimitedChat(max_messages=6)\n\n# \uae34 \ub300\ud654 \uc9c4\ud589\nfor i in range(10):\n    response = chat.chat(f\"\uc774\uac83\uc740 {i+1}\ubc88\uc9f8 \uba54\uc2dc\uc9c0\uc785\ub2c8\ub2e4\")\n    print(f\"\uba54\uc2dc\uc9c0 {i+1}: {response[:50]}...\")\n\n    # \uba54\ubaa8\ub9ac \uc0c1\ud0dc \ud655\uc778\n    usage = chat.get_memory_usage()\n    print(f\"  \u2192 \uba54\ubaa8\ub9ac: {usage['messages']}\uac1c \uba54\uc2dc\uc9c0, \uc57d {usage['estimated_tokens']} \ud1a0\ud070\\n\")\n</code></pre>"},{"location":"examples/03-conversations/remembering-context/#2","title":"2. \uc911\uc694\ud55c \uc815\ubcf4\ub9cc \uae30\uc5b5\ud558\uae30","text":"<pre><code>class SmartMemoryChat:\n    \"\"\"\uc911\uc694\ud55c \uc815\ubcf4\ub9cc \uae30\uc5b5\ud558\ub294 \ub611\ub611\ud55c \ucc57\ubd07\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.ai = LLM.create(model)\n        self.short_term_memory = []  # \ub2e8\uae30 \uae30\uc5b5\n        self.long_term_memory = {}   # \uc7a5\uae30 \uae30\uc5b5 (\uc911\uc694 \uc815\ubcf4)\n\n    def chat(self, user_message):\n        \"\"\"\uc911\uc694\ud55c \uc815\ubcf4\ub97c \ucd94\ucd9c\ud558\uba74\uc11c \ub300\ud654\ud569\ub2c8\ub2e4\"\"\"\n        # \uc911\uc694 \uc815\ubcf4 \ucd94\ucd9c\n        important_info = self._extract_important_info(user_message)\n        if important_info:\n            self.long_term_memory.update(important_info)\n\n        # \ub2e8\uae30 \uae30\uc5b5\uc5d0 \ucd94\uac00\n        self.short_term_memory.append({\"role\": \"user\", \"content\": user_message})\n\n        # \ub9e5\ub77d \uc0dd\uc131\n        context = self._create_context()\n        response = self.ai.ask(context)\n\n        # \uc751\ub2f5 \uc800\uc7a5\n        self.short_term_memory.append({\"role\": \"assistant\", \"content\": response.text})\n\n        # \ub2e8\uae30 \uae30\uc5b5 \uc815\ub9ac (\ucd5c\uadfc 5\uac1c\ub9cc \uc720\uc9c0)\n        if len(self.short_term_memory) &gt; 10:\n            self.short_term_memory = self.short_term_memory[-10:]\n\n        return response.text\n\n    def _extract_important_info(self, message):\n        \"\"\"\uba54\uc2dc\uc9c0\uc5d0\uc11c \uc911\uc694\ud55c \uc815\ubcf4\ub97c \ucd94\ucd9c\ud569\ub2c8\ub2e4\"\"\"\n        extract_prompt = f\"\"\"\n        \ub2e4\uc74c \uba54\uc2dc\uc9c0\uc5d0\uc11c \uae30\uc5b5\ud574\uc57c \ud560 \uc911\uc694\ud55c \uc815\ubcf4\ub97c \ucd94\ucd9c\ud574\uc8fc\uc138\uc694:\n        \"{message}\"\n\n        \uc608\uc2dc: \uc774\ub984, \ub098\uc774, \uc9c1\uc5c5, \ucde8\ubbf8, \uc120\ud638\uc0ac\ud56d \ub4f1\n        \uc5c6\uc73c\uba74 \"\uc5c6\uc74c\"\uc774\ub77c\uace0 \ub2f5\ud558\uc138\uc694.\n        \uc788\uc73c\uba74 \"\ud0a4: \uac12\" \ud615\uc2dd\uc73c\ub85c \ub2f5\ud558\uc138\uc694.\n        \"\"\"\n\n        result = self.ai.ask(extract_prompt)\n\n        # \uacb0\uacfc \ud30c\uc2f1\n        if \"\uc5c6\uc74c\" in result.text:\n            return None\n\n        # \uac04\ub2e8\ud55c \ud30c\uc2f1 (\uc2e4\uc81c\ub85c\ub294 \ub354 \uc815\uad50\ud558\uac8c)\n        info = {}\n        lines = result.text.strip().split('\\n')\n        for line in lines:\n            if ':' in line:\n                key, value = line.split(':', 1)\n                info[key.strip()] = value.strip()\n\n        return info if info else None\n\n    def _create_context(self):\n        \"\"\"\ub300\ud654 \ub9e5\ub77d\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4\"\"\"\n        context_parts = []\n\n        # \uc7a5\uae30 \uae30\uc5b5 \ucd94\uac00\n        if self.long_term_memory:\n            context_parts.append(\"\uae30\uc5b5\ud558\uace0 \uc788\ub294 \uc815\ubcf4:\")\n            for key, value in self.long_term_memory.items():\n                context_parts.append(f\"- {key}: {value}\")\n            context_parts.append(\"\")\n\n        # \ucd5c\uadfc \ub300\ud654 \ucd94\uac00\n        context_parts.append(\"\ucd5c\uadfc \ub300\ud654:\")\n        for msg in self.short_term_memory:\n            role = \"Human\" if msg[\"role\"] == \"user\" else \"Assistant\"\n            context_parts.append(f\"{role}: {msg['content']}\")\n\n        context_parts.append(\"Assistant:\")\n        return \"\\n\".join(context_parts)\n\n    def show_memory(self):\n        \"\"\"\ud604\uc7ac \uae30\uc5b5 \uc0c1\ud0dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4\"\"\"\n        print(\"\\n=== \uc7a5\uae30 \uae30\uc5b5 ===\")\n        for key, value in self.long_term_memory.items():\n            print(f\"{key}: {value}\")\n\n        print(f\"\\n=== \ub2e8\uae30 \uae30\uc5b5 ===\")\n        print(f\"\ucd5c\uadfc {len(self.short_term_memory)}\uac1c \uba54\uc2dc\uc9c0 \uc800\uc7a5 \uc911\")\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nsmart_chat = SmartMemoryChat()\n\n# \uc815\ubcf4\uac00 \ud3ec\ud568\ub41c \ub300\ud654\nconversations = [\n    \"\uc548\ub155! \ub0b4 \uc774\ub984\uc740 \uae40\ucca0\uc218\uc57c\",\n    \"\ub098\ub294 25\uc0b4\uc774\uace0 \uac1c\ubc1c\uc790\ub85c \uc77c\ud558\uace0 \uc788\uc5b4\",\n    \"\uc624\ub298 \ub0a0\uc528 \uc5b4\ub54c?\",\n    \"\ub0b4\uac00 \uba87 \uc0b4\uc774\ub77c\uace0 \ud588\uc9c0?\",\n    \"\ud504\ub85c\uadf8\ub798\ubc0d \uad00\ub828 \ucc45 \ucd94\ucc9c\ud574\uc904 \uc218 \uc788\uc5b4?\"\n]\n\nfor msg in conversations:\n    print(f\"\\n\ud83d\udc64 You: {msg}\")\n    response = smart_chat.chat(msg)\n    print(f\"\ud83e\udd16 Bot: {response}\")\n\n# \uba54\ubaa8\ub9ac \uc0c1\ud0dc \ud655\uc778\nsmart_chat.show_memory()\n</code></pre>"},{"location":"examples/03-conversations/remembering-context/#3","title":"3. \ub300\ud654 \uc694\uc57d\uc744 \ud1b5\ud55c \uba54\ubaa8\ub9ac \uc555\ucd95","text":"<pre><code>class CompressedMemoryChat:\n    \"\"\"\ub300\ud654\ub97c \uc694\uc57d\ud574\uc11c \uba54\ubaa8\ub9ac\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 \ucc57\ubd07\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.ai = LLM.create(model)\n        self.current_conversation = []\n        self.conversation_summary = \"\"\n        self.summary_threshold = 10  # 10\uac1c \uba54\uc2dc\uc9c0\ub9c8\ub2e4 \uc694\uc57d\n\n    def chat(self, user_message):\n        \"\"\"\ub300\ud654\ub97c \uc555\ucd95\ud558\uba74\uc11c \uc9c4\ud589\ud569\ub2c8\ub2e4\"\"\"\n        # \ud604\uc7ac \ub300\ud654\uc5d0 \ucd94\uac00\n        self.current_conversation.append(f\"User: {user_message}\")\n\n        # \uc784\uacc4\uac12 \ub3c4\ub2ec \uc2dc \uc694\uc57d\n        if len(self.current_conversation) &gt;= self.summary_threshold:\n            self._compress_conversation()\n\n        # \uc804\uccb4 \ub9e5\ub77d \uc0dd\uc131\n        context = self._build_context()\n        context += f\"\\nUser: {user_message}\\nAssistant:\"\n\n        # \uc751\ub2f5 \uc0dd\uc131\n        response = self.ai.ask(context)\n        self.current_conversation.append(f\"Assistant: {response.text}\")\n\n        return response.text\n\n    def _compress_conversation(self):\n        \"\"\"\ud604\uc7ac \ub300\ud654\ub97c \uc694\uc57d\ud569\ub2c8\ub2e4\"\"\"\n        # \uc774\uc804 \uc694\uc57d\uacfc \ud604\uc7ac \ub300\ud654\ub97c \ud569\uccd0\uc11c \uc0c8\ub85c\uc6b4 \uc694\uc57d \uc0dd\uc131\n        compress_prompt = f\"\"\"\n        \uc774\uc804 \ub300\ud654 \uc694\uc57d:\n        {self.conversation_summary}\n\n        \ucd5c\uadfc \ub300\ud654:\n        {chr(10).join(self.current_conversation)}\n\n        \uc704 \ub0b4\uc6a9\uc744 \ubaa8\ub450 \ud3ec\ud568\ud558\uc5ec \uac04\ub2e8\ud788 \uc694\uc57d\ud574\uc8fc\uc138\uc694.\n        \uc911\uc694\ud55c \uc815\ubcf4\ub294 \ubc18\ub4dc\uc2dc \ud3ec\ud568\uc2dc\ucf1c\uc8fc\uc138\uc694.\n        \"\"\"\n\n        new_summary = self.ai.ask(compress_prompt)\n        self.conversation_summary = new_summary.text\n\n        # \ucd5c\uadfc 2\uac1c \uba54\uc2dc\uc9c0\ub9cc \ub0a8\uae30\uace0 \ub098\uba38\uc9c0 \uc0ad\uc81c\n        self.current_conversation = self.current_conversation[-2:]\n\n        print(f\"\\n\ud83d\udcbe \uba54\ubaa8\ub9ac \uc555\ucd95 \uc644\ub8cc! (\uc694\uc57d \uae38\uc774: {len(self.conversation_summary)}\uc790)\")\n\n    def _build_context(self):\n        \"\"\"\ub300\ud654 \ub9e5\ub77d\uc744 \uad6c\uc131\ud569\ub2c8\ub2e4\"\"\"\n        parts = []\n\n        # \uc694\uc57d\ub41c \ub0b4\uc6a9\uc774 \uc788\uc73c\uba74 \ucd94\uac00\n        if self.conversation_summary:\n            parts.append(f\"\uc774\uc804 \ub300\ud654 \uc694\uc57d:\\n{self.conversation_summary}\\n\")\n\n        # \ud604\uc7ac \ub300\ud654 \ucd94\uac00\n        if self.current_conversation:\n            parts.append(\"\ucd5c\uadfc \ub300\ud654:\")\n            parts.extend(self.current_conversation)\n\n        return \"\\n\".join(parts)\n\n    def get_memory_stats(self):\n        \"\"\"\uba54\ubaa8\ub9ac \ud1b5\uacc4\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4\"\"\"\n        return {\n            \"summary_length\": len(self.conversation_summary),\n            \"current_messages\": len(self.current_conversation),\n            \"total_chars\": len(self.conversation_summary) + \n                          sum(len(msg) for msg in self.current_conversation)\n        }\n\n# \uc0ac\uc6a9 \uc608\uc2dc\ncompressed_chat = CompressedMemoryChat()\n\n# \uae34 \ub300\ud654 \uc2dc\ubbac\ub808\uc774\uc158\ntopics = [\n    \"\ud30c\uc774\uc36c \ud559\uc2b5\", \"\uc6f9 \uac1c\ubc1c\", \"\ub370\uc774\ud130\ubca0\uc774\uc2a4\", \"API \uc124\uacc4\",\n    \"\ud504\ub860\ud2b8\uc5d4\ub4dc\", \"\ubc31\uc5d4\ub4dc\", \"\ud074\ub77c\uc6b0\ub4dc\", \"DevOps\",\n    \"\uba38\uc2e0\ub7ec\ub2dd\", \"\ub525\ub7ec\ub2dd\", \"\uc790\uc5f0\uc5b4\ucc98\ub9ac\", \"\ucef4\ud4e8\ud130\ube44\uc804\"\n]\n\nfor i, topic in enumerate(topics):\n    print(f\"\\n--- \ub300\ud654 {i+1}: {topic} ---\")\n\n    # \uac01 \uc8fc\uc81c\uc5d0 \ub300\ud574 \ub300\ud654\n    response = compressed_chat.chat(f\"{topic}\uc5d0 \ub300\ud574 \uc54c\ub824\uc918\")\n    print(f\"Bot: {response[:100]}...\")\n\n    # \uba54\ubaa8\ub9ac \uc0c1\ud0dc \ud655\uc778\n    stats = compressed_chat.get_memory_stats()\n    print(f\"\uba54\ubaa8\ub9ac: {stats['current_messages']}\uac1c \uba54\uc2dc\uc9c0, \ucd1d {stats['total_chars']}\uc790\")\n</code></pre>"},{"location":"examples/03-conversations/remembering-context/#_5","title":"\ud83d\udcca \uba54\ubaa8\ub9ac \uc804\ub7b5 \ube44\uad50","text":"\uc804\ub7b5 \uc7a5\uc810 \ub2e8\uc810 \uc0ac\uc6a9 \uc2dc\uae30 \uc804\uccb4 \uae30\ub85d \uc644\ubcbd\ud55c \ub9e5\ub77d \ube44\uc6a9 \uc99d\uac00 \uc9e7\uc740 \ub300\ud654 \ud06c\uae30 \uc81c\ud55c \ube44\uc6a9 \uc808\uc57d \uc624\ub798\ub41c \uc815\ubcf4 \uc190\uc2e4 \uc77c\ubc18\uc801\uc778 \ub300\ud654 \uc911\uc694 \uc815\ubcf4 \ucd94\ucd9c \ud6a8\uc728\uc801 \uad6c\ud604 \ubcf5\uc7a1 \uc7a5\uae30 \ub300\ud654 \ub300\ud654 \uc555\ucd95 \uade0\ud615\uc801 \uc694\uc57d \uc2dc \uc815\ubcf4 \uc190\uc2e4 \ub9e4\uc6b0 \uae34 \ub300\ud654"},{"location":"examples/03-conversations/remembering-context/#_6","title":"\ud83d\udd27 \uc2e4\uc804 \ud301","text":""},{"location":"examples/03-conversations/remembering-context/#1_1","title":"1. \uc2dc\uc2a4\ud15c \uba54\uc2dc\uc9c0 \ud65c\uc6a9","text":"<pre><code>def create_chat_with_personality(personality):\n    \"\"\"\ud2b9\uc815 \uc131\uaca9\uc744 \uac00\uc9c4 \ucc57\ubd07\uc744 \ub9cc\ub4ed\ub2c8\ub2e4\"\"\"\n    chat = ImprovedChat()\n\n    # \uc2dc\uc2a4\ud15c \uba54\uc2dc\uc9c0\ub85c \uc131\uaca9 \uc124\uc815\n    system_message = f\"\ub2f9\uc2e0\uc740 {personality} \ucc57\ubd07\uc785\ub2c8\ub2e4. \uc774 \uc131\uaca9\uc5d0 \ub9de\uac8c \ub300\ud654\ud558\uc138\uc694.\"\n    chat.add_message(\"system\", system_message)\n\n    return chat\n\n# \ub2e4\uc591\ud55c \uc131\uaca9\uc758 \ucc57\ubd07\nfriendly_bot = create_chat_with_personality(\"\uce5c\uc808\ud558\uace0 \uc720\uba38\ub7ec\uc2a4\ud55c\")\nprofessional_bot = create_chat_with_personality(\"\uc804\ubb38\uc801\uc774\uace0 \uc815\ud655\ud55c\")\n</code></pre>"},{"location":"examples/03-conversations/remembering-context/#2_1","title":"2. \ub300\ud654 \uc800\uc7a5\uacfc \ubcf5\uc6d0","text":"<pre><code>import json\n\ndef save_conversation(chat, filename):\n    \"\"\"\ub300\ud654\ub97c \ud30c\uc77c\ub85c \uc800\uc7a5\ud569\ub2c8\ub2e4\"\"\"\n    with open(filename, 'w', encoding='utf-8') as f:\n        json.dump(chat.messages, f, ensure_ascii=False, default=str, indent=2)\n\ndef load_conversation(chat, filename):\n    \"\"\"\uc800\uc7a5\ub41c \ub300\ud654\ub97c \ubd88\ub7ec\uc635\ub2c8\ub2e4\"\"\"\n    with open(filename, 'r', encoding='utf-8') as f:\n        chat.messages = json.load(f)\n    return chat\n</code></pre>"},{"location":"examples/03-conversations/remembering-context/#_7","title":"\u2705 \ud575\uc2ec \uc815\ub9ac","text":"<ol> <li>AI\ub294 \uc2a4\uc2a4\ub85c \uae30\uc5b5\ud558\uc9c0 \ubabb\ud568 - \uc6b0\ub9ac\uac00 \ub300\ud654 \uae30\ub85d\uc744 \uad00\ub9ac\ud574\uc57c \ud568</li> <li>\uba54\ubaa8\ub9ac \uad00\ub9ac\uac00 \uc911\uc694 - \ube44\uc6a9\uacfc \uc131\ub2a5\uc758 \uade0\ud615</li> <li>\ub2e4\uc591\ud55c \uc804\ub7b5 \uc874\uc7ac - \uc0c1\ud669\uc5d0 \ub9de\ub294 \ubc29\ubc95 \uc120\ud0dd</li> <li>\uad6c\uc870\ud654\ub41c \ub370\uc774\ud130 - \uccb4\uacc4\uc801\uc778 \uba54\uc2dc\uc9c0 \uad00\ub9ac</li> </ol>"},{"location":"examples/03-conversations/remembering-context/#_8","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>\ub300\ud654 \uae30\uc5b5 \ubc29\ubc95\uc744 \ubc30\uc6e0\uc73c\ub2c8, \uc774\uc81c \ucc57\ubd07 \ub9cc\ub4e4\uae30\uc5d0\uc11c \uc2e4\uc81c\ub85c \ub300\ud654\ud615 AI\ub97c \uad6c\ud604\ud574\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/08-real-projects/","title":"\ud83d\ude80 \uc2e4\uc804 \ud504\ub85c\uc81d\ud2b8","text":"<p>\uc9c0\uae08\uae4c\uc9c0 \ubc30\uc6b4 \ubaa8\ub4e0 \uac83\uc744 \ud65c\uc6a9\ud574 \uc2e4\uc81c\ub85c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \uc644\uc131\ub41c \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc744 \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4!</p>"},{"location":"examples/08-real-projects/#_2","title":"\ud83c\udfaf \uc774 \uc139\uc158\uc5d0\uc11c \ub9cc\ub4e4 \ud504\ub85c\uc81d\ud2b8\ub4e4","text":""},{"location":"examples/08-real-projects/#1","title":"1. \ud83c\udf73 \ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8","text":"<ul> <li>\uc7ac\ub8cc\ub85c \uc694\ub9ac \ucd94\ucc9c</li> <li>\ub808\uc2dc\ud53c \uac80\uc0c9 \ubc0f \uc800\uc7a5</li> <li>\uc601\uc591 \uc815\ubcf4 \ubd84\uc11d</li> <li>\uc1fc\ud551 \ub9ac\uc2a4\ud2b8 \uc0dd\uc131</li> </ul>"},{"location":"examples/08-real-projects/#2","title":"2. \ud83d\udcda \uacf5\ubd80 \ub3c4\uc6b0\ubbf8","text":"<ul> <li>\ud559\uc2b5 \uc790\ub8cc \uc694\uc57d</li> <li>\ud034\uc988 \uc790\ub3d9 \uc0dd\uc131</li> <li>\uac1c\ub150 \uc124\uba85</li> <li>\ud559\uc2b5 \uc9c4\ub3c4 \uad00\ub9ac</li> </ul>"},{"location":"examples/08-real-projects/#3","title":"3. \u270d\ufe0f \uc2a4\ud1a0\ub9ac \uc791\uac00","text":"<ul> <li>\ucc3d\uc758\uc801\uc778 \uc774\uc57c\uae30 \uc0dd\uc131</li> <li>\uce90\ub9ad\ud130 \uac1c\ubc1c</li> <li>\ud50c\ub86f \uad6c\uc131</li> <li>\ub2e4\uc591\ud55c \uc7a5\ub974 \uc9c0\uc6d0</li> </ul>"},{"location":"examples/08-real-projects/#4","title":"4. \ud83d\udce7 \uc774\uba54\uc77c \ub3c4\uc6b0\ubbf8","text":"<ul> <li>\uc774\uba54\uc77c \uc791\uc131 \uc9c0\uc6d0</li> <li>\uc790\ub3d9 \ub2f5\uc7a5 \uc0dd\uc131</li> <li>\uc774\uba54\uc77c \ubd84\ub958</li> <li>\ud15c\ud50c\ub9bf \uad00\ub9ac</li> </ul>"},{"location":"examples/08-real-projects/#_3","title":"\ud83d\udca1 \uac01 \ud504\ub85c\uc81d\ud2b8\uc758 \ud2b9\uc9d5","text":"\ud504\ub85c\uc81d\ud2b8 \ub09c\uc774\ub3c4 \uc8fc\uc694 \uae30\ub2a5 \ubc30\uc6b0\ub294 \ub0b4\uc6a9 \ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8 \u2b50\u2b50 \ub300\ud654\ud615 \ucd94\ucc9c \ub370\uc774\ud130 \uad00\ub9ac, API \ud65c\uc6a9 \uacf5\ubd80 \ub3c4\uc6b0\ubbf8 \u2b50\u2b50\u2b50 \ud559\uc2b5 \uc9c0\uc6d0 \ud30c\uc77c \ucc98\ub9ac, \uad6c\uc870\ud654\ub41c \ucd9c\ub825 \uc2a4\ud1a0\ub9ac \uc791\uac00 \u2b50\u2b50 \ucc3d\uc758\uc801 \uc0dd\uc131 \ud504\ub86c\ud504\ud2b8 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1 \uc774\uba54\uc77c \ub3c4\uc6b0\ubbf8 \u2b50\u2b50\u2b50 \uc5c5\ubb34 \uc790\ub3d9\ud654 \ud15c\ud50c\ub9bf, \ubd84\ub958 \uc2dc\uc2a4\ud15c"},{"location":"examples/08-real-projects/#_4","title":"\ud83d\udee0\ufe0f \ud504\ub85c\uc81d\ud2b8 \uad6c\uc870","text":"<p>\uac01 \ud504\ub85c\uc81d\ud2b8\ub294 \ub2e4\uc74c\uacfc \uac19\uc740 \uad6c\uc870\ub85c \ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code>\ud504\ub85c\uc81d\ud2b8\uba85/\n\u251c\u2500\u2500 index.md          # \ud504\ub85c\uc81d\ud2b8 \uc18c\uac1c\n\u251c\u2500\u2500 main.py          # \uba54\uc778 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\n\u251c\u2500\u2500 modules/         # \uae30\ub2a5\ubcc4 \ubaa8\ub4c8\n\u251c\u2500\u2500 data/           # \ub370\uc774\ud130 \ud30c\uc77c\n\u2514\u2500\u2500 README.md       # \uc2e4\ud589 \ubc29\ubc95\n</code></pre>"},{"location":"examples/08-real-projects/#_5","title":"\ud83d\udcda \ud559\uc2b5 \ubc29\ubc95","text":""},{"location":"examples/08-real-projects/#1_1","title":"1\ub2e8\uacc4: \ud504\ub85c\uc81d\ud2b8 \uc774\ud574","text":"<ul> <li>\uc804\uccb4 \ucf54\ub4dc\ub97c \uc77d\uace0 \uad6c\uc870 \ud30c\uc545</li> <li>\uac01 \ud568\uc218\uc758 \uc5ed\ud560 \uc774\ud574</li> </ul>"},{"location":"examples/08-real-projects/#2_1","title":"2\ub2e8\uacc4: \uc9c1\uc811 \uc2e4\ud589","text":"<ul> <li>\ucf54\ub4dc\ub97c \ubcf5\uc0ac\ud574\uc11c \uc2e4\ud589</li> <li>\ub2e4\uc591\ud55c \uc785\ub825\uc73c\ub85c \ud14c\uc2a4\ud2b8</li> </ul>"},{"location":"examples/08-real-projects/#3_1","title":"3\ub2e8\uacc4: \uc218\uc815 \ubc0f \ud655\uc7a5","text":"<ul> <li>\uae30\ub2a5 \ucd94\uac00\ub098 \uac1c\uc120</li> <li>\uc790\uc2e0\ub9cc\uc758 \ubc84\uc804 \ub9cc\ub4e4\uae30</li> </ul>"},{"location":"examples/08-real-projects/#_6","title":"\ud83c\udfaf \ud504\ub85c\uc81d\ud2b8 \uc120\ud0dd \uac00\uc774\ub4dc","text":""},{"location":"examples/08-real-projects/#_7","title":"\ucd08\ubcf4\uc790\ub77c\uba74","text":"<p>\u2192 **\ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8**\ubd80\ud130 \uc2dc\uc791\ud558\uc138\uc694. \uac00\uc7a5 \uc9c1\uad00\uc801\uc774\uace0 \uc7ac\ubbf8\uc788\uc2b5\ub2c8\ub2e4!</p>"},{"location":"examples/08-real-projects/#_8","title":"\ud559\uc0dd\uc774\ub77c\uba74","text":"<p>\u2192 **\uacf5\ubd80 \ub3c4\uc6b0\ubbf8**\uac00 \uc2e4\uc81c\ub85c \ub3c4\uc6c0\uc774 \ub420 \uac70\uc608\uc694!</p>"},{"location":"examples/08-real-projects/#_9","title":"\ucc3d\uc758\uc801\uc778 \uc791\uc5c5\uc744 \uc88b\uc544\ud55c\ub2e4\uba74","text":"<p>\u2192 **\uc2a4\ud1a0\ub9ac \uc791\uac00**\ub85c \uc0c1\uc0c1\ub825\uc744 \ubc1c\ud718\ud558\uc138\uc694!</p>"},{"location":"examples/08-real-projects/#_10","title":"\uc5c5\ubb34 \ud6a8\uc728\uc744 \ub192\uc774\uace0 \uc2f6\ub2e4\uba74","text":"<p>\u2192 **\uc774\uba54\uc77c \ub3c4\uc6b0\ubbf8**\ub85c \uc2dc\uac04\uc744 \uc808\uc57d\ud558\uc138\uc694!</p>"},{"location":"examples/08-real-projects/#_11","title":"\ud83d\ude80 \uc2dc\uc791\ud558\uae30","text":"<ol> <li>\uad00\uc2ec \uc788\ub294 \ud504\ub85c\uc81d\ud2b8 \uc120\ud0dd</li> <li>\ud504\ub85c\uc81d\ud2b8 \ud3f4\ub354\ub85c \uc774\ub3d9</li> <li>README \ub530\ub77c \uc124\uce58 \ubc0f \uc2e4\ud589</li> <li>\ucf54\ub4dc \ubd84\uc11d \ubc0f \uc218\uc815</li> </ol>"},{"location":"examples/08-real-projects/#_12","title":"\ud83d\udca1 \ud504\ub85c\uc81d\ud2b8 \uc644\uc131 \ud6c4","text":"<ul> <li>\uc790\uc2e0\ub9cc\uc758 \uae30\ub2a5 \ucd94\uac00\ud558\uae30</li> <li>GitHub\uc5d0 \uacf5\uc720\ud558\uae30</li> <li>\ub2e4\ub978 \ud504\ub85c\uc81d\ud2b8\uc5d0 \ub3c4\uc804\ud558\uae30</li> <li>\uc2e4\uc81c \uc11c\ube44\uc2a4\ub85c \ubc1c\uc804\uc2dc\ud0a4\uae30</li> </ul> <p>\uc900\ube44\ub418\uc168\ub098\uc694? \uccab \ubc88\uc9f8 \ud504\ub85c\uc81d\ud2b8 \ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8\ub97c \uc2dc\uc791\ud574\ubd05\uc2dc\ub2e4! \ud83c\udf89</p>"},{"location":"examples/08-real-projects/recipe-helper/","title":"\ud83c\udf73 AI \ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8","text":"<p>\ub0c9\uc7a5\uace0\uc5d0 \uc788\ub294 \uc7ac\ub8cc\ub85c \ubb34\uc5c7\uc744 \ub9cc\ub4e4 \uc218 \uc788\uc744\uae4c? AI\uac00 \ub3c4\uc640\ub4dc\ub9bd\ub2c8\ub2e4!</p>"},{"location":"examples/08-real-projects/recipe-helper/#_1","title":"\ud83c\udfaf \ud504\ub85c\uc81d\ud2b8 \uc18c\uac1c","text":"<p>\uc774 \ud504\ub85c\uc81d\ud2b8\ub294 \ub2e4\uc74c\uacfc \uac19\uc740 \uae30\ub2a5\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4: - \ud83e\udd57 \ubcf4\uc720\ud55c \uc7ac\ub8cc\ub85c \uc694\ub9ac \ucd94\ucc9c - \ud83d\udcd6 \uc0c1\uc138\ud55c \ub808\uc2dc\ud53c \uc81c\uacf5 - \ud83d\uded2 \ubd80\uc871\ud55c \uc7ac\ub8cc \uc1fc\ud551 \ub9ac\uc2a4\ud2b8 - \ud83d\udcca \uc601\uc591 \uc815\ubcf4 \ubd84\uc11d - \ud83d\udcbe \uc88b\uc544\ud558\ub294 \ub808\uc2dc\ud53c \uc800\uc7a5</p>"},{"location":"examples/08-real-projects/recipe-helper/#_2","title":"\ud83d\ude80 \ube60\ub978 \uc2dc\uc791","text":"<pre><code># \ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8 \uc2e4\ud589\nhelper = RecipeHelper()\n\n# \uc7ac\ub8cc\ub85c \uc694\ub9ac \ucd94\ucc9c\nmy_ingredients = [\"\ub2ed\uac00\uc2b4\uc0b4\", \"\uc591\ud30c\", \"\ud1a0\ub9c8\ud1a0\", \"\uce58\uc988\"]\nrecipe = helper.suggest_recipe(my_ingredients)\nprint(recipe)\n</code></pre>"},{"location":"examples/08-real-projects/recipe-helper/#_3","title":"\ud83d\udcdd \uc804\uccb4 \ucf54\ub4dc","text":"<pre><code># recipe_helper.py\nfrom pyhub.llm import LLM\nimport json\nfrom datetime import datetime\nfrom typing import List, Dict\n\nclass RecipeHelper:\n    \"\"\"AI \uae30\ubc18 \ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8\"\"\"\n\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.ai = LLM.create(model)\n        self.saved_recipes = []  # \uc800\uc7a5\ub41c \ub808\uc2dc\ud53c\n        self.shopping_list = []  # \uc1fc\ud551 \ub9ac\uc2a4\ud2b8\n\n    def suggest_recipe(self, ingredients: List[str], \n                      dietary_restrictions: str = None,\n                      cuisine_type: str = None) -&gt; str:\n        \"\"\"\uc7ac\ub8cc\ub97c \uae30\ubc18\uc73c\ub85c \ub808\uc2dc\ud53c\ub97c \ucd94\ucc9c\ud569\ub2c8\ub2e4\"\"\"\n\n        # \ud504\ub86c\ud504\ud2b8 \uad6c\uc131\n        prompt = f\"\"\"\n        \ub2e4\uc74c \uc7ac\ub8cc\ub4e4\ub85c \ub9cc\ub4e4 \uc218 \uc788\ub294 \uc694\ub9ac\ub97c \ucd94\ucc9c\ud574\uc8fc\uc138\uc694:\n        \uc7ac\ub8cc: {', '.join(ingredients)}\n        \"\"\"\n\n        # \uc2dd\uc774 \uc81c\ud55c \ucd94\uac00\n        if dietary_restrictions:\n            prompt += f\"\\n\uc2dd\uc774 \uc81c\ud55c: {dietary_restrictions}\"\n\n        # \uc694\ub9ac \uc885\ub958 \ucd94\uac00\n        if cuisine_type:\n            prompt += f\"\\n\uc120\ud638 \uc694\ub9ac: {cuisine_type}\"\n\n        prompt += \"\"\"\n\n        \ub2e4\uc74c \ud615\uc2dd\uc73c\ub85c \ub2f5\ubcc0\ud574\uc8fc\uc138\uc694:\n\n        \ud83c\udf7d\ufe0f \uc694\ub9ac\uba85: [\uc694\ub9ac \uc774\ub984]\n        \u23f1\ufe0f \uc870\ub9ac \uc2dc\uac04: [\uc608\uc0c1 \uc2dc\uac04]\n        \ud83d\udc65 \uc778\ubd84: [\uba87 \uc778\ubd84]\n\n        \ud83d\udcdd \ud544\uc694\ud55c \uc7ac\ub8cc:\n        - [\uc7ac\ub8cc1] - [\uc591]\n        - [\uc7ac\ub8cc2] - [\uc591]\n\n        \ud83d\udc68\u200d\ud83c\udf73 \uc870\ub9ac \ubc29\ubc95:\n        1. [\ub2e8\uacc4 1]\n        2. [\ub2e8\uacc4 2]\n        ...\n\n        \ud83d\udca1 \uc694\ub9ac \ud301:\n        [\uc720\uc6a9\ud55c \ud301]\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def analyze_nutrition(self, recipe_text: str) -&gt; Dict:\n        \"\"\"\ub808\uc2dc\ud53c\uc758 \uc601\uc591 \uc815\ubcf4\ub97c \ubd84\uc11d\ud569\ub2c8\ub2e4\"\"\"\n\n        prompt = f\"\"\"\n        \ub2e4\uc74c \ub808\uc2dc\ud53c\uc758 \ub300\ub7b5\uc801\uc778 \uc601\uc591 \uc815\ubcf4\ub97c \ubd84\uc11d\ud574\uc8fc\uc138\uc694:\n\n        {recipe_text}\n\n        1\uc778\ubd84 \uae30\uc900\uc73c\ub85c \ub2e4\uc74c \uc815\ubcf4\ub97c \ucd94\uc815\ud574\uc8fc\uc138\uc694:\n        - \uce7c\ub85c\ub9ac (kcal)\n        - \ub2e8\ubc31\uc9c8 (g)\n        - \ud0c4\uc218\ud654\ubb3c (g)\n        - \uc9c0\ubc29 (g)\n        - \ub098\ud2b8\ub968 (mg)\n\n        JSON \ud615\uc2dd\uc73c\ub85c\ub9cc \ub2f5\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n\n        # JSON \ud30c\uc2f1 \uc2dc\ub3c4\n        try:\n            # AI \uc751\ub2f5\uc5d0\uc11c JSON \ubd80\ubd84\ub9cc \ucd94\ucd9c\n            import re\n            json_match = re.search(r'\\{.*\\}', response.text, re.DOTALL)\n            if json_match:\n                nutrition = json.loads(json_match.group())\n                return nutrition\n        except:\n            pass\n\n        # \ud30c\uc2f1 \uc2e4\ud328 \uc2dc \uae30\ubcf8\uac12\n        return {\n            \"calories\": \"\ubd84\uc11d \uc911\",\n            \"protein\": \"\ubd84\uc11d \uc911\",\n            \"carbs\": \"\ubd84\uc11d \uc911\",\n            \"fat\": \"\ubd84\uc11d \uc911\",\n            \"sodium\": \"\ubd84\uc11d \uc911\"\n        }\n\n    def create_shopping_list(self, recipe_text: str, \n                           available_ingredients: List[str]) -&gt; List[str]:\n        \"\"\"\ub808\uc2dc\ud53c\uc5d0 \ud544\uc694\ud55c \uc7ac\ub8cc \uc911 \uc5c6\ub294 \uac83\ub4e4\uc758 \uc1fc\ud551 \ub9ac\uc2a4\ud2b8\ub97c \ub9cc\ub4ed\ub2c8\ub2e4\"\"\"\n\n        prompt = f\"\"\"\n        \ub808\uc2dc\ud53c:\n        {recipe_text}\n\n        \ud604\uc7ac \uac00\uc9c0\uace0 \uc788\ub294 \uc7ac\ub8cc:\n        {', '.join(available_ingredients)}\n\n        \uc704 \ub808\uc2dc\ud53c\ub97c \ub9cc\ub4e4\uae30 \uc704\ud574 \ucd94\uac00\ub85c \uad6c\ub9e4\ud574\uc57c \ud560 \uc7ac\ub8cc\ub4e4\uc744 \ub9ac\uc2a4\ud2b8\ub85c \ub9cc\ub4e4\uc5b4\uc8fc\uc138\uc694.\n        \uac01 \uc7ac\ub8cc\uc640 \ud544\uc694\ud55c \uc591\uc744 \ud568\uaed8 \uc801\uc5b4\uc8fc\uc138\uc694.\n\n        \ud615\uc2dd:\n        - [\uc7ac\ub8cc\uba85] ([\ud544\uc694\ub7c9])\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n\n        # \uc1fc\ud551 \ub9ac\uc2a4\ud2b8 \ud30c\uc2f1\n        shopping_items = []\n        lines = response.text.split('\\n')\n        for line in lines:\n            if line.strip().startswith('-'):\n                item = line.strip()[1:].strip()\n                shopping_items.append(item)\n\n        self.shopping_list.extend(shopping_items)\n        return shopping_items\n\n    def modify_recipe(self, recipe_text: str, modification: str) -&gt; str:\n        \"\"\"\ub808\uc2dc\ud53c\ub97c \uc218\uc815\ud569\ub2c8\ub2e4 (\uc778\ubd84 \uc870\uc808, \uc7ac\ub8cc \ub300\uccb4 \ub4f1)\"\"\"\n\n        prompt = f\"\"\"\n        \uc6d0\ubcf8 \ub808\uc2dc\ud53c:\n        {recipe_text}\n\n        \uc218\uc815 \uc694\uccad: {modification}\n\n        \uc694\uccad\uc5d0 \ub530\ub77c \ub808\uc2dc\ud53c\ub97c \uc218\uc815\ud574\uc8fc\uc138\uc694.\n        \uc6d0\ubcf8\uacfc \uac19\uc740 \ud615\uc2dd\uc744 \uc720\uc9c0\ud574\uc8fc\uc138\uc694.\n        \"\"\"\n\n        response = self.ai.ask(prompt)\n        return response.text\n\n    def save_recipe(self, recipe_text: str, name: str = None):\n        \"\"\"\ub808\uc2dc\ud53c\ub97c \uc800\uc7a5\ud569\ub2c8\ub2e4\"\"\"\n\n        if not name:\n            # \ub808\uc2dc\ud53c \uc774\ub984 \ucd94\ucd9c\n            lines = recipe_text.split('\\n')\n            for line in lines:\n                if '\uc694\ub9ac\uba85:' in line:\n                    name = line.split('\uc694\ub9ac\uba85:')[1].strip()\n                    break\n\n        recipe_data = {\n            \"name\": name,\n            \"content\": recipe_text,\n            \"saved_date\": datetime.now().isoformat(),\n            \"tags\": []\n        }\n\n        self.saved_recipes.append(recipe_data)\n\n        # \ud30c\uc77c\ub85c \uc800\uc7a5\n        with open(\"saved_recipes.json\", \"w\", encoding=\"utf-8\") as f:\n            json.dump(self.saved_recipes, f, ensure_ascii=False, indent=2)\n\n        return f\"\u2705 '{name}' \ub808\uc2dc\ud53c\uac00 \uc800\uc7a5\ub418\uc5c8\uc2b5\ub2c8\ub2e4!\"\n\n    def load_saved_recipes(self):\n        \"\"\"\uc800\uc7a5\ub41c \ub808\uc2dc\ud53c\ub97c \ubd88\ub7ec\uc635\ub2c8\ub2e4\"\"\"\n        try:\n            with open(\"saved_recipes.json\", \"r\", encoding=\"utf-8\") as f:\n                self.saved_recipes = json.load(f)\n            return f\"\ud83d\udcda {len(self.saved_recipes)}\uac1c\uc758 \ub808\uc2dc\ud53c\ub97c \ubd88\ub7ec\uc654\uc2b5\ub2c8\ub2e4.\"\n        except FileNotFoundError:\n            return \"\uc800\uc7a5\ub41c \ub808\uc2dc\ud53c\uac00 \uc5c6\uc2b5\ub2c8\ub2e4.\"\n\n    def search_recipes(self, keyword: str) -&gt; List[Dict]:\n        \"\"\"\uc800\uc7a5\ub41c \ub808\uc2dc\ud53c\uc5d0\uc11c \uac80\uc0c9\ud569\ub2c8\ub2e4\"\"\"\n        results = []\n        for recipe in self.saved_recipes:\n            if keyword.lower() in recipe[\"name\"].lower() or \\\n               keyword.lower() in recipe[\"content\"].lower():\n                results.append(recipe)\n        return results\n\n\nclass InteractiveRecipeHelper:\n    \"\"\"\ub300\ud654\ud615 \ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8\"\"\"\n\n    def __init__(self):\n        self.helper = RecipeHelper()\n        self.current_recipe = None\n\n    def start(self):\n        \"\"\"\ub300\ud654\ud615 \ubaa8\ub4dc\ub97c \uc2dc\uc791\ud569\ub2c8\ub2e4\"\"\"\n        print(\"\"\"\n\ud83c\udf73 AI \ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8\uc5d0 \uc624\uc2e0 \uac83\uc744 \ud658\uc601\ud569\ub2c8\ub2e4!\n\n\uba85\ub839\uc5b4:\n- '\uc7ac\ub8cc' : \uc7ac\ub8cc\ub85c \ub808\uc2dc\ud53c \ucd94\ucc9c\ubc1b\uae30\n- '\uac80\uc0c9' : \uc800\uc7a5\ub41c \ub808\uc2dc\ud53c \uac80\uc0c9\n- '\uc601\uc591' : \ud604\uc7ac \ub808\uc2dc\ud53c \uc601\uc591 \ubd84\uc11d\n- '\uc218\uc815' : \ud604\uc7ac \ub808\uc2dc\ud53c \uc218\uc815\n- '\uc800\uc7a5' : \ud604\uc7ac \ub808\uc2dc\ud53c \uc800\uc7a5\n- '\uc1fc\ud551' : \uc1fc\ud551 \ub9ac\uc2a4\ud2b8 \ub9cc\ub4e4\uae30\n- '\ub3c4\uc6c0\ub9d0' : \uba85\ub839\uc5b4 \ubcf4\uae30\n- '\uc885\ub8cc' : \ud504\ub85c\uadf8\ub7a8 \uc885\ub8cc\n        \"\"\")\n\n        # \uc800\uc7a5\ub41c \ub808\uc2dc\ud53c \ubd88\ub7ec\uc624\uae30\n        print(self.helper.load_saved_recipes())\n\n        while True:\n            command = input(\"\\n\ud83c\udf7d\ufe0f \ubb34\uc5c7\uc744 \ub3c4\uc640\ub4dc\ub9b4\uae4c\uc694? \").strip()\n\n            if command == \"\uc885\ub8cc\":\n                print(\"\ud83d\udc4b \ub9db\uc788\ub294 \uc694\ub9ac \ud558\uc138\uc694!\")\n                break\n            elif command == \"\uc7ac\ub8cc\":\n                self.handle_ingredients()\n            elif command == \"\uac80\uc0c9\":\n                self.handle_search()\n            elif command == \"\uc601\uc591\":\n                self.handle_nutrition()\n            elif command == \"\uc218\uc815\":\n                self.handle_modify()\n            elif command == \"\uc800\uc7a5\":\n                self.handle_save()\n            elif command == \"\uc1fc\ud551\":\n                self.handle_shopping()\n            elif command == \"\ub3c4\uc6c0\ub9d0\":\n                self.show_help()\n            else:\n                print(\"\u2753 \uc54c \uc218 \uc5c6\ub294 \uba85\ub839\uc5b4\uc785\ub2c8\ub2e4. '\ub3c4\uc6c0\ub9d0'\uc744 \uc785\ub825\ud574\ubcf4\uc138\uc694.\")\n\n    def handle_ingredients(self):\n        \"\"\"\uc7ac\ub8cc \uae30\ubc18 \ub808\uc2dc\ud53c \ucd94\ucc9c\uc744 \ucc98\ub9ac\ud569\ub2c8\ub2e4\"\"\"\n        print(\"\\n\ud83e\udd57 \uc5b4\ub5a4 \uc7ac\ub8cc\ub97c \uac00\uc9c0\uace0 \uacc4\uc2e0\uac00\uc694?\")\n        print(\"(\uc27c\ud45c\ub85c \uad6c\ubd84\ud574\uc11c \uc785\ub825\ud574\uc8fc\uc138\uc694)\")\n\n        ingredients_input = input(\"\uc7ac\ub8cc: \").strip()\n        ingredients = [i.strip() for i in ingredients_input.split(',')]\n\n        # \uc635\uc158 \ud655\uc778\n        dietary = input(\"\uc2dd\uc774 \uc81c\ud55c\uc774 \uc788\ub098\uc694? (\uc5c6\uc73c\uba74 \uc5d4\ud130): \").strip()\n        cuisine = input(\"\uc120\ud638\ud558\ub294 \uc694\ub9ac \uc885\ub958\ub294? (\ud55c\uc2dd/\uc911\uc2dd/\uc77c\uc2dd/\uc591\uc2dd \ub4f1, \uc5c6\uc73c\uba74 \uc5d4\ud130): \").strip()\n\n        print(\"\\n\ud83d\udd0d \ub808\uc2dc\ud53c\ub97c \ucc3e\uace0 \uc788\uc2b5\ub2c8\ub2e4...\")\n\n        # \ub808\uc2dc\ud53c \ucd94\ucc9c\n        recipe = self.helper.suggest_recipe(\n            ingredients,\n            dietary_restrictions=dietary if dietary else None,\n            cuisine_type=cuisine if cuisine else None\n        )\n\n        self.current_recipe = recipe\n        print(\"\\n\" + recipe)\n\n        # \ub2e4\uc74c \uc561\uc158 \uc81c\uc548\n        print(\"\\n\ud83d\udca1 \ub2e4\uc74c \uc791\uc5c5\uc744 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\")\n        print(\"- '\uc601\uc591' : \uc601\uc591 \uc815\ubcf4 \ubd84\uc11d\")\n        print(\"- '\uc218\uc815' : \ub808\uc2dc\ud53c \uc218\uc815 (\uc778\ubd84 \uc870\uc808 \ub4f1)\")\n        print(\"- '\uc800\uc7a5' : \uc774 \ub808\uc2dc\ud53c \uc800\uc7a5\")\n        print(\"- '\uc1fc\ud551' : \uc1fc\ud551 \ub9ac\uc2a4\ud2b8 \ub9cc\ub4e4\uae30\")\n\n    def handle_search(self):\n        \"\"\"\ub808\uc2dc\ud53c \uac80\uc0c9\uc744 \ucc98\ub9ac\ud569\ub2c8\ub2e4\"\"\"\n        keyword = input(\"\\n\ud83d\udd0d \uac80\uc0c9\uc5b4\ub97c \uc785\ub825\ud558\uc138\uc694: \").strip()\n\n        results = self.helper.search_recipes(keyword)\n\n        if results:\n            print(f\"\\n\ud83d\udcda '{keyword}' \uac80\uc0c9 \uacb0\uacfc: {len(results)}\uac1c\")\n            for i, recipe in enumerate(results, 1):\n                print(f\"{i}. {recipe['name']} (\uc800\uc7a5\uc77c: {recipe['saved_date'][:10]})\")\n\n            # \ub808\uc2dc\ud53c \uc120\ud0dd\n            try:\n                choice = int(input(\"\\n\ubc88\ud638\ub97c \uc120\ud0dd\ud558\uc138\uc694 (0: \ucde8\uc18c): \"))\n                if 1 &lt;= choice &lt;= len(results):\n                    self.current_recipe = results[choice-1]['content']\n                    print(\"\\n\" + self.current_recipe)\n            except:\n                print(\"\ucde8\uc18c\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\")\n        else:\n            print(f\"\u274c '{keyword}'\uc5d0 \ub300\ud55c \uac80\uc0c9 \uacb0\uacfc\uac00 \uc5c6\uc2b5\ub2c8\ub2e4.\")\n\n    def handle_nutrition(self):\n        \"\"\"\uc601\uc591 \uc815\ubcf4 \ubd84\uc11d\uc744 \ucc98\ub9ac\ud569\ub2c8\ub2e4\"\"\"\n        if not self.current_recipe:\n            print(\"\u274c \uba3c\uc800 \ub808\uc2dc\ud53c\ub97c \uc120\ud0dd\ud574\uc8fc\uc138\uc694.\")\n            return\n\n        print(\"\\n\ud83d\udcca \uc601\uc591 \uc815\ubcf4\ub97c \ubd84\uc11d\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4...\")\n        nutrition = self.helper.analyze_nutrition(self.current_recipe)\n\n        print(\"\\n\ud83e\udd57 \uc601\uc591 \uc815\ubcf4 (1\uc778\ubd84 \uae30\uc900):\")\n        print(f\"- \uce7c\ub85c\ub9ac: {nutrition.get('calories', '?')} kcal\")\n        print(f\"- \ub2e8\ubc31\uc9c8: {nutrition.get('protein', '?')} g\")\n        print(f\"- \ud0c4\uc218\ud654\ubb3c: {nutrition.get('carbs', '?')} g\")\n        print(f\"- \uc9c0\ubc29: {nutrition.get('fat', '?')} g\")\n        print(f\"- \ub098\ud2b8\ub968: {nutrition.get('sodium', '?')} mg\")\n\n    def handle_modify(self):\n        \"\"\"\ub808\uc2dc\ud53c \uc218\uc815\uc744 \ucc98\ub9ac\ud569\ub2c8\ub2e4\"\"\"\n        if not self.current_recipe:\n            print(\"\u274c \uba3c\uc800 \ub808\uc2dc\ud53c\ub97c \uc120\ud0dd\ud574\uc8fc\uc138\uc694.\")\n            return\n\n        print(\"\\n\u270f\ufe0f \uc5b4\ub5bb\uac8c \uc218\uc815\ud558\uc2dc\uaca0\uc2b5\ub2c8\uae4c?\")\n        print(\"\uc608: '4\uc778\ubd84\uc73c\ub85c \ub298\ub824\uc918', '\ub9e4\uc6b4\ub9db \uc904\uc5ec\uc918', '\ub2ed\uace0\uae30\ub97c \ub450\ubd80\ub85c \ubc14\uafd4\uc918'\")\n\n        modification = input(\"\uc218\uc815 \uc0ac\ud56d: \").strip()\n\n        print(\"\\n\ud83d\udd04 \ub808\uc2dc\ud53c\ub97c \uc218\uc815\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4...\")\n        modified_recipe = self.helper.modify_recipe(self.current_recipe, modification)\n\n        self.current_recipe = modified_recipe\n        print(\"\\n\" + modified_recipe)\n\n    def handle_save(self):\n        \"\"\"\ub808\uc2dc\ud53c \uc800\uc7a5\uc744 \ucc98\ub9ac\ud569\ub2c8\ub2e4\"\"\"\n        if not self.current_recipe:\n            print(\"\u274c \uba3c\uc800 \ub808\uc2dc\ud53c\ub97c \uc120\ud0dd\ud574\uc8fc\uc138\uc694.\")\n            return\n\n        custom_name = input(\"\\n\ud83d\udcbe \ub808\uc2dc\ud53c \uc774\ub984 (\uc5d4\ud130: \uc790\ub3d9): \").strip()\n\n        result = self.helper.save_recipe(\n            self.current_recipe,\n            name=custom_name if custom_name else None\n        )\n        print(result)\n\n    def handle_shopping(self):\n        \"\"\"\uc1fc\ud551 \ub9ac\uc2a4\ud2b8 \uc0dd\uc131\uc744 \ucc98\ub9ac\ud569\ub2c8\ub2e4\"\"\"\n        if not self.current_recipe:\n            print(\"\u274c \uba3c\uc800 \ub808\uc2dc\ud53c\ub97c \uc120\ud0dd\ud574\uc8fc\uc138\uc694.\")\n            return\n\n        print(\"\\n\ud83d\uded2 \ud604\uc7ac \uac00\uc9c0\uace0 \uc788\ub294 \uc7ac\ub8cc\ub97c \uc785\ub825\ud574\uc8fc\uc138\uc694:\")\n        print(\"(\uc27c\ud45c\ub85c \uad6c\ubd84)\")\n\n        available = input(\"\ubcf4\uc720 \uc7ac\ub8cc: \").strip()\n        available_list = [i.strip() for i in available.split(',')] if available else []\n\n        print(\"\\n\ud83d\udcdd \uc1fc\ud551 \ub9ac\uc2a4\ud2b8\ub97c \ub9cc\ub4e4\uace0 \uc788\uc2b5\ub2c8\ub2e4...\")\n        shopping_list = self.helper.create_shopping_list(\n            self.current_recipe,\n            available_list\n        )\n\n        if shopping_list:\n            print(\"\\n\ud83d\uded2 \uad6c\ub9e4\ud574\uc57c \ud560 \uc7ac\ub8cc:\")\n            for item in shopping_list:\n                print(f\"  {item}\")\n\n            # \uc1fc\ud551 \ub9ac\uc2a4\ud2b8 \uc800\uc7a5 \uc635\uc158\n            save_list = input(\"\\n\uc1fc\ud551 \ub9ac\uc2a4\ud2b8\ub97c \uc800\uc7a5\ud558\uc2dc\uaca0\uc2b5\ub2c8\uae4c? (y/n): \").lower()\n            if save_list == 'y':\n                with open(\"shopping_list.txt\", \"w\", encoding=\"utf-8\") as f:\n                    f.write(\"\ud83d\uded2 \uc1fc\ud551 \ub9ac\uc2a4\ud2b8\\n\")\n                    f.write(f\"\uc0dd\uc131\uc77c: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\\n\")\n                    for item in shopping_list:\n                        f.write(f\"\u25a1 {item}\\n\")\n                print(\"\u2705 shopping_list.txt\uc5d0 \uc800\uc7a5\ub418\uc5c8\uc2b5\ub2c8\ub2e4!\")\n        else:\n            print(\"\u2705 \ucd94\uac00\ub85c \uad6c\ub9e4\ud560 \uc7ac\ub8cc\uac00 \uc5c6\uc2b5\ub2c8\ub2e4!\")\n\n    def show_help(self):\n        \"\"\"\ub3c4\uc6c0\ub9d0\uc744 \ud45c\uc2dc\ud569\ub2c8\ub2e4\"\"\"\n        print(\"\"\"\n\ud83d\udcd6 \ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8 \uc0ac\uc6a9\ubc95:\n\n\ud83e\udd57 \uc7ac\ub8cc\ub85c \ub808\uc2dc\ud53c \ucc3e\uae30:\n1. '\uc7ac\ub8cc' \uba85\ub839\uc5b4 \uc785\ub825\n2. \ubcf4\uc720\ud55c \uc7ac\ub8cc\ub4e4\uc744 \uc27c\ud45c\ub85c \uad6c\ubd84\ud574\uc11c \uc785\ub825\n3. \uc2dd\uc774 \uc81c\ud55c\uc774\ub098 \uc120\ud638 \uc694\ub9ac \uc885\ub958 \uc120\ud0dd (\uc120\ud0dd\uc0ac\ud56d)\n\n\ud83d\udd0d \uc800\uc7a5\ub41c \ub808\uc2dc\ud53c \uac80\uc0c9:\n1. '\uac80\uc0c9' \uba85\ub839\uc5b4 \uc785\ub825\n2. \uac80\uc0c9\uc5b4 \uc785\ub825 (\uc694\ub9ac\uba85, \uc7ac\ub8cc \ub4f1)\n3. \uacb0\uacfc\uc5d0\uc11c \ubc88\ud638 \uc120\ud0dd\n\n\ud83d\udcca \uc601\uc591 \uc815\ubcf4 \ud655\uc778:\n- \ud604\uc7ac \ub808\uc2dc\ud53c\uc758 \uc601\uc591 \uc815\ubcf4\ub97c \ubd84\uc11d\ud569\ub2c8\ub2e4\n\n\u270f\ufe0f \ub808\uc2dc\ud53c \uc218\uc815:\n- \uc778\ubd84 \uc870\uc808, \uc7ac\ub8cc \ub300\uccb4 \ub4f1 \uc790\uc720\ub86d\uac8c \uc218\uc815 \uac00\ub2a5\n\n\ud83d\udcbe \ub808\uc2dc\ud53c \uc800\uc7a5:\n- \ub9c8\uc74c\uc5d0 \ub4dc\ub294 \ub808\uc2dc\ud53c\ub97c \uc800\uc7a5\ud574\ub450\uace0 \ub098\uc911\uc5d0 \uac80\uc0c9 \uac00\ub2a5\n\n\ud83d\uded2 \uc1fc\ud551 \ub9ac\uc2a4\ud2b8:\n- \ud604\uc7ac \uac00\uc9c4 \uc7ac\ub8cc\ub97c \uc785\ub825\ud558\uba74 \ubd80\uc871\ud55c \uc7ac\ub8cc \ub9ac\uc2a4\ud2b8 \uc0dd\uc131\n        \"\"\")\n\n\n# \ucd94\uac00 \uc720\ud2f8\ub9ac\ud2f0 \ud568\uc218\ub4e4\ndef create_meal_plan(helper: RecipeHelper, days: int = 7):\n    \"\"\"\uc8fc\uac04 \uc2dd\ub2e8\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4\"\"\"\n\n    prompt = f\"\"\"\n    {days}\uc77c\uac04\uc758 \uade0\ud615\uc7a1\ud78c \uc2dd\ub2e8\uc744 \ub9cc\ub4e4\uc5b4\uc8fc\uc138\uc694.\n\n    \uac01 \ub0a0\uc9dc\ubcc4\ub85c:\n    - \uc544\uce68\n    - \uc810\uc2ec  \n    - \uc800\ub141\n\n    \ub2e4\uc591\ud558\uace0 \uc601\uc591\uac00 \uc788\ub294 \uba54\ub274\ub85c \uad6c\uc131\ud574\uc8fc\uc138\uc694.\n    \ud55c\uad6d\uc778\uc758 \uc785\ub9db\uc5d0 \ub9de\uac8c \ub9cc\ub4e4\uc5b4\uc8fc\uc138\uc694.\n    \"\"\"\n\n    response = helper.ai.ask(prompt)\n    return response.text\n\n\ndef suggest_by_mood(helper: RecipeHelper, mood: str):\n    \"\"\"\uae30\ubd84\uc5d0 \ub530\ub978 \uc694\ub9ac \ucd94\ucc9c\"\"\"\n\n    mood_foods = {\n        \"\ud53c\uace4\": \"\uc5d0\ub108\uc9c0\ub97c \uc8fc\ub294 \uc601\uc591\uac00 \ub192\uc740\",\n        \"\uc6b0\uc6b8\": \"\uae30\ubd84\uc744 \uc88b\uac8c \ub9cc\ub4dc\ub294 \ub2ec\ucf64\ud558\uac70\ub098 \ub530\ub73b\ud55c\",\n        \"\uc2a4\ud2b8\ub808\uc2a4\": \"\uc2a4\ud2b8\ub808\uc2a4 \ud574\uc18c\uc5d0 \uc88b\uc740 \ud3b8\uc548\ud55c\",\n        \"\ud589\ubcf5\": \"\ud2b9\ubcc4\ud55c \ub0a0\uc5d0 \uc5b4\uc6b8\ub9ac\ub294 \ud654\ub824\ud55c\",\n        \"\ub354\uc6cc\": \"\uc2dc\uc6d0\ud558\uace0 \uc0c1\ud07c\ud55c\",\n        \"\ucd94\uc6cc\": \"\ub530\ub73b\ud558\uace0 \ub4e0\ub4e0\ud55c\"\n    }\n\n    food_type = mood_foods.get(mood, \"\ub9db\uc788\ub294\")\n\n    prompt = f\"\"\"\n    {mood}\ud55c \uae30\ubd84\uc77c \ub54c \uba39\uae30 \uc88b\uc740 {food_type} \uc694\ub9ac 3\uac00\uc9c0\ub97c \ucd94\ucc9c\ud574\uc8fc\uc138\uc694.\n    \uac01 \uc694\ub9ac\uc758 \ud2b9\uc9d5\uacfc \uc65c \uc774 \uae30\ubd84\uc5d0 \uc88b\uc740\uc9c0 \uc124\uba85\ud574\uc8fc\uc138\uc694.\n    \"\"\"\n\n    response = helper.ai.ask(prompt)\n    return response.text\n\n\n# \uba54\uc778 \uc2e4\ud589 \ucf54\ub4dc\nif __name__ == \"__main__\":\n    # \ub300\ud654\ud615 \ubaa8\ub4dc \uc2e4\ud589\n    app = InteractiveRecipeHelper()\n    app.start()\n</code></pre>"},{"location":"examples/08-real-projects/recipe-helper/#_4","title":"\ud83c\udfae \uc0ac\uc6a9 \uc608\uc2dc","text":""},{"location":"examples/08-real-projects/recipe-helper/#1","title":"1. \uae30\ubcf8 \uc0ac\uc6a9\ubc95","text":"<pre><code># \ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8 \uc0dd\uc131\nhelper = RecipeHelper()\n\n# \uc7ac\ub8cc\ub85c \uc694\ub9ac \ucd94\ucc9c\ningredients = [\"\ub3fc\uc9c0\uace0\uae30\", \"\uae40\uce58\", \"\ub450\ubd80\"]\nrecipe = helper.suggest_recipe(ingredients, cuisine_type=\"\ud55c\uc2dd\")\nprint(recipe)\n</code></pre>"},{"location":"examples/08-real-projects/recipe-helper/#2","title":"2. \uc601\uc591 \uc815\ubcf4 \ubd84\uc11d","text":"<pre><code># \ub808\uc2dc\ud53c\uc758 \uc601\uc591 \uc815\ubcf4 \ubd84\uc11d\nnutrition = helper.analyze_nutrition(recipe)\nprint(f\"\uce7c\ub85c\ub9ac: {nutrition['calories']} kcal\")\n</code></pre>"},{"location":"examples/08-real-projects/recipe-helper/#3","title":"3. \uae30\ubd84\uc5d0 \ub530\ub978 \ucd94\ucc9c","text":"<pre><code># \ud53c\uace4\ud560 \ub54c \uc88b\uc740 \uc694\ub9ac \ucd94\ucc9c\nsuggestion = suggest_by_mood(helper, \"\ud53c\uace4\")\nprint(suggestion)\n</code></pre>"},{"location":"examples/08-real-projects/recipe-helper/#4","title":"4. \uc8fc\uac04 \uc2dd\ub2e8 \uc0dd\uc131","text":"<pre><code># 7\uc77c \uc2dd\ub2e8 \ub9cc\ub4e4\uae30\nmeal_plan = create_meal_plan(helper, days=7)\nprint(meal_plan)\n</code></pre>"},{"location":"examples/08-real-projects/recipe-helper/#_5","title":"\ud83d\udca1 \ud655\uc7a5 \uc544\uc774\ub514\uc5b4","text":"<ol> <li>\uc54c\ub808\ub974\uae30 \uad00\ub9ac: \ud2b9\uc815 \uc7ac\ub8cc \uc790\ub3d9 \uc81c\uc678</li> <li>\uce7c\ub85c\ub9ac \uacc4\uc0b0\uae30: \ubaa9\ud45c \uce7c\ub85c\ub9ac\uc5d0 \ub9de\ub294 \uc2dd\ub2e8</li> <li>\uc694\ub9ac \ud0c0\uc774\uba38: \ub2e8\uacc4\ubcc4 \ud0c0\uc774\uba38 \uae30\ub2a5</li> <li>\uc0ac\uc9c4 \uc778\uc2dd: \uc7ac\ub8cc \uc0ac\uc9c4\uc73c\ub85c \uc778\uc2dd</li> <li>\ucee4\ubba4\ub2c8\ud2f0: \ub808\uc2dc\ud53c \uacf5\uc720 \uae30\ub2a5</li> </ol>"},{"location":"examples/08-real-projects/recipe-helper/#_6","title":"\ud83d\udd27 \ucee4\uc2a4\ud130\ub9c8\uc774\uc9d5","text":""},{"location":"examples/08-real-projects/recipe-helper/#_7","title":"\uc120\ud638\ub3c4 \uc124\uc815 \ucd94\uac00","text":"<pre><code>class PersonalizedRecipeHelper(RecipeHelper):\n    def __init__(self):\n        super().__init__()\n        self.preferences = {\n            \"spicy_level\": 3,  # 1-5\n            \"cooking_time\": \"30\ubd84 \uc774\ub0b4\",\n            \"difficulty\": \"\ucd08\uae09\"\n        }\n</code></pre>"},{"location":"examples/08-real-projects/recipe-helper/#_8","title":"\ub370\uc774\ud130\ubca0\uc774\uc2a4 \uc5f0\ub3d9","text":"<pre><code>import sqlite3\n\ndef save_to_database(recipe_data):\n    conn = sqlite3.connect('recipes.db')\n    # ... \ub370\uc774\ud130\ubca0\uc774\uc2a4 \uc800\uc7a5 \ub85c\uc9c1\n</code></pre>"},{"location":"examples/08-real-projects/recipe-helper/#_9","title":"\u2705 \ud559\uc2b5 \ud3ec\uc778\ud2b8","text":"<ol> <li>\ud074\ub798\uc2a4 \uc124\uacc4: \uae30\ub2a5\ubcc4\ub85c \uba54\uc11c\ub4dc \ubd84\ub9ac</li> <li>\ud504\ub86c\ud504\ud2b8 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1: \uad6c\uc870\ud654\ub41c \ucd9c\ub825 \uc694\uccad</li> <li>\ud30c\uc77c \uc785\ucd9c\ub825: JSON\uc73c\ub85c \ub370\uc774\ud130 \uc800\uc7a5</li> <li>\uc0ac\uc6a9\uc790 \uc778\ud130\ud398\uc774\uc2a4: \ub300\ud654\ud615 \uba85\ub839\uc5b4 \ucc98\ub9ac</li> <li>\uc5d0\ub7ec \ucc98\ub9ac: \uc608\uc678 \uc0c1\ud669 \ub300\uc751</li> </ol>"},{"location":"examples/08-real-projects/recipe-helper/#_10","title":"\ud83d\ude80 \ub2e4\uc74c \ub2e8\uacc4","text":"<p>\ub808\uc2dc\ud53c \ub3c4\uc6b0\ubbf8\ub97c \uc644\uc131\ud588\ub2e4\uba74: - \uc6f9 \uc778\ud130\ud398\uc774\uc2a4 \ucd94\uac00 (Flask/FastAPI) - \ubaa8\ubc14\uc77c \uc571\uc73c\ub85c \ud655\uc7a5 - \uc74c\uc131 \uc778\uc2dd \uae30\ub2a5 \ucd94\uac00 - \ub2e4\ub978 \ud504\ub85c\uc81d\ud2b8 \ub3c4\uc804!</p> <p>\ub2e4\uc74c \ud504\ub85c\uc81d\ud2b8 \uacf5\ubd80 \ub3c4\uc6b0\ubbf8\ub3c4 \ud655\uc778\ud574\ubcf4\uc138\uc694! \ud83d\udcda</p>"},{"location":"getting-started/","title":"\uc2dc\uc791\ud558\uae30","text":"<p>pyhub-llm\uc744 \uc2dc\uc791\ud558\ub294 \ubc29\ubc95\uc744 \uc548\ub0b4\ud569\ub2c8\ub2e4.</p>"},{"location":"getting-started/#_2","title":"\uc774 \uc139\uc158\uc758 \ub0b4\uc6a9","text":"<ul> <li> <p> \uc124\uce58</p> <p>pyhub-llm\uc744 \uc124\uce58\ud558\uace0 \ud658\uacbd\uc744 \uc124\uc815\ud558\ub294 \ubc29\ubc95\uc744 \uc54c\uc544\ubd05\ub2c8\ub2e4.</p> </li> <li> <p> \ube60\ub978 \uc2dc\uc791</p> <p>5\ubd84 \uc548\uc5d0 \uccab \ubc88\uc9f8 LLM \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc744 \ub9cc\ub4e4\uc5b4\ubd05\ub2c8\ub2e4.</p> </li> </ul>"},{"location":"getting-started/#_3","title":"\uc804\uc81c \uc870\uac74","text":"<ul> <li>Python 3.10 \uc774\uc0c1</li> <li>pip \ub610\ub294 poetry</li> <li>API \ud0a4 (\uc0ac\uc6a9\ud558\ub824\ub294 LLM \ud504\ub85c\ubc14\uc774\ub354)</li> </ul>"},{"location":"getting-started/#_4","title":"\uc9c0\uc6d0 \ud504\ub85c\ubc14\uc774\ub354","text":"\ud504\ub85c\ubc14\uc774\ub354 \ud544\uc694\ud55c API \ud0a4 \uc124\uce58 \uba85\ub839 OpenAI <code>OPENAI_API_KEY</code> <code>pip install pyhub-llm[openai]</code> Anthropic <code>ANTHROPIC_API_KEY</code> <code>pip install pyhub-llm[anthropic]</code> Google <code>GOOGLE_API_KEY</code> <code>pip install pyhub-llm[google]</code> Ollama \uc5c6\uc74c (\ub85c\uceec) <code>pip install pyhub-llm[ollama]</code>"},{"location":"getting-started/#_5","title":"\uccab \ubc88\uc9f8 \ucf54\ub4dc","text":"<pre><code>from pyhub.llm import LLM\n\n# LLM \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131\nllm = LLM.create(\"gpt-4o-mini\")\n\n# \uc9c8\ubb38\ud558\uae30\nreply = llm.ask(\"\uc548\ub155\ud558\uc138\uc694! \ud30c\uc774\uc36c\uc5d0 \ub300\ud574 \uc54c\ub824\uc8fc\uc138\uc694.\")\nprint(reply.text)\n</code></pre> <p>\uc900\ube44\ub418\uc168\ub098\uc694? \uc124\uce58 \uac00\uc774\ub4dc\ub85c \uc2dc\uc791\ud574\ubcf4\uc138\uc694!</p>"},{"location":"getting-started/installation/","title":"\uc124\uce58","text":""},{"location":"getting-started/installation/#_2","title":"\uc2dc\uc2a4\ud15c \uc694\uad6c\uc0ac\ud56d","text":"<ul> <li>Python: 3.10 \uc774\uc0c1</li> <li>\uc6b4\uc601\uccb4\uc81c: Windows, macOS, Linux</li> <li>\uba54\ubaa8\ub9ac: \ucd5c\uc18c 4GB RAM \uad8c\uc7a5</li> </ul>"},{"location":"getting-started/installation/#_3","title":"\uc124\uce58 \ubc29\ubc95","text":""},{"location":"getting-started/installation/#pip","title":"pip\ub97c \uc0ac\uc6a9\ud55c \uc124\uce58","text":"\uae30\ubcf8 \uc124\uce58\ud2b9\uc815 \ud504\ub85c\ubc14\uc774\ub354\uc804\uccb4 \uc124\uce58\uac1c\ubc1c \ud658\uacbd <pre><code>pip install pyhub-llm\n</code></pre> <p>\uae30\ubcf8 \uc124\uce58 \ud3ec\ud568 \ub0b4\uc6a9</p> <ul> <li>\ud575\uc2ec \uae30\ub2a5</li> <li>\uae30\ubcf8 \uc758\uc874\uc131</li> <li>\ud0c0\uc785 \ud78c\ud2b8 \uc9c0\uc6d0</li> </ul> <pre><code># OpenAI\ub9cc \uc124\uce58\npip install pyhub-llm[openai]\n\n# \uc5ec\ub7ec \ud504\ub85c\ubc14\uc774\ub354 \uc124\uce58\npip install pyhub-llm[openai,anthropic]\n\n# \uc0ac\uc6a9 \uac00\ub2a5\ud55c \ud504\ub85c\ubc14\uc774\ub354\n# - openai: OpenAI GPT \ubaa8\ub378\n# - anthropic: Claude \ubaa8\ub378\n# - google: Gemini \ubaa8\ub378\n# - ollama: \ub85c\uceec \ubaa8\ub378\n# - upstage: Solar \ubaa8\ub378\n</code></pre> <pre><code># \ubaa8\ub4e0 \ud504\ub85c\ubc14\uc774\ub354\uc640 \ucd94\uac00 \uae30\ub2a5\npip install pyhub-llm[all]\n</code></pre> <p>\uc804\uccb4 \uc124\uce58 \uc2dc \uc8fc\uc758\uc0ac\ud56d</p> <p>\ubaa8\ub4e0 \ud504\ub85c\ubc14\uc774\ub354\uc758 \uc758\uc874\uc131\uc744 \uc124\uce58\ud558\ubbc0\ub85c \uc124\uce58 \uc2dc\uac04\uc774 \uc624\ub798 \uac78\ub9b4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <pre><code># \uac1c\ubc1c \ub3c4\uad6c \ud3ec\ud568 \uc124\uce58\npip install pyhub-llm[dev]\n\n# \ubb38\uc11c \ub3c4\uad6c \ud3ec\ud568\npip install pyhub-llm[docs]\n\n# \ubaa8\ub4e0 \uac83 \ud3ec\ud568\npip install pyhub-llm[all,dev,docs]\n</code></pre>"},{"location":"getting-started/installation/#poetry","title":"poetry\ub97c \uc0ac\uc6a9\ud55c \uc124\uce58","text":"<pre><code># \uae30\ubcf8 \uc124\uce58\npoetry add pyhub-llm\n\n# \ud2b9\uc815 \ud504\ub85c\ubc14\uc774\ub354\npoetry add pyhub-llm[openai,anthropic]\n\n# \uac1c\ubc1c \uc758\uc874\uc131\npoetry add --group dev pyhub-llm[dev]\n</code></pre>"},{"location":"getting-started/installation/#_4","title":"\uc18c\uc2a4\uc5d0\uc11c \uc124\uce58","text":"<pre><code># \uc800\uc7a5\uc18c \ud074\ub860\ngit clone https://github.com/pyhub-kr/pyhub-llm.git\ncd pyhub-llm\n\n# \uac1c\ubc1c \ubaa8\ub4dc\ub85c \uc124\uce58\npip install -e \".[all,dev]\"\n</code></pre>"},{"location":"getting-started/installation/#api","title":"API \ud0a4 \uc124\uc815","text":""},{"location":"getting-started/installation/#_5","title":"\ud658\uacbd \ubcc0\uc218\ub85c \uc124\uc815","text":"Linux/macOSWindows (PowerShell)Windows (CMD) <pre><code>export OPENAI_API_KEY=\"your-openai-key\"\nexport ANTHROPIC_API_KEY=\"your-anthropic-key\"\nexport GOOGLE_API_KEY=\"your-google-key\"\nexport UPSTAGE_API_KEY=\"your-upstage-key\"\n</code></pre> <pre><code>$env:OPENAI_API_KEY=\"your-openai-key\"\n$env:ANTHROPIC_API_KEY=\"your-anthropic-key\"\n$env:GOOGLE_API_KEY=\"your-google-key\"\n$env:UPSTAGE_API_KEY=\"your-upstage-key\"\n</code></pre> <pre><code>set OPENAI_API_KEY=your-openai-key\nset ANTHROPIC_API_KEY=your-anthropic-key\nset GOOGLE_API_KEY=your-google-key\nset UPSTAGE_API_KEY=your-upstage-key\n</code></pre>"},{"location":"getting-started/installation/#env","title":".env \ud30c\uc77c \uc0ac\uc6a9","text":"<p>\ud504\ub85c\uc81d\ud2b8 \ub8e8\ud2b8\uc5d0 <code>.env</code> \ud30c\uc77c\uc744 \uc0dd\uc131\ud558\uace0 API \ud0a4\ub97c \uc800\uc7a5\ud569\ub2c8\ub2e4:</p> <pre><code># .env\nOPENAI_API_KEY=your-openai-key\nANTHROPIC_API_KEY=your-anthropic-key\nGOOGLE_API_KEY=your-google-key\nUPSTAGE_API_KEY=your-upstage-key\n</code></pre> <p>\ubcf4\uc548 \uc8fc\uc758\uc0ac\ud56d</p> <p><code>.env</code> \ud30c\uc77c\uc744 git\uc5d0 \ucee4\ubc0b\ud558\uc9c0 \uc54a\ub3c4\ub85d <code>.gitignore</code>\uc5d0 \ucd94\uac00\ud558\uc138\uc694!</p>"},{"location":"getting-started/installation/#_6","title":"\ucf54\ub4dc\uc5d0\uc11c \uc9c1\uc811 \uc124\uc815","text":"<pre><code>from pyhub.llm import OpenAILLM, AnthropicLLM\n\n# API \ud0a4 \uc9c1\uc811 \uc804\ub2ec\nopenai_llm = OpenAILLM(\n    model=\"gpt-4o-mini\",\n    api_key=\"your-openai-key\"\n)\n\nanthropic_llm = AnthropicLLM(\n    model=\"claude-3-5-haiku-latest\",\n    api_key=\"your-anthropic-key\"\n)\n</code></pre>"},{"location":"getting-started/installation/#api_1","title":"API \ud0a4 \ubc1c\uae09 \ubc29\ubc95","text":"\ud504\ub85c\ubc14\uc774\ub354 \ubc1c\uae09 \ub9c1\ud06c \ubb34\ub8cc \ud06c\ub808\ub527 OpenAI platform.openai.com/api-keys $5 (\uc2e0\uaddc \uacc4\uc815) Anthropic console.anthropic.com/settings/keys $5 (\uc2e0\uaddc \uacc4\uc815) Google makersuite.google.com/app/apikey \ubb34\ub8cc \ud2f0\uc5b4 \uc81c\uacf5 Upstage console.upstage.ai/ \ubb34\ub8cc \ud06c\ub808\ub527 \uc81c\uacf5"},{"location":"getting-started/installation/#_7","title":"\uc124\uce58 \ud655\uc778","text":"<p>\uc124\uce58\uac00 \uc644\ub8cc\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\ud574\ubcf4\uc138\uc694:</p> <pre><code># Python\uc5d0\uc11c \ud655\uc778\nimport pyhub.llm\nprint(pyhub.llm.__version__)\n\n# \uc0ac\uc6a9 \uac00\ub2a5\ud55c \ud504\ub85c\ubc14\uc774\ub354 \ud655\uc778\nfrom pyhub.llm import LLM\nprint(LLM.available_providers())\n</code></pre> <p>\uba85\ub839\uc904\uc5d0\uc11c \ud655\uc778:</p> <pre><code># \ubc84\uc804 \ud655\uc778\npython -c \"import pyhub.llm; print(pyhub.llm.__version__)\"\n\n# CLI \ub3c4\uad6c \ud655\uc778\npyhub-llm --version\n</code></pre>"},{"location":"getting-started/installation/#_8","title":"\ubb38\uc81c \ud574\uacb0","text":""},{"location":"getting-started/installation/#importerror","title":"ImportError \ubc1c\uc0dd \uc2dc","text":"<pre><code># ImportError: cannot import name 'OpenAILLM'\n</code></pre> <p>\ud574\ub2f9 \ud504\ub85c\ubc14\uc774\ub354\uac00 \uc124\uce58\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4:</p> <pre><code>pip install pyhub-llm[openai]\n</code></pre>"},{"location":"getting-started/installation/#api_2","title":"API \ud0a4 \uc624\ub958","text":"<pre><code># AuthenticationError: Invalid API key\n</code></pre> <ol> <li>API \ud0a4\uac00 \uc62c\ubc14\ub978\uc9c0 \ud655\uc778</li> <li>\ud658\uacbd \ubcc0\uc218\uba85\uc774 \uc815\ud655\ud55c\uc9c0 \ud655\uc778</li> <li><code>.env</code> \ud30c\uc77c \uc704\uce58\uac00 \uc62c\ubc14\ub978\uc9c0 \ud655\uc778</li> </ol>"},{"location":"getting-started/installation/#_9","title":"\uc758\uc874\uc131 \ucda9\ub3cc","text":"<pre><code># \uae30\uc874 \ud328\ud0a4\uc9c0 \uc81c\uac70 \ud6c4 \uc7ac\uc124\uce58\npip uninstall pyhub-llm\npip install pyhub-llm[all] --upgrade\n</code></pre>"},{"location":"getting-started/installation/#_10","title":"\ub2e4\uc74c \ub2e8\uacc4","text":"<p>\uc124\uce58\uac00 \uc644\ub8cc\ub418\uc5c8\ub2e4\uba74 \ube60\ub978 \uc2dc\uc791 \uac00\uc774\ub4dc\ub97c \ud1b5\ud574 \uccab \ubc88\uc9f8 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc744 \ub9cc\ub4e4\uc5b4\ubcf4\uc138\uc694!</p>"},{"location":"getting-started/quickstart/","title":"\ube60\ub978 \uc2dc\uc791","text":"<p>5\ubd84 \uc548\uc5d0 pyhub-llm\uc73c\ub85c \uccab \ubc88\uc9f8 LLM \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc744 \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4!</p>"},{"location":"getting-started/quickstart/#1","title":"1. \uccab \ubc88\uc9f8 \ub300\ud654","text":"<p>\uac00\uc7a5 \uac04\ub2e8\ud55c \uc608\uc81c\ubd80\ud130 \uc2dc\uc791\ud574\ubd05\uc2dc\ub2e4:</p> <pre><code>from pyhub.llm import LLM\n\n# LLM \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131 (\ubaa8\ub378\uba85\uc73c\ub85c \uc790\ub3d9 \ud504\ub85c\ubc14\uc774\ub354 \uac10\uc9c0)\nllm = LLM.create(\"gpt-4o-mini\")\n\n# \uc9c8\ubb38\ud558\uae30\nreply = llm.ask(\"\ud30c\uc774\uc36c\uc758 \uc7a5\uc810\uc744 3\uac00\uc9c0\ub9cc \uc54c\ub824\uc8fc\uc138\uc694\")\nprint(reply.text)\n</code></pre> <p>\ucd9c\ub825 \uc608\uc2dc</p> <pre><code>\ud30c\uc774\uc36c\uc758 \uc8fc\uc694 \uc7a5\uc810 3\uac00\uc9c0\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\n\n1. **\uac04\uacb0\ud558\uace0 \uc77d\uae30 \uc26c\uc6b4 \ubb38\ubc95**: \uc790\uc5f0\uc5b4\uc5d0 \uac00\uae4c\uc6b4 \ubb38\ubc95\uc73c\ub85c \ucd08\ubcf4\uc790\ub3c4 \uc27d\uac8c \ubc30\uc6b8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n2. **\ud48d\ubd80\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac**: \ub370\uc774\ud130 \ubd84\uc11d, \uc6f9 \uac1c\ubc1c, AI/ML \ub4f1 \ub2e4\uc591\ud55c \ubd84\uc57c\uc758 \ub77c\uc774\ube0c\ub7ec\ub9ac\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n3. **\ub192\uc740 \uc0dd\uc0b0\uc131**: \ube60\ub978 \uac1c\ubc1c\uacfc \ud504\ub85c\ud1a0\ud0c0\uc774\ud551\uc774 \uac00\ub2a5\ud558\uc5ec \uac1c\ubc1c \uc2dc\uac04\uc744 \ub2e8\ucd95\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n</code></pre>"},{"location":"getting-started/quickstart/#2","title":"2. \ud504\ub85c\ubc14\uc774\ub354 \uc804\ud658\ud558\uae30","text":"<p>\ub2e4\ub978 LLM \ud504\ub85c\ubc14\uc774\ub354\ub85c \uc27d\uac8c \uc804\ud658\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code># OpenAI\nopenai_llm = LLM.create(\"gpt-4o-mini\")\n\n# Anthropic Claude\nclaude_llm = LLM.create(\"claude-3-5-haiku-latest\")\n\n# Google Gemini\ngemini_llm = LLM.create(\"gemini-2.0-flash-exp\")\n\n# \ubaa8\ub450 \ub3d9\uc77c\ud55c \uc778\ud130\ud398\uc774\uc2a4 \uc0ac\uc6a9\nquestion = \"\uba38\uc2e0\ub7ec\ub2dd\uc774\ub780 \ubb34\uc5c7\uc778\uac00\uc694?\"\nfor llm in [openai_llm, claude_llm, gemini_llm]:\n    reply = llm.ask(question)\n    print(f\"\\n{llm.model}\uc758 \ub2f5\ubcc0:\")\n    print(reply.text[:100] + \"...\")\n</code></pre>"},{"location":"getting-started/quickstart/#3","title":"3. \ub300\ud654 \uc774\uc5b4\uac00\uae30","text":"<p>pyhub-llm\uc740 \uc790\ub3d9\uc73c\ub85c \ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac\ub97c \uad00\ub9ac\ud569\ub2c8\ub2e4:</p> <pre><code>llm = LLM.create(\"gpt-4o-mini\")\n\n# \uccab \ubc88\uc9f8 \uc9c8\ubb38\nllm.ask(\"\uc81c \uc774\ub984\uc740 \uae40\ucca0\uc218\uc785\ub2c8\ub2e4.\")\n\n# \uc774\uc804 \ub300\ud654\ub97c \uae30\uc5b5\ud558\uace0 \ub2f5\ubcc0\nreply = llm.ask(\"\uc81c \uc774\ub984\uc774 \ubb50\ub77c\uace0 \ud588\uc8e0?\")\nprint(reply.text)  # \"\uae40\ucca0\uc218\ub2d8\uc774\ub77c\uace0 \ub9d0\uc500\ud558\uc168\uc2b5\ub2c8\ub2e4.\"\n\n# \ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac \ud655\uc778\nprint(f\"\ucd1d {len(llm.history)}\uac1c\uc758 \uba54\uc2dc\uc9c0\")\n\n# \ub300\ud654 \ucd08\uae30\ud654\nllm.clear()\n</code></pre>"},{"location":"getting-started/quickstart/#4","title":"4. \uad6c\uc870\ud654\ub41c \ucd9c\ub825 \ubc1b\uae30","text":"<p>\uc751\ub2f5\uc744 \uc6d0\ud558\ub294 \ud615\uc2dd\uc73c\ub85c \ubc1b\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p>"},{"location":"getting-started/quickstart/#_2","title":"\uc120\ud0dd\uc9c0\uc5d0\uc11c \uace0\ub974\uae30","text":"<pre><code># \uac10\uc815 \ubd84\uc11d\nreply = llm.ask(\n    \"\ub2e4\uc74c \ubb38\uc7a5\uc758 \uac10\uc815\uc744 \ubd84\uc11d\ud574\uc8fc\uc138\uc694: '\uc624\ub298 \uc815\ub9d0 \uae30\ubd84\uc774 \uc88b\uc544\uc694!'\",\n    choices=[\"\uae0d\uc815\", \"\ubd80\uc815\", \"\uc911\ub9bd\"]\n)\n\nprint(f\"\uac10\uc815: {reply.choice}\")  # \"\uae0d\uc815\"\nprint(f\"\ud655\uc2e0\ub3c4: {reply.confidence}\")  # 0.95\n</code></pre>"},{"location":"getting-started/quickstart/#pydantic","title":"Pydantic \uc2a4\ud0a4\ub9c8 \uc0ac\uc6a9","text":"<pre><code>from pydantic import BaseModel\nfrom typing import List\n\nclass MovieReview(BaseModel):\n    title: str\n    rating: float  # 0-10\n    pros: List[str]\n    cons: List[str]\n    recommend: bool\n\nreply = llm.ask(\n    \"\uc601\ud654 '\uc778\ud130\uc2a4\ud154\ub77c'\uc5d0 \ub300\ud55c \ub9ac\ubdf0\ub97c \uc791\uc131\ud574\uc8fc\uc138\uc694\",\n    schema=MovieReview\n)\n\nreview = reply.structured_data\nprint(f\"\uc81c\ubaa9: {review.title}\")\nprint(f\"\ud3c9\uc810: {review.rating}/10\")\nprint(f\"\uc7a5\uc810: {', '.join(review.pros)}\")\nprint(f\"\ucd94\ucc9c \uc5ec\ubd80: {'\ucd94\ucc9c' if review.recommend else '\ube44\ucd94\ucc9c'}\")\n</code></pre>"},{"location":"getting-started/quickstart/#5","title":"5. \uc2a4\ud2b8\ub9ac\ubc0d \uc751\ub2f5","text":"<p>\uc2e4\uc2dc\uac04\uc73c\ub85c \uc751\ub2f5\uc744 \ubc1b\uc544\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code># \uc2a4\ud2b8\ub9ac\ubc0d\uc73c\ub85c \uc751\ub2f5 \ubc1b\uae30\nfor chunk in llm.ask(\"\ud30c\uc774\uc36c\uc73c\ub85c \ud560 \uc218 \uc788\ub294 \uc77c\ub4e4\uc744 \uc124\uba85\ud574\uc8fc\uc138\uc694\", stream=True):\n    print(chunk.text, end=\"\", flush=True)\n</code></pre>"},{"location":"getting-started/quickstart/#6","title":"6. \ube44\ub3d9\uae30 \ucc98\ub9ac","text":"<p>\ube44\ub3d9\uae30\ub85c \uc5ec\ub7ec \uc694\uccad\uc744 \ub3d9\uc2dc\uc5d0 \ucc98\ub9ac\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code>import asyncio\n\nasync def ask_multiple():\n    llm = LLM.create(\"gpt-4o-mini\")\n\n    questions = [\n        \"Python\uc758 \uc7a5\uc810\uc740?\",\n        \"JavaScript\uc758 \uc7a5\uc810\uc740?\",\n        \"Go\uc758 \uc7a5\uc810\uc740?\"\n    ]\n\n    # \ub3d9\uc2dc\uc5d0 \uc5ec\ub7ec \uc9c8\ubb38 \ucc98\ub9ac\n    tasks = [llm.ask_async(q) for q in questions]\n    replies = await asyncio.gather(*tasks)\n\n    for q, r in zip(questions, replies):\n        print(f\"Q: {q}\")\n        print(f\"A: {r.text[:50]}...\\n\")\n\n# \uc2e4\ud589\nasyncio.run(ask_multiple())\n</code></pre>"},{"location":"getting-started/quickstart/#7","title":"7. \uc774\ubbf8\uc9c0\uc640 \ud568\uaed8 \uc9c8\ubb38\ud558\uae30","text":"<p>\uc774\ubbf8\uc9c0\ub97c \ud3ec\ud568\ud55c \uba40\ud2f0\ubaa8\ub2ec \uc9c8\ubb38\ub3c4 \uac00\ub2a5\ud569\ub2c8\ub2e4:</p> <pre><code># \uc774\ubbf8\uc9c0 \ud30c\uc77c\uacfc \ud568\uaed8 \uc9c8\ubb38\nreply = llm.ask(\n    \"\uc774 \uc774\ubbf8\uc9c0\uc5d0 \ubb34\uc5c7\uc774 \uc788\ub098\uc694?\",\n    files=[\"image.jpg\"]\n)\nprint(reply.text)\n\n# \uc5ec\ub7ec \uc774\ubbf8\uc9c0 \ube44\uad50\nreply = llm.ask(\n    \"\uc774 \ub450 \uc774\ubbf8\uc9c0\uc758 \ucc28\uc774\uc810\uc744 \uc124\uba85\ud574\uc8fc\uc138\uc694\",\n    files=[\"before.png\", \"after.png\"]\n)\n</code></pre>"},{"location":"getting-started/quickstart/#8-stateless","title":"8. \ub3c5\ub9bd\uc801\uc778 \uc791\uc5c5 \ucc98\ub9ac (Stateless \ubaa8\ub4dc)","text":"<p>\ubc18\ubcf5\uc801\uc778 \ub3c5\ub9bd \uc791\uc5c5\uc5d0\ub294 Stateless \ubaa8\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc138\uc694:</p> <pre><code># Stateless \ubaa8\ub4dc - \ud788\uc2a4\ud1a0\ub9ac \uc800\uc7a5 \uc548 \ud568\nclassifier = LLM.create(\"gpt-4o-mini\", stateless=True)\n\n# \ub300\ub7c9\uc758 \ud14d\uc2a4\ud2b8 \ubd84\ub958\ntexts = [\n    \"\uc774 \uc81c\ud488 \uc815\ub9d0 \uc88b\uc544\uc694!\",\n    \"\ubc30\uc1a1\uc774 \ub108\ubb34 \ub2a6\uc5b4\uc694\",\n    \"\ud488\uc9c8\uc774 \uae30\ub300 \uc774\ud558\ub124\uc694\",\n    \"\ub2e4\uc2dc \uad6c\ub9e4\ud560 \uc608\uc815\uc785\ub2c8\ub2e4\"\n]\n\nfor text in texts:\n    reply = classifier.ask(\n        f\"\uac10\uc815 \ubd84\uc11d: {text}\",\n        choices=[\"\uae0d\uc815\", \"\ubd80\uc815\"]\n    )\n    print(f\"{text} -&gt; {reply.choice}\")\n</code></pre>"},{"location":"getting-started/quickstart/#_3","title":"\ub2e4\uc74c \ub2e8\uacc4","text":"<p>\ucd95\ud558\ud569\ub2c8\ub2e4! \ud83c\udf89 pyhub-llm\uc758 \uae30\ubcf8 \uae30\ub2a5\uc744 \ubaa8\ub450 \uc0b4\ud3b4\ubcf4\uc558\uc2b5\ub2c8\ub2e4.</p> <p>\ub354 \uc790\uc138\ud55c \ub0b4\uc6a9\uc744 \uc54c\uc544\ubcf4\ub824\uba74:</p> <ul> <li>\uae30\ubcf8 \uc0ac\uc6a9\ubc95 \uac00\uc774\ub4dc - \ub354 \ub9ce\uc740 \uae30\ubcf8 \uae30\ub2a5</li> <li>\ub300\ud654 \uad00\ub9ac - \ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac \uad00\ub9ac</li> <li>\uad6c\uc870\ud654\ub41c \ucd9c\ub825 - \ubcf5\uc7a1\ud55c \uc2a4\ud0a4\ub9c8 \uc0ac\uc6a9</li> <li>API \ub808\ud37c\ub7f0\uc2a4 - \uc804\uccb4 API \ubb38\uc11c</li> </ul>"},{"location":"getting-started/quickstart/#_4","title":"\ub3c4\uc6c0\ub9d0","text":"<p>\ubb38\uc81c\uac00 \ubc1c\uc0dd\ud588\ub098\uc694?</p> <ul> <li>\ud83d\udce7 \uc774\uba54\uc77c: me@pyhub.kr</li> <li>\ud83d\udcac GitHub Discussions</li> <li>\ud83d\udc1b GitHub Issues</li> </ul>"},{"location":"guides/","title":"\uac00\uc774\ub4dc","text":"<p>pyhub-llm\uc758 \ub2e4\uc591\ud55c \uae30\ub2a5\uc744 \uc790\uc138\ud788 \uc54c\uc544\ubd05\ub2c8\ub2e4.</p>"},{"location":"guides/#_2","title":"\uac00\uc774\ub4dc \ubaa9\ub85d","text":"<ul> <li> <p> \uae30\ubcf8 \uc0ac\uc6a9\ubc95</p> <p>LLM \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131, \uc9c8\ubb38\ud558\uae30, \uc751\ub2f5 \ucc98\ub9ac \ub4f1 \uae30\ubcf8\uc801\uc778 \uc0ac\uc6a9 \ubc29\ubc95\uc744 \uc54c\uc544\ubd05\ub2c8\ub2e4.</p> </li> <li> <p> \ub300\ud654 \uad00\ub9ac</p> <p>\ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac \uad00\ub9ac, Stateless \ubaa8\ub4dc, \ucee8\ud14d\uc2a4\ud2b8 \uc708\ub3c4\uc6b0 \ub4f1\uc744 \ub2e4\ub8f9\ub2c8\ub2e4.</p> </li> <li> <p> \ud504\ub85c\ubc14\uc774\ub354</p> <p>OpenAI, Anthropic, Google \ub4f1 \uac01 \ud504\ub85c\ubc14\uc774\ub354\uc758 \ud2b9\uc9d5\uacfc \uc0ac\uc6a9\ubc95\uc744 \uc54c\uc544\ubd05\ub2c8\ub2e4.</p> </li> <li> <p> \uad6c\uc870\ud654\ub41c \ucd9c\ub825</p> <p>Pydantic \uc2a4\ud0a4\ub9c8\ub97c \uc0ac\uc6a9\ud55c \ud0c0\uc785 \uc548\uc804\ud55c \uc751\ub2f5 \ucc98\ub9ac \ubc29\ubc95\uc744 \ubc30\uc6c1\ub2c8\ub2e4.</p> </li> <li> <p> \uace0\uae09 \uae30\ub2a5</p> <p>\uc784\ubca0\ub529, \uce90\uc2f1, \uc2a4\ud2b8\ub9ac\ubc0d, \ube44\ub3d9\uae30 \ucc98\ub9ac \ub4f1 \uace0\uae09 \uae30\ub2a5\uc744 \ub2e4\ub8f9\ub2c8\ub2e4.</p> </li> </ul>"},{"location":"guides/#_3","title":"\ud559\uc2b5 \uacbd\ub85c","text":""},{"location":"guides/#_4","title":"\ucd08\uae09\uc790","text":"<ol> <li>\uae30\ubcf8 \uc0ac\uc6a9\ubc95\ubd80\ud130 \uc2dc\uc791\ud558\uc138\uc694</li> <li>\ub300\ud654 \uad00\ub9ac\ub85c \ub300\ud654\ud615 \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30</li> <li>\ud504\ub85c\ubc14\uc774\ub354\ub97c \ube44\uad50\ud558\uace0 \uc120\ud0dd\ud558\uae30</li> </ol>"},{"location":"guides/#_5","title":"\uc911\uae09\uc790","text":"<ol> <li>\uad6c\uc870\ud654\ub41c \ucd9c\ub825\uc73c\ub85c \ubcf5\uc7a1\ud55c \ub370\uc774\ud130 \ucc98\ub9ac</li> <li>\uace0\uae09 \uae30\ub2a5\uc758 \uc2a4\ud2b8\ub9ac\ubc0d\uacfc \ube44\ub3d9\uae30 \ucc98\ub9ac \ud65c\uc6a9</li> <li>\uc131\ub2a5 \ucd5c\uc801\ud654 \uae30\ubc95 \uc801\uc6a9</li> </ol>"},{"location":"guides/#_6","title":"\uace0\uae09\uc790","text":"<ol> <li>\ucee4\uc2a4\ud140 \ud504\ub85c\ubc14\uc774\ub354 \uad6c\ud604</li> <li>MCP(Model Context Protocol) \ud1b5\ud569</li> <li>\ub300\uaddc\ubaa8 \uc2dc\uc2a4\ud15c \uc544\ud0a4\ud14d\ucc98 \uc124\uacc4</li> </ol>"},{"location":"guides/#_7","title":"\uc8fc\uc694 \uac1c\ub150","text":"<p>\ud1b5\ud569 \uc778\ud130\ud398\uc774\uc2a4</p> <p>\ubaa8\ub4e0 LLM \ud504\ub85c\ubc14\uc774\ub354\ub294 \ub3d9\uc77c\ud55c \uc778\ud130\ud398\uc774\uc2a4\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ud55c \ubc88 \ubc30\uc6b0\uba74 \ubaa8\ub4e0 \ud504\ub85c\ubc14\uc774\ub354\uc5d0 \uc801\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\ud0c0\uc785 \uc548\uc804\uc131</p> <p>pyhub-llm\uc740 \uc644\uc804\ud55c \ud0c0\uc785 \ud78c\ud2b8\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. IDE\uc758 \uc790\ub3d9 \uc644\uc131\uacfc \ud0c0\uc785 \uac80\uc0ac\ub97c \ud65c\uc6a9\ud558\uc138\uc694.</p> <p>API \ube44\uc6a9</p> <p>\ub300\ubd80\ubd84\uc758 LLM API\ub294 \ud1a0\ud070 \ub2e8\uc704\ub85c \uacfc\uae08\ub429\ub2c8\ub2e4. \uce90\uc2f1\uacfc Stateless \ubaa8\ub4dc\ub97c \ud65c\uc6a9\ud574 \ube44\uc6a9\uc744 \uc808\uac10\ud558\uc138\uc694.</p>"},{"location":"guides/#_8","title":"\uc608\uc81c \uc911\uc2ec \ud559\uc2b5","text":"<p>\uac01 \uac00\uc774\ub4dc\ub294 \uc2e4\uc81c \ucf54\ub4dc \uc608\uc81c\ub97c \uc911\uc2ec\uc73c\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code># \ubaa8\ub4e0 \uc608\uc81c\ub294 \ubc14\ub85c \uc2e4\ud589 \uac00\ub2a5\ud569\ub2c8\ub2e4\nfrom pyhub.llm import LLM\n\nllm = LLM.create(\"gpt-4o-mini\")\nreply = llm.ask(\"Hello, World!\")\nprint(reply.text)\n</code></pre>"},{"location":"guides/#_9","title":"\ub3c4\uc6c0\uc774 \ud544\uc694\ud558\uc2e0\uac00\uc694?","text":"<ul> <li>\ud83d\udca1 \uac01 \ud398\uc774\uc9c0\uc758 \uc608\uc81c \ucf54\ub4dc\ub97c \uc9c1\uc811 \uc2e4\ud589\ud574\ubcf4\uc138\uc694</li> <li>\ud83d\udcdd \ucf54\ub4dc \ube14\ub85d\uc758 \ubcf5\uc0ac \ubc84\ud2bc\uc744 \ud65c\uc6a9\ud558\uc138\uc694</li> <li>\ud83d\udd0d \uac80\uc0c9 \uae30\ub2a5\uc73c\ub85c \ud544\uc694\ud55c \ub0b4\uc6a9\uc744 \ube60\ub974\uac8c \ucc3e\uc73c\uc138\uc694</li> <li>\ud83d\udcac \uc9c8\ubb38\uc774 \uc788\ub2e4\uba74 GitHub Discussions\uc5d0 \ub0a8\uaca8\uc8fc\uc138\uc694</li> </ul>"},{"location":"guides/advanced/","title":"\uace0\uae09 \uae30\ub2a5","text":"<p>pyhub-llm\uc758 \uace0\uae09 \uae30\ub2a5\uc744 \ud65c\uc6a9\ud558\uc5ec \uc131\ub2a5\uc744 \ucd5c\uc801\ud654\ud558\uace0 \ubcf5\uc7a1\ud55c \uc0ac\uc6a9 \uc0ac\ub840\ub97c \uad6c\ud604\ud558\ub294 \ubc29\ubc95\uc744 \uc54c\uc544\ubd05\ub2c8\ub2e4.</p>"},{"location":"guides/advanced/#_2","title":"\uc2a4\ud2b8\ub9ac\ubc0d \uc751\ub2f5","text":""},{"location":"guides/advanced/#_3","title":"\uae30\ubcf8 \uc2a4\ud2b8\ub9ac\ubc0d","text":"<pre><code>from pyhub.llm import LLM\n\nllm = LLM.create(\"gpt-4o-mini\")\n\n# \uc2e4\uc2dc\uac04 \uc2a4\ud2b8\ub9ac\ubc0d \ucd9c\ub825\nfor chunk in llm.ask(\"\ud30c\uc774\uc36c\uc758 \uc5ed\uc0ac\ub97c \uc790\uc138\ud788 \uc124\uba85\ud574\uc8fc\uc138\uc694\", stream=True):\n    print(chunk.text, end=\"\", flush=True)\nprint()  # \uc904\ubc14\uafc8\n\n# \uc2a4\ud2b8\ub9ac\ubc0d \uc911 \ud1b5\uacc4\ntotal_tokens = 0\nchunks_received = 0\n\nfor chunk in llm.ask(\"\uba38\uc2e0\ub7ec\ub2dd \uc54c\uace0\ub9ac\uc998\uc744 \uc124\uba85\ud574\uc8fc\uc138\uc694\", stream=True):\n    print(chunk.text, end=\"\", flush=True)\n    if chunk.text:\n        total_tokens += len(chunk.text.split())\n        chunks_received += 1\n\nprint(f\"\\n\\n\uccad\ud06c \uc218: {chunks_received}, \ub300\ub7b5\uc801\uc778 \ud1a0\ud070 \uc218: {total_tokens}\")\n</code></pre>"},{"location":"guides/advanced/#_4","title":"\uc2a4\ud2b8\ub9ac\ubc0d \uc911 \ucc98\ub9ac","text":"<pre><code>import time\nfrom typing import List\n\nclass StreamProcessor:\n    def __init__(self):\n        self.buffer = \"\"\n        self.sentences = []\n        self.start_time = time.time()\n\n    def process_chunk(self, chunk):\n        \"\"\"\uccad\ud06c\ub97c \ucc98\ub9ac\ud558\uace0 \uc644\uc131\ub41c \ubb38\uc7a5 \ubc18\ud658\"\"\"\n        self.buffer += chunk.text\n\n        # \ubb38\uc7a5 \ub2e8\uc704\ub85c \ubd84\ub9ac\n        while \".\" in self.buffer or \"!\" in self.buffer or \"?\" in self.buffer:\n            # \uccab \ubc88\uc9f8 \ubb38\uc7a5 \uc885\ub8cc \uc9c0\uc810 \ucc3e\uae30\n            end_idx = min(\n                self.buffer.find(\".\") if \".\" in self.buffer else float('inf'),\n                self.buffer.find(\"!\") if \"!\" in self.buffer else float('inf'),\n                self.buffer.find(\"?\") if \"?\" in self.buffer else float('inf')\n            )\n\n            if end_idx != float('inf'):\n                sentence = self.buffer[:end_idx + 1].strip()\n                self.buffer = self.buffer[end_idx + 1:].lstrip()\n\n                if sentence:\n                    self.sentences.append(sentence)\n                    return sentence\n\n        return None\n\n    def get_stats(self):\n        elapsed = time.time() - self.start_time\n        return {\n            \"sentences\": len(self.sentences),\n            \"elapsed_seconds\": elapsed,\n            \"sentences_per_second\": len(self.sentences) / elapsed if elapsed &gt; 0 else 0\n        }\n\n# \uc0ac\uc6a9\nprocessor = StreamProcessor()\n\nfor chunk in llm.ask(\"\uc778\uacf5\uc9c0\ub2a5\uc758 \uc7a5\ub2e8\uc810\uc744 5\uac00\uc9c0\uc529 \uc124\uba85\ud574\uc8fc\uc138\uc694\", stream=True):\n    sentence = processor.process_chunk(chunk)\n    if sentence:\n        print(f\"\\n[\ubb38\uc7a5 {len(processor.sentences)}] {sentence}\")\n\nstats = processor.get_stats()\nprint(f\"\\n\ud1b5\uacc4: {stats}\")\n</code></pre>"},{"location":"guides/advanced/#_5","title":"\uc870\uae30 \uc885\ub8cc","text":"<pre><code>def stream_until_keyword(prompt: str, stop_keyword: str, max_tokens: int = 500):\n    \"\"\"\ud2b9\uc815 \ud0a4\uc6cc\ub4dc\uac00 \ub098\uc624\uba74 \uc2a4\ud2b8\ub9ac\ubc0d \uc911\ub2e8\"\"\"\n    llm = LLM.create(\"gpt-4o-mini\")\n    collected_text = \"\"\n\n    try:\n        for chunk in llm.ask(prompt, stream=True, max_tokens=max_tokens):\n            collected_text += chunk.text\n            print(chunk.text, end=\"\", flush=True)\n\n            if stop_keyword.lower() in collected_text.lower():\n                print(f\"\\n\\n['{stop_keyword}' \ud0a4\uc6cc\ub4dc \uac10\uc9c0 - \uc911\ub2e8]\")\n                break\n    except KeyboardInterrupt:\n        print(\"\\n\\n[\uc0ac\uc6a9\uc790 \uc911\ub2e8]\")\n\n    return collected_text\n\n# \uc0ac\uc6a9\ntext = stream_until_keyword(\n    \"\ud30c\uc774\uc36c\uc758 \uc7a5\uc810\uc744 \ub098\uc5f4\ud574\uc8fc\uc138\uc694\",\n    stop_keyword=\"\ub2e8\uc810\"\n)\n</code></pre>"},{"location":"guides/advanced/#_6","title":"\ube44\ub3d9\uae30 \ucc98\ub9ac","text":""},{"location":"guides/advanced/#_7","title":"\uae30\ubcf8 \ube44\ub3d9\uae30 \ud638\ucd9c","text":"<pre><code>import asyncio\nfrom typing import List\n\nasync def async_example():\n    llm = LLM.create(\"gpt-4o-mini\")\n\n    # \ub2e8\uc77c \ube44\ub3d9\uae30 \ud638\ucd9c\n    reply = await llm.ask_async(\"\ud30c\uc774\uc36c\uc758 \ube44\ub3d9\uae30 \ud504\ub85c\uadf8\ub798\ubc0d\uc744 \uc124\uba85\ud574\uc8fc\uc138\uc694\")\n    print(reply.text)\n\n    # \uc5ec\ub7ec \ube44\ub3d9\uae30 \ud638\ucd9c \ub3d9\uc2dc \uc2e4\ud589\n    questions = [\n        \"\ud30c\uc774\uc36c\uc774\ub780?\",\n        \"\uc790\ubc14\uc2a4\ud06c\ub9bd\ud2b8\ub780?\",\n        \"Go \uc5b8\uc5b4\ub780?\"\n    ]\n\n    tasks = [llm.ask_async(q) for q in questions]\n    replies = await asyncio.gather(*tasks)\n\n    for q, r in zip(questions, replies):\n        print(f\"\\nQ: {q}\")\n        print(f\"A: {r.text[:100]}...\")\n\n# \uc2e4\ud589\nasyncio.run(async_example())\n</code></pre>"},{"location":"guides/advanced/#_8","title":"\ube44\ub3d9\uae30 \uc2a4\ud2b8\ub9ac\ubc0d","text":"<pre><code>async def async_streaming():\n    llm = LLM.create(\"gpt-4o-mini\")\n\n    # \ube44\ub3d9\uae30 \uc2a4\ud2b8\ub9ac\ubc0d\n    async for chunk in llm.ask_async(\"AI\uc758 \ubbf8\ub798\ub97c \uc608\uce21\ud574\uc8fc\uc138\uc694\", stream=True):\n        print(chunk.text, end=\"\", flush=True)\n        # \ub2e4\ub978 \ube44\ub3d9\uae30 \uc791\uc5c5 \uc218\ud589 \uac00\ub2a5\n        await asyncio.sleep(0.01)  # \uc2dc\ubbac\ub808\uc774\uc158\n\n# \ub3d9\uc2dc \uc2a4\ud2b8\ub9ac\ubc0d\nasync def parallel_streaming():\n    llm1 = LLM.create(\"gpt-4o-mini\", stateless=True)\n    llm2 = LLM.create(\"claude-3-5-haiku-latest\", stateless=True)\n\n    async def stream_with_prefix(llm, prompt, prefix):\n        async for chunk in llm.ask_async(prompt, stream=True):\n            print(f\"[{prefix}] {chunk.text}\", end=\"\")\n\n    # \ub450 \ubaa8\ub378\uc5d0\uc11c \ub3d9\uc2dc\uc5d0 \uc2a4\ud2b8\ub9ac\ubc0d\n    await asyncio.gather(\n        stream_with_prefix(llm1, \"\ud30c\uc774\uc36c\uc758 \uc7a5\uc810\", \"GPT\"),\n        stream_with_prefix(llm2, \"\ud30c\uc774\uc36c\uc758 \uc7a5\uc810\", \"Claude\")\n    )\n\nasyncio.run(parallel_streaming())\n</code></pre>"},{"location":"guides/advanced/#_9","title":"\ube44\ub3d9\uae30 \ud30c\uc774\ud504\ub77c\uc778","text":"<pre><code>class AsyncPipeline:\n    def __init__(self, models: List[str]):\n        self.llms = [LLM.create(model, stateless=True) for model in models]\n\n    async def process_batch(self, items: List[str], processor_prompt: str):\n        \"\"\"\ubc30\uce58 \uc544\uc774\ud15c\uc744 \ubcd1\ub82c \ucc98\ub9ac\"\"\"\n        tasks = []\n\n        for item in items:\n            # \ub77c\uc6b4\ub4dc \ub85c\ube48\uc73c\ub85c LLM \ud560\ub2f9\n            llm = self.llms[len(tasks) % len(self.llms)]\n            prompt = processor_prompt.format(item=item)\n            tasks.append(llm.ask_async(prompt))\n\n        results = await asyncio.gather(*tasks)\n        return [(item, result.text) for item, result in zip(items, results)]\n\n    async def process_chain(self, initial_input: str, prompts: List[str]):\n        \"\"\"\uc21c\ucc28\uc801 \ucc98\ub9ac \uccb4\uc778\"\"\"\n        result = initial_input\n\n        for i, prompt in enumerate(prompts):\n            llm = self.llms[i % len(self.llms)]\n            reply = await llm.ask_async(prompt.format(input=result))\n            result = reply.text\n            print(f\"Step {i+1}: {result[:50]}...\")\n\n        return result\n\n# \uc0ac\uc6a9\nasync def pipeline_example():\n    pipeline = AsyncPipeline([\"gpt-4o-mini\", \"claude-3-5-haiku-latest\"])\n\n    # \ubc30\uce58 \ucc98\ub9ac\n    items = [\"\uc0ac\uacfc\", \"\ubc14\ub098\ub098\", \"\uc624\ub80c\uc9c0\"]\n    results = await pipeline.process_batch(\n        items,\n        \"'{item}'\uc758 \uc601\uc591 \uc131\ubd84\uc744 \ud55c \uc904\ub85c \uc694\uc57d\ud558\uc138\uc694\"\n    )\n\n    for item, result in results:\n        print(f\"{item}: {result}\")\n\n    # \uccb4\uc778 \ucc98\ub9ac\n    final = await pipeline.process_chain(\n        \"\uc778\uacf5\uc9c0\ub2a5\",\n        [\n            \"{input}\uc758 \uc815\uc758\ub97c \ud55c \ubb38\uc7a5\uc73c\ub85c\",\n            \"{input}\ub97c 5\uc0b4 \uc544\uc774\uc5d0\uac8c \uc124\uba85\ud558\uba74\",\n            \"{input}\ub97c \uc774\ubaa8\ud2f0\ucf58\uc73c\ub85c\ub9cc \ud45c\ud604\ud558\uba74\"\n        ]\n    )\n    print(f\"\\n\ucd5c\uc885 \uacb0\uacfc: {final}\")\n\nasyncio.run(pipeline_example())\n</code></pre>"},{"location":"guides/advanced/#_10","title":"\uce90\uc2f1","text":""},{"location":"guides/advanced/#_11","title":"\uae30\ubcf8 \uce90\uc2f1","text":"<pre><code>from pyhub.llm.cache import InMemoryCache, FileCache\n\n# \uc778\uba54\ubaa8\ub9ac \uce90\uc2dc\nmemory_cache = InMemoryCache(max_size=100, ttl=3600)  # 100\uac1c, 1\uc2dc\uac04\nllm_cached = LLM.create(\"gpt-4o-mini\", cache=memory_cache)\n\n# \uccab \ud638\ucd9c - API \uc694\uccad\nreply1 = llm_cached.ask(\"\ud30c\uc774\uc36c\uc758 \ucc3d\uc2dc\uc790\ub294 \ub204\uad6c\uc778\uac00\uc694?\")\nprint(f\"\uccab \ubc88\uc9f8 \ud638\ucd9c: {reply1.text}\")\nprint(f\"\uce90\uc2dc \ud788\ud2b8: {reply1.cache_hit}\")  # False\n\n# \ub450 \ubc88\uc9f8 \ud638\ucd9c - \uce90\uc2dc\uc5d0\uc11c\nreply2 = llm_cached.ask(\"\ud30c\uc774\uc36c\uc758 \ucc3d\uc2dc\uc790\ub294 \ub204\uad6c\uc778\uac00\uc694?\")\nprint(f\"\ub450 \ubc88\uc9f8 \ud638\ucd9c: {reply2.text}\")\nprint(f\"\uce90\uc2dc \ud788\ud2b8: {reply2.cache_hit}\")  # True\n</code></pre>"},{"location":"guides/advanced/#_12","title":"\ud30c\uc77c \uae30\ubc18 \uce90\uc2f1","text":"<pre><code># \uc601\uad6c \ud30c\uc77c \uce90\uc2dc\nfile_cache = FileCache(\n    cache_dir=\"./llm_cache\",\n    ttl=86400 * 7  # 7\uc77c\n)\n\nllm_persistent = LLM.create(\"gpt-4o-mini\", cache=file_cache)\n\n# \ud504\ub85c\uadf8\ub7a8 \uc7ac\uc2dc\uc791 \ud6c4\uc5d0\ub3c4 \uce90\uc2dc \uc720\uc9c0\nreply = llm_persistent.ask(\"\ubcf5\uc7a1\ud55c \uc218\ud559 \ubb38\uc81c \ud574\uacb0...\")\n</code></pre>"},{"location":"guides/advanced/#_13","title":"\ucee4\uc2a4\ud140 \uce90\uc2dc \uad6c\ud604","text":"<pre><code>from pyhub.llm.cache import BaseCache\nimport hashlib\nimport redis\nimport json\n\nclass RedisCache(BaseCache):\n    \"\"\"Redis \uae30\ubc18 \ubd84\uc0b0 \uce90\uc2dc\"\"\"\n\n    def __init__(self, redis_url: str = \"redis://localhost:6379\", ttl: int = 3600):\n        self.client = redis.from_url(redis_url)\n        self.ttl = ttl\n\n    def _make_key(self, prompt: str, **kwargs) -&gt; str:\n        \"\"\"\uce90\uc2dc \ud0a4 \uc0dd\uc131\"\"\"\n        cache_data = {\n            \"prompt\": prompt,\n            \"model\": kwargs.get(\"model\", \"\"),\n            \"temperature\": kwargs.get(\"temperature\", 0.7),\n            \"max_tokens\": kwargs.get(\"max_tokens\", None)\n        }\n\n        key_string = json.dumps(cache_data, sort_keys=True)\n        return f\"llm:cache:{hashlib.md5(key_string.encode()).hexdigest()}\"\n\n    def get(self, prompt: str, **kwargs) -&gt; Optional[str]:\n        key = self._make_key(prompt, **kwargs)\n        value = self.client.get(key)\n        return value.decode() if value else None\n\n    def set(self, prompt: str, response: str, **kwargs):\n        key = self._make_key(prompt, **kwargs)\n        self.client.setex(key, self.ttl, response)\n\n    def clear(self):\n        pattern = \"llm:cache:*\"\n        for key in self.client.scan_iter(match=pattern):\n            self.client.delete(key)\n\n# \uc0ac\uc6a9\nredis_cache = RedisCache(ttl=7200)  # 2\uc2dc\uac04\nllm_distributed = LLM.create(\"gpt-4o-mini\", cache=redis_cache)\n</code></pre>"},{"location":"guides/advanced/#_14","title":"\uce90\uc2dc \uc804\ub7b5","text":"<pre><code>class SmartCache:\n    \"\"\"\uc0c1\ud669\ubcc4 \uce90\uc2f1 \uc804\ub7b5\"\"\"\n\n    def __init__(self):\n        self.short_cache = InMemoryCache(ttl=300)      # 5\ubd84 - \ube60\ub978 \ubcc0\uacbd\n        self.medium_cache = InMemoryCache(ttl=3600)    # 1\uc2dc\uac04 - \uc77c\ubc18\n        self.long_cache = FileCache(ttl=86400 * 30)    # 30\uc77c - \uc815\uc801\n\n    def get_llm_for_query(self, query_type: str) -&gt; LLM:\n        if query_type == \"realtime\":\n            # \uc2e4\uc2dc\uac04 \uc815\ubcf4 - \uce90\uc2dc \uc5c6\uc74c\n            return LLM.create(\"gpt-4o-mini\")\n        elif query_type == \"dynamic\":\n            # \uc790\uc8fc \ubcc0\uacbd - \uc9e7\uc740 \uce90\uc2dc\n            return LLM.create(\"gpt-4o-mini\", cache=self.short_cache)\n        elif query_type == \"stable\":\n            # \uc548\uc815\uc801 \uc815\ubcf4 - \uc911\uac04 \uce90\uc2dc\n            return LLM.create(\"gpt-4o-mini\", cache=self.medium_cache)\n        else:  # static\n            # \uc815\uc801 \uc815\ubcf4 - \uae34 \uce90\uc2dc\n            return LLM.create(\"gpt-4o-mini\", cache=self.long_cache)\n\n# \uc0ac\uc6a9\ncache_manager = SmartCache()\n\n# \uc2e4\uc2dc\uac04 \uc815\ubcf4\nrealtime_llm = cache_manager.get_llm_for_query(\"realtime\")\nweather = realtime_llm.ask(\"\ud604\uc7ac \uc11c\uc6b8 \ub0a0\uc528\ub294?\")\n\n# \uc815\uc801 \uc815\ubcf4\nstatic_llm = cache_manager.get_llm_for_query(\"static\")\nhistory = static_llm.ask(\"\ud55c\uad6d\uc758 \uc5ed\uc0ac\ub97c \uc694\uc57d\ud574\uc8fc\uc138\uc694\")\n</code></pre>"},{"location":"guides/advanced/#_15","title":"\uc784\ubca0\ub529","text":""},{"location":"guides/advanced/#_16","title":"\ud14d\uc2a4\ud2b8 \uc784\ubca0\ub529","text":"<pre><code>from typing import List\nimport numpy as np\n\n# \uc784\ubca0\ub529 \uc0dd\uc131\nllm = LLM.create(\"text-embedding-3-small\")\n\n# \ub2e8\uc77c \ud14d\uc2a4\ud2b8 \uc784\ubca0\ub529\ntext = \"\ud30c\uc774\uc36c\uc740 \uac04\uacb0\ud558\uace0 \uc77d\uae30 \uc26c\uc6b4 \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\uc785\ub2c8\ub2e4.\"\nembedding = llm.embed(text)\nprint(f\"\uc784\ubca0\ub529 \ucc28\uc6d0: {len(embedding)}\")\nprint(f\"\uc784\ubca0\ub529 \ubca1\ud130 (\ucc98\uc74c 5\uac1c): {embedding[:5]}\")\n\n# \uc5ec\ub7ec \ud14d\uc2a4\ud2b8 \uc784\ubca0\ub529\ntexts = [\n    \"\ud30c\uc774\uc36c\uc740 \ub370\uc774\ud130 \uacfc\ud559\uc5d0 \ub110\ub9ac \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\",\n    \"\uc790\ubc14\uc2a4\ud06c\ub9bd\ud2b8\ub294 \uc6f9 \uac1c\ubc1c\uc758 \ud575\uc2ec \uc5b8\uc5b4\uc785\ub2c8\ub2e4.\",\n    \"\uba38\uc2e0\ub7ec\ub2dd\uc740 \uc778\uacf5\uc9c0\ub2a5\uc758 \ud55c \ubd84\uc57c\uc785\ub2c8\ub2e4.\"\n]\n\nembeddings = llm.embed_many(texts)\nprint(f\"\uc784\ubca0\ub529 \uac1c\uc218: {len(embeddings)}\")\n</code></pre>"},{"location":"guides/advanced/#_17","title":"\uc720\uc0ac\ub3c4 \uac80\uc0c9","text":"<pre><code>from sklearn.metrics.pairwise import cosine_similarity\n\nclass SemanticSearch:\n    def __init__(self, model: str = \"text-embedding-3-small\"):\n        self.llm = LLM.create(model)\n        self.documents = []\n        self.embeddings = []\n\n    def add_documents(self, documents: List[str]):\n        \"\"\"\ubb38\uc11c \ucd94\uac00 \ubc0f \uc784\ubca0\ub529\"\"\"\n        self.documents.extend(documents)\n        new_embeddings = self.llm.embed_many(documents)\n        self.embeddings.extend(new_embeddings)\n\n    def search(self, query: str, top_k: int = 5) -&gt; List[tuple[str, float]]:\n        \"\"\"\uc758\ubbf8 \uae30\ubc18 \uac80\uc0c9\"\"\"\n        # \ucffc\ub9ac \uc784\ubca0\ub529\n        query_embedding = self.llm.embed(query)\n\n        # \ucf54\uc0ac\uc778 \uc720\uc0ac\ub3c4 \uacc4\uc0b0\n        similarities = cosine_similarity(\n            [query_embedding],\n            self.embeddings\n        )[0]\n\n        # \uc0c1\uc704 k\uac1c \uacb0\uacfc\n        top_indices = np.argsort(similarities)[-top_k:][::-1]\n\n        results = []\n        for idx in top_indices:\n            results.append((\n                self.documents[idx],\n                similarities[idx]\n            ))\n\n        return results\n\n# \uc0ac\uc6a9\nsearch_engine = SemanticSearch()\n\n# \ubb38\uc11c \ucd94\uac00\ndocuments = [\n    \"\ud30c\uc774\uc36c\uc740 \uac04\uacb0\ud558\uace0 \uc77d\uae30 \uc26c\uc6b4 \ubb38\ubc95\uc744 \uac00\uc9c4 \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\uc785\ub2c8\ub2e4.\",\n    \"\uba38\uc2e0\ub7ec\ub2dd\uc740 \ub370\uc774\ud130\ub85c\ubd80\ud130 \ud328\ud134\uc744 \ud559\uc2b5\ud558\ub294 \uc778\uacf5\uc9c0\ub2a5 \uae30\uc220\uc785\ub2c8\ub2e4.\",\n    \"\uc6f9 \uac1c\ubc1c\uc5d0\ub294 HTML, CSS, JavaScript\uac00 \ud544\uc218\uc801\uc785\ub2c8\ub2e4.\",\n    \"\ub370\uc774\ud130\ubca0\uc774\uc2a4\ub294 \uc815\ubcf4\ub97c \uccb4\uacc4\uc801\uc73c\ub85c \uc800\uc7a5\ud558\uace0 \uad00\ub9ac\ud558\ub294 \uc2dc\uc2a4\ud15c\uc785\ub2c8\ub2e4.\",\n    \"API\ub294 \uc11c\ub85c \ub2e4\ub978 \uc18c\ud504\ud2b8\uc6e8\uc5b4 \uac04\uc758 \ud1b5\uc2e0\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4.\"\n]\n\nsearch_engine.add_documents(documents)\n\n# \uac80\uc0c9\nresults = search_engine.search(\"\ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4 \ubb38\ubc95\", top_k=3)\n\nfor doc, score in results:\n    print(f\"\uc720\uc0ac\ub3c4: {score:.3f} - {doc}\")\n</code></pre>"},{"location":"guides/advanced/#_18","title":"\ud074\ub7ec\uc2a4\ud130\ub9c1","text":"<pre><code>from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\nclass TextClusterer:\n    def __init__(self, n_clusters: int = 3):\n        self.llm = LLM.create(\"text-embedding-3-small\")\n        self.n_clusters = n_clusters\n        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n\n    def cluster_texts(self, texts: List[str]) -&gt; Dict[int, List[str]]:\n        \"\"\"\ud14d\uc2a4\ud2b8\ub97c \uc758\ubbf8\uc801\uc73c\ub85c \ud074\ub7ec\uc2a4\ud130\ub9c1\"\"\"\n        # \uc784\ubca0\ub529 \uc0dd\uc131\n        embeddings = self.llm.embed_many(texts)\n\n        # \ud074\ub7ec\uc2a4\ud130\ub9c1\n        labels = self.kmeans.fit_predict(embeddings)\n\n        # \uacb0\uacfc \uc815\ub9ac\n        clusters = {}\n        for text, label in zip(texts, labels):\n            if label not in clusters:\n                clusters[label] = []\n            clusters[label].append(text)\n\n        return clusters\n\n    def visualize_clusters(self, texts: List[str], embeddings: List[List[float]]):\n        \"\"\"\ud074\ub7ec\uc2a4\ud130 \uc2dc\uac01\ud654 (2D)\"\"\"\n        # PCA\ub85c \ucc28\uc6d0 \ucd95\uc18c\n        pca = PCA(n_components=2)\n        reduced = pca.fit_transform(embeddings)\n\n        # \ud074\ub7ec\uc2a4\ud130 \ub808\uc774\ube14\n        labels = self.kmeans.predict(embeddings)\n\n        # \uc2dc\uac01\ud654\n        plt.figure(figsize=(10, 8))\n        for i in range(self.n_clusters):\n            cluster_points = reduced[labels == i]\n            plt.scatter(\n                cluster_points[:, 0],\n                cluster_points[:, 1],\n                label=f'Cluster {i}',\n                alpha=0.6\n            )\n\n        plt.title(\"Text Clustering Visualization\")\n        plt.legend()\n        plt.show()\n\n# \uc0ac\uc6a9\nclusterer = TextClusterer(n_clusters=3)\n\ntexts = [\n    # \ud504\ub85c\uadf8\ub798\ubc0d \uad00\ub828\n    \"\ud30c\uc774\uc36c\uc740 \uc778\uae30 \uc788\ub294 \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\uc785\ub2c8\ub2e4\",\n    \"\uc790\ubc14\uc2a4\ud06c\ub9bd\ud2b8\ub85c \uc6f9 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc744 \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4\",\n    \"C++\ub294 \uc2dc\uc2a4\ud15c \ud504\ub85c\uadf8\ub798\ubc0d\uc5d0 \uc0ac\uc6a9\ub429\ub2c8\ub2e4\",\n\n    # \uc74c\uc2dd \uad00\ub828\n    \"\uae40\uce58\ub294 \ud55c\uad6d\uc758 \uc804\ud1b5 \ubc1c\ud6a8 \uc2dd\ud488\uc785\ub2c8\ub2e4\",\n    \"\ud53c\uc790\ub294 \uc774\ud0c8\ub9ac\uc544\uc5d0\uc11c \uc720\ub798\ud55c \uc74c\uc2dd\uc785\ub2c8\ub2e4\",\n    \"\ucd08\ubc25\uc740 \uc77c\ubcf8\uc758 \ub300\ud45c\uc801\uc778 \uc694\ub9ac\uc785\ub2c8\ub2e4\",\n\n    # \uc6b4\ub3d9 \uad00\ub828\n    \"\ucd95\uad6c\ub294 \uc138\uacc4\uc5d0\uc11c \uac00\uc7a5 \uc778\uae30 \uc788\ub294 \uc2a4\ud3ec\uce20\uc785\ub2c8\ub2e4\",\n    \"\uc694\uac00\ub294 \ubab8\uacfc \ub9c8\uc74c\uc758 \uac74\uac15\uc5d0 \uc88b\uc2b5\ub2c8\ub2e4\",\n    \"\uc218\uc601\uc740 \uc804\uc2e0 \uc6b4\ub3d9\uc5d0 \ud6a8\uacfc\uc801\uc785\ub2c8\ub2e4\"\n]\n\nclusters = clusterer.cluster_texts(texts)\n\nfor cluster_id, cluster_texts in clusters.items():\n    print(f\"\\n\ud074\ub7ec\uc2a4\ud130 {cluster_id}:\")\n    for text in cluster_texts:\n        print(f\"  - {text}\")\n</code></pre>"},{"location":"guides/advanced/#_19","title":"\uba54\ud0c0\ud504\ub86c\ud504\ud305","text":""},{"location":"guides/advanced/#_20","title":"\ud504\ub86c\ud504\ud2b8 \uc790\ub3d9 \uc0dd\uc131","text":"<pre><code>class MetaPrompter:\n    def __init__(self, model: str = \"gpt-4o\"):\n        self.llm = LLM.create(model)\n\n    def generate_prompt(self, task: str, examples: List[Dict] = None) -&gt; str:\n        \"\"\"\uc791\uc5c5\uc5d0 \ucd5c\uc801\ud654\ub41c \ud504\ub86c\ud504\ud2b8 \uc0dd\uc131\"\"\"\n\n        meta_prompt = f\"\"\"\n        \ub2e4\uc74c \uc791\uc5c5\uc744 \uc218\ud589\ud558\uae30 \uc704\ud55c \ucd5c\uc801\uc758 \ud504\ub86c\ud504\ud2b8\ub97c \uc0dd\uc131\ud558\uc138\uc694:\n\n        \uc791\uc5c5: {task}\n\n        \ud504\ub86c\ud504\ud2b8\ub294 \ub2e4\uc74c\uc744 \ud3ec\ud568\ud574\uc57c \ud569\ub2c8\ub2e4:\n        1. \uba85\ud655\ud55c \uc9c0\uc2dc\uc0ac\ud56d\n        2. \ucd9c\ub825 \ud615\uc2dd \uc9c0\uc815\n        3. \ud488\uc9c8 \uae30\uc900\n        4. \uc608\uc2dc (\uc81c\uacf5\ub41c \uacbd\uc6b0)\n\n        \"\"\"\n\n        if examples:\n            meta_prompt += \"\\n\uc81c\uacf5\ub41c \uc608\uc2dc:\\n\"\n            for i, example in enumerate(examples):\n                meta_prompt += f\"{i+1}. \uc785\ub825: {example['input']}\\n   \ucd9c\ub825: {example['output']}\\n\"\n\n        reply = self.llm.ask(meta_prompt)\n        return reply.text\n\n    def optimize_prompt(self, original_prompt: str, feedback: str) -&gt; str:\n        \"\"\"\ud53c\ub4dc\ubc31\uc744 \ubc14\ud0d5\uc73c\ub85c \ud504\ub86c\ud504\ud2b8 \uac1c\uc120\"\"\"\n\n        optimization_prompt = f\"\"\"\n        \ub2e4\uc74c \ud504\ub86c\ud504\ud2b8\ub97c \ud53c\ub4dc\ubc31\uc744 \ubc14\ud0d5\uc73c\ub85c \uac1c\uc120\ud558\uc138\uc694:\n\n        \uc6d0\ubcf8 \ud504\ub86c\ud504\ud2b8:\n        {original_prompt}\n\n        \ud53c\ub4dc\ubc31:\n        {feedback}\n\n        \uac1c\uc120\ub41c \ud504\ub86c\ud504\ud2b8\ub97c \uc81c\uc2dc\ud558\uc138\uc694.\n        \"\"\"\n\n        reply = self.llm.ask(optimization_prompt)\n        return reply.text\n\n# \uc0ac\uc6a9\nmeta_prompter = MetaPrompter()\n\n# \ud504\ub86c\ud504\ud2b8 \uc0dd\uc131\ntask = \"\uace0\uac1d \ub9ac\ubdf0\ub97c \ubd84\uc11d\ud558\uc5ec \uac10\uc815\uacfc \uc8fc\uc694 \ud0a4\uc6cc\ub4dc\ub97c \ucd94\ucd9c\"\nexamples = [\n    {\n        \"input\": \"\uc774 \uc81c\ud488 \uc815\ub9d0 \uc88b\uc544\uc694! \ubc30\uc1a1\ub3c4 \ube60\ub974\uace0 \ud488\uc9c8\ub3c4 \ucd5c\uace0\uc785\ub2c8\ub2e4.\",\n        \"output\": \"\uac10\uc815: \uae0d\uc815, \ud0a4\uc6cc\ub4dc: \ud488\uc9c8, \ubc30\uc1a1\"\n    }\n]\n\noptimized_prompt = meta_prompter.generate_prompt(task, examples)\nprint(\"\uc0dd\uc131\ub41c \ud504\ub86c\ud504\ud2b8:\", optimized_prompt)\n\n# \ud504\ub86c\ud504\ud2b8 \uac1c\uc120\nfeedback = \"\uac10\uc815\uc744 \ub354 \uc138\ubd84\ud654\ud558\uace0 \uc2e0\ub8b0\ub3c4 \uc810\uc218\ub3c4 \ud3ec\ud568\ud574\uc8fc\uc138\uc694\"\nimproved_prompt = meta_prompter.optimize_prompt(optimized_prompt, feedback)\nprint(\"\\n\uac1c\uc120\ub41c \ud504\ub86c\ud504\ud2b8:\", improved_prompt)\n</code></pre>"},{"location":"guides/advanced/#_21","title":"\uccb4\uc778 \ubc0f \ud30c\uc774\ud504\ub77c\uc778","text":""},{"location":"guides/advanced/#_22","title":"\uc21c\ucc28 \uccb4\uc778","text":"<pre><code>class SequentialChain:\n    def __init__(self):\n        self.steps = []\n\n    def add_step(self, name: str, llm: LLM, prompt_template: str):\n        \"\"\"\uccb4\uc778\uc5d0 \ub2e8\uacc4 \ucd94\uac00\"\"\"\n        self.steps.append({\n            \"name\": name,\n            \"llm\": llm,\n            \"prompt_template\": prompt_template\n        })\n        return self\n\n    def run(self, initial_input: str) -&gt; Dict[str, str]:\n        \"\"\"\uccb4\uc778 \uc2e4\ud589\"\"\"\n        results = {\"initial_input\": initial_input}\n        current_output = initial_input\n\n        for step in self.steps:\n            prompt = step[\"prompt_template\"].format(\n                input=current_output,\n                **results  # \uc774\uc804 \uacb0\uacfc\ub4e4\ub3c4 \uc0ac\uc6a9 \uac00\ub2a5\n            )\n\n            reply = step[\"llm\"].ask(prompt)\n            current_output = reply.text\n            results[step[\"name\"]] = current_output\n\n            print(f\"\\n[{step['name']}] \uc644\ub8cc\")\n\n        return results\n\n# \uc0ac\uc6a9\nchain = SequentialChain()\n\n# \ube14\ub85c\uadf8 \ud3ec\uc2a4\ud2b8 \uc0dd\uc131 \uccb4\uc778\nchain.add_step(\n    \"outline\",\n    LLM.create(\"gpt-4o-mini\"),\n    \"\ub2e4\uc74c \uc8fc\uc81c\uc5d0 \ub300\ud55c \ube14\ub85c\uadf8 \ud3ec\uc2a4\ud2b8 \uac1c\uc694\ub97c \uc791\uc131\ud558\uc138\uc694: {input}\"\n).add_step(\n    \"draft\",\n    LLM.create(\"gpt-4o-mini\"),\n    \"\ub2e4\uc74c \uac1c\uc694\ub97c \ubc14\ud0d5\uc73c\ub85c \ube14\ub85c\uadf8 \ud3ec\uc2a4\ud2b8 \ucd08\uc548\uc744 \uc791\uc131\ud558\uc138\uc694:\\n{outline}\"\n).add_step(\n    \"polish\",\n    LLM.create(\"gpt-4o\"),\n    \"\ub2e4\uc74c \ucd08\uc548\uc744 \ub2e4\ub4ec\uc5b4 \uc644\uc131\ub3c4 \ub192\uc740 \ube14\ub85c\uadf8 \ud3ec\uc2a4\ud2b8\ub85c \ub9cc\ub4e4\uc5b4\uc8fc\uc138\uc694:\\n{draft}\"\n)\n\nresults = chain.run(\"\ud30c\uc774\uc36c\uc73c\ub85c \uc6f9 \uc2a4\ud06c\ub798\ud551\ud558\uae30\")\nprint(\"\\n\ucd5c\uc885 \uacb0\uacfc:\", results[\"polish\"][:200] + \"...\")\n</code></pre>"},{"location":"guides/advanced/#_23","title":"\uc870\uac74\ubd80 \ud30c\uc774\ud504\ub77c\uc778","text":"<pre><code>class ConditionalPipeline:\n    def __init__(self):\n        self.analyzer = LLM.create(\"gpt-4o-mini\")\n        self.processors = {}\n\n    def add_processor(self, condition: str, llm: LLM, prompt: str):\n        \"\"\"\uc870\uac74\ubcc4 \ud504\ub85c\uc138\uc11c \ucd94\uac00\"\"\"\n        self.processors[condition] = {\n            \"llm\": llm,\n            \"prompt\": prompt\n        }\n\n    async def process(self, text: str) -&gt; str:\n        \"\"\"\ud14d\uc2a4\ud2b8 \ubd84\uc11d \ud6c4 \uc801\uc808\ud55c \ud504\ub85c\uc138\uc11c\ub85c \ub77c\uc6b0\ud305\"\"\"\n\n        # 1. \ud14d\uc2a4\ud2b8 \ud0c0\uc785 \ubd84\uc11d\n        analysis = await self.analyzer.ask_async(\n            f\"\ub2e4\uc74c \ud14d\uc2a4\ud2b8\uc758 \ud0c0\uc785\uc744 \ubd84\ub958\ud558\uc138\uc694: {text}\",\n            choices=list(self.processors.keys())\n        )\n\n        text_type = analysis.choice\n\n        # 2. \ud574\ub2f9 \ud504\ub85c\uc138\uc11c \uc2e4\ud589\n        processor = self.processors[text_type]\n        result = await processor[\"llm\"].ask_async(\n            processor[\"prompt\"].format(text=text)\n        )\n\n        return result.text\n\n# \uc0ac\uc6a9\npipeline = ConditionalPipeline()\n\n# \ub2e4\uc591\ud55c \ud0c0\uc785\ubcc4 \ud504\ub85c\uc138\uc11c \uc124\uc815\npipeline.add_processor(\n    \"\uae30\uc220\ubb38\uc11c\",\n    LLM.create(\"gpt-4o-mini\"),\n    \"\ub2e4\uc74c \uae30\uc220 \ubb38\uc11c\ub97c \uc694\uc57d\ud558\uace0 \ud575\uc2ec \uac1c\ub150\uc744 \ucd94\ucd9c\ud558\uc138\uc694: {text}\"\n)\n\npipeline.add_processor(\n    \"\uace0\uac1d\ubb38\uc758\",\n    LLM.create(\"claude-3-5-haiku-latest\"),\n    \"\ub2e4\uc74c \uace0\uac1d \ubb38\uc758\uc5d0 \uce5c\uc808\ud558\uac8c \ub2f5\ubcc0\ud558\uc138\uc694: {text}\"\n)\n\npipeline.add_processor(\n    \"\ucf54\ub4dc\",\n    LLM.create(\"gpt-4-turbo\"),\n    \"\ub2e4\uc74c \ucf54\ub4dc\ub97c \ubd84\uc11d\ud558\uace0 \uac1c\uc120\uc810\uc744 \uc81c\uc548\ud558\uc138\uc694: {text}\"\n)\n\n# \uc2e4\ud589\ntext = \"def calculate_sum(numbers): return sum(numbers)\"\nresult = asyncio.run(pipeline.process(text))\nprint(result)\n</code></pre>"},{"location":"guides/advanced/#_24","title":"\uc5d0\uc774\uc804\ud2b8 \ud328\ud134","text":""},{"location":"guides/advanced/#_25","title":"\ub3c4\uad6c \uc0ac\uc6a9 \uc5d0\uc774\uc804\ud2b8","text":"<pre><code>from typing import Callable, Dict, Any\n\nclass ToolAgent:\n    def __init__(self, model: str = \"gpt-4o\"):\n        self.llm = LLM.create(model)\n        self.tools = {}\n\n    def register_tool(self, name: str, func: Callable, description: str):\n        \"\"\"\ub3c4\uad6c \ub4f1\ub85d\"\"\"\n        self.tools[name] = {\n            \"function\": func,\n            \"description\": description\n        }\n\n    def run(self, task: str) -&gt; str:\n        \"\"\"\uc791\uc5c5 \uc2e4\ud589\"\"\"\n        # 1. \uc0ac\uc6a9\ud560 \ub3c4\uad6c \uacb0\uc815\n        tool_prompt = f\"\"\"\n        \uc791\uc5c5: {task}\n\n        \uc0ac\uc6a9 \uac00\ub2a5\ud55c \ub3c4\uad6c:\n        {self._format_tools()}\n\n        \uc5b4\ub5a4 \ub3c4\uad6c\ub97c \uc0ac\uc6a9\ud574\uc57c \ud560\uae4c\uc694? \ub3c4\uad6c \uc774\ub984\ub9cc \ub2f5\ud558\uc138\uc694.\n        \"\"\"\n\n        tool_choice = self.llm.ask(\n            tool_prompt,\n            choices=list(self.tools.keys()) + [\"\uc5c6\uc74c\"]\n        ).choice\n\n        if tool_choice == \"\uc5c6\uc74c\":\n            # \ub3c4\uad6c \uc5c6\uc774 \uc9c1\uc811 \ub2f5\ubcc0\n            return self.llm.ask(task).text\n\n        # 2. \ub3c4\uad6c \ud30c\ub77c\ubbf8\ud130 \ucd94\ucd9c\n        param_prompt = f\"\"\"\n        \uc791\uc5c5: {task}\n        \uc120\ud0dd\ub41c \ub3c4\uad6c: {tool_choice}\n\n        \uc774 \ub3c4\uad6c\ub97c \uc2e4\ud589\ud558\uae30 \uc704\ud55c \ud30c\ub77c\ubbf8\ud130\ub97c JSON \ud615\uc2dd\uc73c\ub85c \uc81c\uacf5\ud558\uc138\uc694.\n        \"\"\"\n\n        params_reply = self.llm.ask(param_prompt)\n        # \uc2e4\uc81c\ub85c\ub294 JSON \ud30c\uc2f1 \ud544\uc694\n\n        # 3. \ub3c4\uad6c \uc2e4\ud589\n        tool = self.tools[tool_choice]\n        result = tool[\"function\"](**params)  # \uac04\ub2e8\ud654\ub41c \uc608\uc2dc\n\n        # 4. \uacb0\uacfc \uc815\ub9ac\n        final_prompt = f\"\"\"\n        \uc791\uc5c5: {task}\n        \ub3c4\uad6c \uc2e4\ud589 \uacb0\uacfc: {result}\n\n        \uc774 \uacb0\uacfc\ub97c \ubc14\ud0d5\uc73c\ub85c \uc0ac\uc6a9\uc790\uc5d0\uac8c \ub2f5\ubcc0\ud558\uc138\uc694.\n        \"\"\"\n\n        return self.llm.ask(final_prompt).text\n\n    def _format_tools(self) -&gt; str:\n        lines = []\n        for name, tool in self.tools.items():\n            lines.append(f\"- {name}: {tool['description']}\")\n        return \"\\n\".join(lines)\n\n# \uc0ac\uc6a9\nagent = ToolAgent()\n\n# \ub3c4\uad6c \ub4f1\ub85d\ndef calculate(expression: str) -&gt; float:\n    \"\"\"\uc218\uc2dd \uacc4\uc0b0\"\"\"\n    return eval(expression)  # \uc2e4\uc81c\ub85c\ub294 \uc548\uc804\ud55c \ud30c\uc11c \uc0ac\uc6a9\n\ndef web_search(query: str) -&gt; str:\n    \"\"\"\uc6f9 \uac80\uc0c9 \uc2dc\ubbac\ub808\uc774\uc158\"\"\"\n    return f\"\uac80\uc0c9 \uacb0\uacfc: {query}\uc5d0 \ub300\ud55c \ucd5c\uc2e0 \uc815\ubcf4...\"\n\nagent.register_tool(\"\uacc4\uc0b0\uae30\", calculate, \"\uc218\ud559 \uacc4\uc0b0\uc744 \uc218\ud589\ud569\ub2c8\ub2e4\")\nagent.register_tool(\"\uc6f9\uac80\uc0c9\", web_search, \"\uc778\ud130\ub137\uc5d0\uc11c \uc815\ubcf4\ub97c \uac80\uc0c9\ud569\ub2c8\ub2e4\")\n\n# \uc791\uc5c5 \uc2e4\ud589\nresult = agent.run(\"2024\ub144 \ud604\uc7ac \ud30c\uc774\uc36c \ucd5c\uc2e0 \ubc84\uc804\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\")\nprint(result)\n</code></pre>"},{"location":"guides/advanced/#_26","title":"\uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1","text":""},{"location":"guides/advanced/#_27","title":"\uba54\ud2b8\ub9ad \uc218\uc9d1","text":"<pre><code>import time\nfrom dataclasses import dataclass\nfrom collections import defaultdict\n\n@dataclass\nclass Metrics:\n    prompt: str\n    model: str\n    response_time: float\n    tokens_used: int\n    cache_hit: bool\n    error: Optional[str] = None\n\nclass PerformanceMonitor:\n    def __init__(self):\n        self.metrics = []\n        self.model_stats = defaultdict(lambda: {\n            \"count\": 0,\n            \"total_time\": 0,\n            \"total_tokens\": 0,\n            \"errors\": 0,\n            \"cache_hits\": 0\n        })\n\n    def track(self, llm: LLM):\n        \"\"\"LLM \uc778\uc2a4\ud134\uc2a4\uc5d0 \ubaa8\ub2c8\ud130\ub9c1 \ucd94\uac00\"\"\"\n        original_ask = llm.ask\n\n        def wrapped_ask(prompt: str, **kwargs):\n            start_time = time.time()\n            error = None\n\n            try:\n                reply = original_ask(prompt, **kwargs)\n                response_time = time.time() - start_time\n\n                metric = Metrics(\n                    prompt=prompt[:100],  # \ucc98\uc74c 100\uc790\ub9cc\n                    model=llm.model,\n                    response_time=response_time,\n                    tokens_used=reply.usage.total_tokens if reply.usage else 0,\n                    cache_hit=getattr(reply, 'cache_hit', False)\n                )\n\n                self._update_stats(metric)\n                return reply\n\n            except Exception as e:\n                error = str(e)\n                metric = Metrics(\n                    prompt=prompt[:100],\n                    model=llm.model,\n                    response_time=time.time() - start_time,\n                    tokens_used=0,\n                    cache_hit=False,\n                    error=error\n                )\n                self._update_stats(metric)\n                raise\n\n        llm.ask = wrapped_ask\n        return llm\n\n    def _update_stats(self, metric: Metrics):\n        self.metrics.append(metric)\n        stats = self.model_stats[metric.model]\n\n        stats[\"count\"] += 1\n        stats[\"total_time\"] += metric.response_time\n        stats[\"total_tokens\"] += metric.tokens_used\n\n        if metric.error:\n            stats[\"errors\"] += 1\n        if metric.cache_hit:\n            stats[\"cache_hits\"] += 1\n\n    def get_report(self) -&gt; Dict[str, Any]:\n        \"\"\"\uc131\ub2a5 \ub9ac\ud3ec\ud2b8 \uc0dd\uc131\"\"\"\n        report = {}\n\n        for model, stats in self.model_stats.items():\n            count = stats[\"count\"]\n            if count &gt; 0:\n                report[model] = {\n                    \"requests\": count,\n                    \"avg_response_time\": stats[\"total_time\"] / count,\n                    \"total_tokens\": stats[\"total_tokens\"],\n                    \"avg_tokens_per_request\": stats[\"total_tokens\"] / count,\n                    \"error_rate\": stats[\"errors\"] / count,\n                    \"cache_hit_rate\": stats[\"cache_hits\"] / count\n                }\n\n        return report\n\n# \uc0ac\uc6a9\nmonitor = PerformanceMonitor()\n\n# \ubaa8\ub2c8\ud130\ub9c1\ud560 LLM \uc0dd\uc131\nllm1 = monitor.track(LLM.create(\"gpt-4o-mini\"))\nllm2 = monitor.track(LLM.create(\"claude-3-5-haiku-latest\"))\n\n# \uc791\uc5c5 \uc218\ud589\nfor i in range(10):\n    llm1.ask(f\"\uc9c8\ubb38 {i}\")\n    llm2.ask(f\"\uc9c8\ubb38 {i}\")\n\n# \ub9ac\ud3ec\ud2b8 \ud655\uc778\nreport = monitor.get_report()\nfor model, stats in report.items():\n    print(f\"\\n{model}:\")\n    print(f\"  \ud3c9\uade0 \uc751\ub2f5 \uc2dc\uac04: {stats['avg_response_time']:.2f}\ucd08\")\n    print(f\"  \ud3c9\uade0 \ud1a0\ud070 \uc0ac\uc6a9: {stats['avg_tokens_per_request']:.0f}\")\n    print(f\"  \uce90\uc2dc \ud788\ud2b8\uc728: {stats['cache_hit_rate']:.1%}\")\n</code></pre>"},{"location":"guides/advanced/#_28","title":"\ub2e4\uc74c \ub2e8\uacc4","text":"<ul> <li>API \ub808\ud37c\ub7f0\uc2a4 - \uc804\uccb4 API \ubb38\uc11c</li> <li>\uc608\uc81c - \uc2e4\uc81c \uc0ac\uc6a9 \uc0ac\ub840</li> <li>\ubb38\uc81c \ud574\uacb0 - \uc77c\ubc18\uc801\uc778 \ubb38\uc81c\uc640 \ud574\uacb0\ubc95</li> </ul>"},{"location":"guides/basic-usage/","title":"\uae30\ubcf8 \uc0ac\uc6a9\ubc95","text":"<p>pyhub-llm\uc758 \uae30\ubcf8\uc801\uc778 \uc0ac\uc6a9 \ubc29\ubc95\uc744 \uc54c\uc544\ubd05\ub2c8\ub2e4.</p>"},{"location":"guides/basic-usage/#llm","title":"LLM \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131","text":""},{"location":"guides/basic-usage/#_2","title":"\uc790\ub3d9 \ud504\ub85c\ubc14\uc774\ub354 \uac10\uc9c0","text":"<p>\uac00\uc7a5 \uac04\ub2e8\ud55c \ubc29\ubc95\uc740 \ubaa8\ub378\uba85\uc744 \ud1b5\ud55c \uc790\ub3d9 \ud504\ub85c\ubc14\uc774\ub354 \uac10\uc9c0\uc785\ub2c8\ub2e4:</p> <pre><code>from pyhub.llm import LLM\n\n# \ubaa8\ub378\uba85\uc73c\ub85c \ud504\ub85c\ubc14\uc774\ub354 \uc790\ub3d9 \uac10\uc9c0\nllm = LLM.create(\"gpt-4o-mini\")  # OpenAI\nllm = LLM.create(\"claude-3-5-haiku-latest\")  # Anthropic\nllm = LLM.create(\"gemini-2.0-flash-exp\")  # Google\n</code></pre>"},{"location":"guides/basic-usage/#_3","title":"\uba85\uc2dc\uc801 \ud504\ub85c\ubc14\uc774\ub354 \uc0ac\uc6a9","text":"<p>\ud2b9\uc815 \ud504\ub85c\ubc14\uc774\ub354\ub97c \uc9c1\uc811 \uc0ac\uc6a9\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4:</p> <pre><code>from pyhub.llm import OpenAILLM, AnthropicLLM\n\n# OpenAI\nopenai_llm = OpenAILLM(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n    max_tokens=1000\n)\n\n# Anthropic\nanthropic_llm = AnthropicLLM(\n    model=\"claude-3-5-haiku-latest\",\n    temperature=0.5\n)\n</code></pre>"},{"location":"guides/basic-usage/#_4","title":"\uae30\ubcf8 \uc9c8\ubb38\ud558\uae30","text":""},{"location":"guides/basic-usage/#_5","title":"\ud14d\uc2a4\ud2b8 \uc751\ub2f5 \ubc1b\uae30","text":"<pre><code># \uac04\ub2e8\ud55c \uc9c8\ubb38\nreply = llm.ask(\"\ud30c\uc774\uc36c\uc758 \uc7a5\uc810\uc744 3\uac00\uc9c0 \uc54c\ub824\uc8fc\uc138\uc694\")\nprint(reply.text)\n\n# \uc751\ub2f5 \uba54\ud0c0\ub370\uc774\ud130 \ud655\uc778\nprint(f\"\uc0ac\uc6a9 \ud1a0\ud070: {reply.usage.total_tokens}\")\nprint(f\"\uc751\ub2f5 \uc2dc\uac04: {reply.elapsed_time:.2f}\ucd08\")\n</code></pre>"},{"location":"guides/basic-usage/#_6","title":"\uc2dc\uc2a4\ud15c \ud504\ub86c\ud504\ud2b8 \uc124\uc815","text":"<pre><code># \uc2dc\uc2a4\ud15c \ud504\ub86c\ud504\ud2b8\ub85c \ud398\ub974\uc18c\ub098 \uc124\uc815\nllm = LLM.create(\n    \"gpt-4o-mini\",\n    system_prompt=\"\ub2f9\uc2e0\uc740 \uce5c\uc808\ud55c \uad50\uc721 \uc804\ubb38\uac00\uc785\ub2c8\ub2e4. \uc27d\uace0 \uba85\ud655\ud558\uac8c \uc124\uba85\ud574\uc8fc\uc138\uc694.\"\n)\n\nreply = llm.ask(\"\uc7ac\uadc0 \ud568\uc218\ub780 \ubb34\uc5c7\uc778\uac00\uc694?\")\nprint(reply.text)\n</code></pre>"},{"location":"guides/basic-usage/#_7","title":"\uc120\ud0dd\uc9c0\uc5d0\uc11c \uace0\ub974\uae30","text":""},{"location":"guides/basic-usage/#_8","title":"\ub2e8\uc21c \uc120\ud0dd","text":"<pre><code># \uac10\uc815 \ubd84\uc11d\nreply = llm.ask(\n    \"\ub2e4\uc74c \ub9ac\ubdf0\uc758 \uac10\uc815\uc744 \ubd84\uc11d\ud574\uc8fc\uc138\uc694: '\uc774 \uc81c\ud488 \uc815\ub9d0 \ucd5c\uace0\uc608\uc694!'\",\n    choices=[\"\uae0d\uc815\", \"\ubd80\uc815\", \"\uc911\ub9bd\"]\n)\n\nprint(f\"\uac10\uc815: {reply.choice}\")\nprint(f\"\ud655\uc2e0\ub3c4: {reply.confidence:.2%}\")\n</code></pre>"},{"location":"guides/basic-usage/#_9","title":"\ub2e4\uc911 \uc120\ud0dd \ubd84\ub958","text":"<pre><code># \uce74\ud14c\uace0\ub9ac \ubd84\ub958\ncategories = [\"\uae30\uc220\", \"\uc2a4\ud3ec\uce20\", \"\uc815\uce58\", \"\uacbd\uc81c\", \"\ubb38\ud654\", \"\uacfc\ud559\"]\n\nreply = llm.ask(\n    \"\ub2e4\uc74c \ub274\uc2a4\uc758 \uce74\ud14c\uace0\ub9ac\ub97c \uc120\ud0dd\ud558\uc138\uc694: 'OpenAI\uac00 \uc0c8\ub85c\uc6b4 GPT-5 \ubaa8\ub378\uc744 \ubc1c\ud45c\ud588\uc2b5\ub2c8\ub2e4.'\",\n    choices=categories\n)\n\nprint(f\"\uce74\ud14c\uace0\ub9ac: {reply.choice}\")\n</code></pre>"},{"location":"guides/basic-usage/#_10","title":"\uad6c\uc870\ud654\ub41c \ucd9c\ub825","text":""},{"location":"guides/basic-usage/#pydantic","title":"Pydantic \ubaa8\ub378 \uc0ac\uc6a9","text":"<pre><code>from pydantic import BaseModel\nfrom typing import List\n\nclass ProductInfo(BaseModel):\n    name: str\n    price: float\n    features: List[str]\n    in_stock: bool\n\n# \uad6c\uc870\ud654\ub41c \ub370\uc774\ud130 \uc694\uccad\nreply = llm.ask(\n    \"\uc544\uc774\ud3f0 15 Pro\uc5d0 \ub300\ud55c \uc81c\ud488 \uc815\ubcf4\ub97c \uc54c\ub824\uc8fc\uc138\uc694\",\n    schema=ProductInfo\n)\n\nproduct = reply.structured_data\nprint(f\"\uc81c\ud488\uba85: {product.name}\")\nprint(f\"\uac00\uaca9: ${product.price:,.0f}\")\nprint(f\"\uc8fc\uc694 \uae30\ub2a5: {', '.join(product.features)}\")\nprint(f\"\uc7ac\uace0: {'\uc788\uc74c' if product.in_stock else '\uc5c6\uc74c'}\")\n</code></pre>"},{"location":"guides/basic-usage/#_11","title":"\ubcf5\uc7a1\ud55c \uc2a4\ud0a4\ub9c8","text":"<pre><code>from datetime import datetime\nfrom enum import Enum\n\nclass Priority(str, Enum):\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n\nclass Task(BaseModel):\n    title: str\n    description: str\n    priority: Priority\n    due_date: datetime\n    tags: List[str]\n    estimated_hours: float\n\nreply = llm.ask(\n    \"\ub2e4\uc74c \ud504\ub85c\uc81d\ud2b8\ub97c \uc704\ud55c \uc791\uc5c5\uc744 \uc0dd\uc131\ud574\uc8fc\uc138\uc694: AI \ucc57\ubd07 \uac1c\ubc1c\",\n    schema=Task\n)\n\ntask = reply.structured_data\nprint(f\"\uc791\uc5c5: {task.title}\")\nprint(f\"\uc6b0\uc120\uc21c\uc704: {task.priority.value}\")\nprint(f\"\ub9c8\uac10\uc77c: {task.due_date.strftime('%Y-%m-%d')}\")\n</code></pre>"},{"location":"guides/basic-usage/#_12","title":"\uc2a4\ud2b8\ub9ac\ubc0d \uc751\ub2f5","text":""},{"location":"guides/basic-usage/#_13","title":"\uc2e4\uc2dc\uac04 \ucd9c\ub825","text":"<pre><code># \uc2a4\ud2b8\ub9ac\ubc0d\uc73c\ub85c \uae34 \uc751\ub2f5 \ubc1b\uae30\nprint(\"AI \ub2f5\ubcc0: \", end=\"\")\nfor chunk in llm.ask(\"\uba38\uc2e0\ub7ec\ub2dd\uc758 \uc5ed\uc0ac\ub97c \uc790\uc138\ud788 \uc124\uba85\ud574\uc8fc\uc138\uc694\", stream=True):\n    print(chunk.text, end=\"\", flush=True)\nprint()  # \uc904\ubc14\uafc8\n</code></pre>"},{"location":"guides/basic-usage/#_14","title":"\uc2a4\ud2b8\ub9ac\ubc0d \uc911 \ucc98\ub9ac","text":"<pre><code># \ub2e8\uc5b4 \uc218 \uacc4\uc0b0\ud558\uba70 \uc2a4\ud2b8\ub9ac\ubc0d\ntotal_words = 0\nfor chunk in llm.ask(\"\ud30c\uc774\uc36c\uc758 \ud65c\uc6a9 \ubd84\uc57c\ub97c \uc124\uba85\ud574\uc8fc\uc138\uc694\", stream=True):\n    print(chunk.text, end=\"\", flush=True)\n    total_words += len(chunk.text.split())\n\nprint(f\"\\n\\n\ucd1d \ub2e8\uc5b4 \uc218: {total_words}\")\n</code></pre>"},{"location":"guides/basic-usage/#_15","title":"\uc774\ubbf8\uc9c0\uc640 \ud568\uaed8 \uc9c8\ubb38\ud558\uae30","text":""},{"location":"guides/basic-usage/#_16","title":"\ub2e8\uc77c \uc774\ubbf8\uc9c0 \ubd84\uc11d","text":"<pre><code># \uc774\ubbf8\uc9c0 \uc124\uba85\nreply = llm.ask(\n    \"\uc774 \uc774\ubbf8\uc9c0\uc5d0 \ubb34\uc5c7\uc774 \uc788\ub098\uc694?\",\n    files=[\"photo.jpg\"]\n)\nprint(reply.text)\n\n# \uc774\ubbf8\uc9c0 \uae30\ubc18 \uc9c8\ubb38\nreply = llm.ask(\n    \"\uc774 \ucc28\ud2b8\uc5d0\uc11c \uac00\uc7a5 \ub192\uc740 \uac12\uc740 \uc5bc\ub9c8\uc778\uac00\uc694?\",\n    files=[\"chart.png\"]\n)\n</code></pre>"},{"location":"guides/basic-usage/#_17","title":"\uc5ec\ub7ec \uc774\ubbf8\uc9c0 \ube44\uad50","text":"<pre><code># \uc774\ubbf8\uc9c0 \ube44\uad50\nreply = llm.ask(\n    \"\uc774 \ub450 \uc774\ubbf8\uc9c0\uc758 \ucc28\uc774\uc810\uc744 \ucc3e\uc544\uc8fc\uc138\uc694\",\n    files=[\"before.jpg\", \"after.jpg\"]\n)\n\n# \uc774\ubbf8\uc9c0 \uc2dc\ud000\uc2a4 \ubd84\uc11d\nreply = llm.ask(\n    \"\uc774 \uc774\ubbf8\uc9c0\ub4e4\uc774 \ubcf4\uc5ec\uc8fc\ub294 \uacfc\uc815\uc744 \uc124\uba85\ud574\uc8fc\uc138\uc694\",\n    files=[\"step1.png\", \"step2.png\", \"step3.png\"]\n)\n</code></pre>"},{"location":"guides/basic-usage/#_18","title":"\ud15c\ud50c\ub9bf \uc0ac\uc6a9","text":""},{"location":"guides/basic-usage/#jinja2","title":"Jinja2 \ud15c\ud50c\ub9bf","text":"<pre><code>from pyhub.llm.templates import PromptTemplate\n\n# \ud15c\ud50c\ub9bf \uc815\uc758\ntemplate = PromptTemplate(\"\"\"\n\ub2e4\uc74c \uc81c\ud488\uc5d0 \ub300\ud55c \ub9c8\ucf00\ud305 \ubb38\uad6c\ub97c \uc791\uc131\ud574\uc8fc\uc138\uc694:\n\n\uc81c\ud488\uba85: {{ product_name }}\n\ud2b9\uc9d5: {{ features | join(\", \") }}\n\ud0c0\uac9f: {{ target_audience }}\n\n\ud1a4: {{ tone }}\n\"\"\")\n\n# \ud15c\ud50c\ub9bf \uc0ac\uc6a9\nprompt = template.render(\n    product_name=\"\uc2a4\ub9c8\ud2b8 \uc6cc\uce58 Pro\",\n    features=[\"\uc2ec\ubc15\uc218 \uce21\uc815\", \"GPS\", \"\ubc29\uc218\"],\n    target_audience=\"\uc6b4\ub3d9\uc744 \uc88b\uc544\ud558\ub294 20-30\ub300\",\n    tone=\"\ud65c\uae30\ucc28\uace0 \ub3d9\uae30\ubd80\uc5ec\uac00 \ub418\ub294\"\n)\n\nreply = llm.ask(prompt)\nprint(reply.text)\n</code></pre>"},{"location":"guides/basic-usage/#_19","title":"\uc7ac\uc0ac\uc6a9 \uac00\ub2a5\ud55c \ud15c\ud50c\ub9bf","text":"<pre><code># \ubc88\uc5ed \ud15c\ud50c\ub9bf\ntranslate_template = PromptTemplate(\n    \"\ub2e4\uc74c {{ source_lang }} \ubb38\uc7a5\uc744 {{ target_lang }}\ub85c \ubc88\uc5ed\ud574\uc8fc\uc138\uc694:\\n\\n{{ text }}\"\n)\n\n# \uc5ec\ub7ec \ubc88\uc5ed\uc5d0 \uc7ac\uc0ac\uc6a9\ntexts = [\"Hello, world!\", \"How are you?\", \"Nice to meet you.\"]\n\nfor text in texts:\n    prompt = translate_template.render(\n        source_lang=\"\uc601\uc5b4\",\n        target_lang=\"\ud55c\uad6d\uc5b4\",\n        text=text\n    )\n    reply = llm.ask(prompt)\n    print(f\"{text} \u2192 {reply.text}\")\n</code></pre>"},{"location":"guides/basic-usage/#_20","title":"\uc5d0\ub7ec \ucc98\ub9ac","text":""},{"location":"guides/basic-usage/#_21","title":"\uae30\ubcf8 \uc5d0\ub7ec \ucc98\ub9ac","text":"<pre><code>from pyhub.llm.exceptions import LLMError, RateLimitError, AuthenticationError\n\ntry:\n    reply = llm.ask(\"\uc9c8\ubb38\")\nexcept AuthenticationError:\n    print(\"API \ud0a4\uac00 \uc720\ud6a8\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4\")\nexcept RateLimitError:\n    print(\"API \ud638\ucd9c \ud55c\ub3c4\ub97c \ucd08\uacfc\ud588\uc2b5\ub2c8\ub2e4\")\nexcept LLMError as e:\n    print(f\"LLM \uc624\ub958 \ubc1c\uc0dd: {e}\")\n</code></pre>"},{"location":"guides/basic-usage/#_22","title":"\uc7ac\uc2dc\ub3c4 \ub85c\uc9c1","text":"<pre><code>import time\n\ndef ask_with_retry(llm, prompt, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            return llm.ask(prompt)\n        except RateLimitError:\n            if attempt &lt; max_retries - 1:\n                wait_time = 2 ** attempt  # \uc9c0\uc218 \ubc31\uc624\ud504\n                print(f\"\uc7ac\uc2dc\ub3c4 \uc911... {wait_time}\ucd08 \ub300\uae30\")\n                time.sleep(wait_time)\n            else:\n                raise\n\n# \uc0ac\uc6a9\nreply = ask_with_retry(llm, \"\ubcf5\uc7a1\ud55c \uc9c8\ubb38...\")\n</code></pre>"},{"location":"guides/basic-usage/#_23","title":"\uc124\uc815 \uad00\ub9ac","text":""},{"location":"guides/basic-usage/#_24","title":"\ud658\uacbd\ubcc4 \uc124\uc815","text":"<pre><code>from pyhub.llm.settings import Settings\n\n# \uac1c\ubc1c \ud658\uacbd\ndev_settings = Settings(\n    openai_api_key=\"dev-key\",\n    log_level=\"DEBUG\",\n    cache_enabled=False\n)\n\n# \ud504\ub85c\ub355\uc158 \ud658\uacbd\nprod_settings = Settings.from_env()  # \ud658\uacbd \ubcc0\uc218\uc5d0\uc11c \ub85c\ub4dc\n\n# \uc124\uc815 \uc801\uc6a9\nllm = LLM.create(\"gpt-4o-mini\", settings=prod_settings)\n</code></pre>"},{"location":"guides/basic-usage/#_25","title":"\ub3d9\uc801 \uc124\uc815 \ubcc0\uacbd","text":"<pre><code># \uc628\ub3c4 \uc870\uc808\ncreative_llm = LLM.create(\"gpt-4o-mini\", temperature=0.9)  # \ucc3d\uc758\uc801\nprecise_llm = LLM.create(\"gpt-4o-mini\", temperature=0.1)   # \uc815\ud655\ud55c\n\n# \ud1a0\ud070 \uc81c\ud55c\nshort_llm = LLM.create(\"gpt-4o-mini\", max_tokens=50)   # \uc9e7\uc740 \ub2f5\ubcc0\nlong_llm = LLM.create(\"gpt-4o-mini\", max_tokens=2000)  # \uae34 \ub2f5\ubcc0\n</code></pre>"},{"location":"guides/basic-usage/#_26","title":"\ubaa8\ubc94 \uc0ac\ub840","text":""},{"location":"guides/basic-usage/#1","title":"1. \uba85\ud655\ud55c \ud504\ub86c\ud504\ud2b8 \uc791\uc131","text":"<pre><code># \u274c \ubaa8\ud638\ud55c \ud504\ub86c\ud504\ud2b8\nreply = llm.ask(\"\ud30c\uc774\uc36c\")\n\n# \u2705 \uba85\ud655\ud55c \ud504\ub86c\ud504\ud2b8\nreply = llm.ask(\"\ud30c\uc774\uc36c \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\uc758 \uc8fc\uc694 \ud2b9\uc9d5 5\uac00\uc9c0\ub97c \uc124\uba85\ud574\uc8fc\uc138\uc694\")\n</code></pre>"},{"location":"guides/basic-usage/#2","title":"2. \uc801\uc808\ud55c \ubaa8\ub378 \uc120\ud0dd","text":"<pre><code># \uac04\ub2e8\ud55c \uc791\uc5c5: \ube60\ub974\uace0 \uc800\ub834\ud55c \ubaa8\ub378\nsimple_llm = LLM.create(\"gpt-4o-mini\")\n\n# \ubcf5\uc7a1\ud55c \uc791\uc5c5: \uace0\uc131\ub2a5 \ubaa8\ub378\ncomplex_llm = LLM.create(\"gpt-4o\")\n\n# \ucf54\ub4dc \uc0dd\uc131: \ucf54\ub4dc \ud2b9\ud654 \ubaa8\ub378\ncode_llm = LLM.create(\"gpt-4-turbo\")\n</code></pre>"},{"location":"guides/basic-usage/#3","title":"3. \ube44\uc6a9 \ucd5c\uc801\ud654","text":"<pre><code># Stateless \ubaa8\ub4dc\ub85c \ubd88\ud544\uc694\ud55c \ucee8\ud14d\uc2a4\ud2b8 \uc81c\uac70\nclassifier = LLM.create(\"gpt-4o-mini\", stateless=True)\n\n# \uce90\uc2f1 \ud65c\uc6a9\nfrom pyhub.llm.cache import FileCache\n\nllm = LLM.create(\"gpt-4o-mini\", cache=FileCache())\n</code></pre>"},{"location":"guides/basic-usage/#_27","title":"\ub2e4\uc74c \ub2e8\uacc4","text":"<ul> <li>\ub300\ud654 \uad00\ub9ac - \ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac\uc640 \ucee8\ud14d\uc2a4\ud2b8 \uad00\ub9ac</li> <li>\uad6c\uc870\ud654\ub41c \ucd9c\ub825 - \ubcf5\uc7a1\ud55c \ub370\uc774\ud130 \uad6c\uc870 \ucc98\ub9ac</li> <li>\uace0\uae09 \uae30\ub2a5 - \uc131\ub2a5 \ucd5c\uc801\ud654\uc640 \uace0\uae09 \ud328\ud134</li> </ul>"},{"location":"guides/conversation/","title":"\ub300\ud654 \uad00\ub9ac","text":"<p>pyhub-llm\uc758 \ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac \uad00\ub9ac\uc640 \ucee8\ud14d\uc2a4\ud2b8 \uc81c\uc5b4 \uae30\ub2a5\uc744 \uc54c\uc544\ubd05\ub2c8\ub2e4.</p>"},{"location":"guides/conversation/#_2","title":"\ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac \uc790\ub3d9 \uad00\ub9ac","text":""},{"location":"guides/conversation/#_3","title":"\uae30\ubcf8 \ub300\ud654 \uc774\uc5b4\uac00\uae30","text":"<p>pyhub-llm\uc740 \uc790\ub3d9\uc73c\ub85c \ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac\ub97c \uad00\ub9ac\ud569\ub2c8\ub2e4:</p> <pre><code>from pyhub.llm import LLM\n\nllm = LLM.create(\"gpt-4o-mini\")\n\n# \uccab \ubc88\uc9f8 \ub300\ud654\nllm.ask(\"\uc81c \uc774\ub984\uc740 \uae40\ucca0\uc218\uc785\ub2c8\ub2e4. \ud30c\uc774\uc36c\uc744 \ubc30\uc6b0\uace0 \uc788\uc5b4\uc694.\")\n\n# \uc774\uc804 \ub300\ud654\ub97c \uae30\uc5b5\ud558\uace0 \ub2f5\ubcc0\nreply = llm.ask(\"\uc81c\uac00 \ub204\uad6c\ub77c\uace0 \ud588\uc8e0?\")\nprint(reply.text)  # \"\uae40\ucca0\uc218\ub2d8\uc774\ub77c\uace0 \ud558\uc168\uc2b5\ub2c8\ub2e4.\"\n\nreply = llm.ask(\"\uc81c\uac00 \ubb34\uc5c7\uc744 \ubc30\uc6b0\uace0 \uc788\ub2e4\uace0 \ud588\ub098\uc694?\")\nprint(reply.text)  # \"\ud30c\uc774\uc36c\uc744 \ubc30\uc6b0\uace0 \uacc4\uc2dc\ub2e4\uace0 \ud558\uc168\uc2b5\ub2c8\ub2e4.\"\n</code></pre>"},{"location":"guides/conversation/#_4","title":"\ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac \ud655\uc778","text":"<pre><code># \uc804\uccb4 \ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac \ud655\uc778\nprint(f\"\ucd1d \uba54\uc2dc\uc9c0 \uc218: {len(llm.history)}\")\n\n# \ub300\ud654 \ub0b4\uc6a9 \ucd9c\ub825\nfor msg in llm.history:\n    role = msg[\"role\"]\n    content = msg[\"content\"][:50] + \"...\" if len(msg[\"content\"]) &gt; 50 else msg[\"content\"]\n    print(f\"{role}: {content}\")\n</code></pre>"},{"location":"guides/conversation/#_5","title":"\ub300\ud654 \ucd08\uae30\ud654","text":"<pre><code># \uc804\uccb4 \ub300\ud654 \ucd08\uae30\ud654\nllm.clear()\nprint(f\"\ub300\ud654 \ucd08\uae30\ud654 \ud6c4 \uba54\uc2dc\uc9c0 \uc218: {len(llm.history)}\")  # 0\n\n# \uc2dc\uc2a4\ud15c \ud504\ub86c\ud504\ud2b8\ub294 \uc720\uc9c0\ub428\nllm = LLM.create(\"gpt-4o-mini\", system_prompt=\"\ub2f9\uc2e0\uc740 \uce5c\uc808\ud55c \uc0c1\ub2f4\uc0ac\uc785\ub2c8\ub2e4.\")\nllm.ask(\"\uc548\ub155\ud558\uc138\uc694\")\nllm.clear()  # \uc2dc\uc2a4\ud15c \ud504\ub86c\ud504\ud2b8\ub294 \uc720\uc9c0, \ub300\ud654\ub9cc \ucd08\uae30\ud654\n</code></pre>"},{"location":"guides/conversation/#stateless","title":"Stateless \ubaa8\ub4dc","text":"<p>\ubc18\ubcf5\uc801\uc778 \ub3c5\ub9bd \uc791\uc5c5\uc5d0\ub294 Stateless \ubaa8\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc131\ub2a5\uc744 \ucd5c\uc801\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:</p>"},{"location":"guides/conversation/#_6","title":"\uae30\ubcf8 \uc0ac\uc6a9\ubc95","text":"<pre><code># Stateless \ubaa8\ub4dc - \ub300\ud654 \ud788\uc2a4\ud1a0\ub9ac \uc800\uc7a5 \uc548 \ud568\nstateless_llm = LLM.create(\"gpt-4o-mini\", stateless=True)\n\n# \uac01 \uc694\uccad\uc774 \ub3c5\ub9bd\uc801\uc73c\ub85c \ucc98\ub9ac\ub428\nstateless_llm.ask(\"\uc81c \uc774\ub984\uc740 \uae40\ucca0\uc218\uc785\ub2c8\ub2e4.\")\nreply = stateless_llm.ask(\"\uc81c \uc774\ub984\uc774 \ubb50\ub77c\uace0 \ud588\uc8e0?\")\nprint(reply.text)  # \uc774\uc804 \ub300\ud654\ub97c \uae30\uc5b5\ud558\uc9c0 \ubabb\ud568\n</code></pre>"},{"location":"guides/conversation/#_7","title":"\ub300\ub7c9 \ucc98\ub9ac\uc5d0 \uc801\ud569","text":"<pre><code># \uac10\uc815 \ubd84\uc11d\uae30 - \uac01 \ubd84\uc11d\uc774 \ub3c5\ub9bd\uc801\nanalyzer = LLM.create(\"gpt-4o-mini\", stateless=True)\n\nreviews = [\n    \"\uc774 \uc81c\ud488 \uc815\ub9d0 \uc88b\uc544\uc694! \uac15\ub825 \ucd94\ucc9c\ud569\ub2c8\ub2e4.\",\n    \"\ubc30\uc1a1\uc774 \ub108\ubb34 \ub2a6\uc5b4\uc11c \uc2e4\ub9dd\ud588\uc2b5\ub2c8\ub2e4.\",\n    \"\uac00\uaca9\ub300\ube44 \uad1c\ucc2e\uc740 \uac83 \uac19\uc544\uc694.\",\n    \"\ub2e4\uc2dc\ub294 \uad6c\ub9e4\ud558\uc9c0 \uc54a\uc744 \uac83 \uac19\uc2b5\ub2c8\ub2e4.\"\n]\n\n# \uac01 \ub9ac\ubdf0\ub97c \ub3c5\ub9bd\uc801\uc73c\ub85c \ubd84\uc11d\nfor review in reviews:\n    reply = analyzer.ask(\n        f\"\ub2e4\uc74c \ub9ac\ubdf0\uc758 \uac10\uc815\uc744 \ubd84\uc11d\ud558\uc138\uc694: '{review}'\",\n        choices=[\"\uae0d\uc815\", \"\ubd80\uc815\", \"\uc911\ub9bd\"]\n    )\n    print(f\"{review[:20]}... \u2192 {reply.choice}\")\n</code></pre>"},{"location":"guides/conversation/#stateless-vs","title":"Stateless vs \uc77c\ubc18 \ubaa8\ub4dc \ube44\uad50","text":"<pre><code>import time\n\n# \uc131\ub2a5 \ube44\uad50\ntexts = [\"\ud14d\uc2a4\ud2b8 \" + str(i) for i in range(100)]\n\n# \uc77c\ubc18 \ubaa8\ub4dc (\ud788\uc2a4\ud1a0\ub9ac \ub204\uc801)\nnormal_llm = LLM.create(\"gpt-4o-mini\")\nstart = time.time()\nfor text in texts[:10]:  # \ucc98\uc74c 10\uac1c\ub9cc\n    normal_llm.ask(f\"\ub2e4\uc74c\uc744 \uc694\uc57d\ud558\uc138\uc694: {text}\")\nnormal_time = time.time() - start\n\n# Stateless \ubaa8\ub4dc (\ud788\uc2a4\ud1a0\ub9ac \uc5c6\uc74c)\nstateless_llm = LLM.create(\"gpt-4o-mini\", stateless=True)\nstart = time.time()\nfor text in texts[:10]:  # \ucc98\uc74c 10\uac1c\ub9cc\n    stateless_llm.ask(f\"\ub2e4\uc74c\uc744 \uc694\uc57d\ud558\uc138\uc694: {text}\")\nstateless_time = time.time() - start\n\nprint(f\"\uc77c\ubc18 \ubaa8\ub4dc: {normal_time:.2f}\ucd08\")\nprint(f\"Stateless \ubaa8\ub4dc: {stateless_time:.2f}\ucd08\")\nprint(f\"\uc131\ub2a5 \ud5a5\uc0c1: {(normal_time - stateless_time) / normal_time * 100:.1f}%\")\n</code></pre>"},{"location":"guides/conversation/#_8","title":"\ucee8\ud14d\uc2a4\ud2b8 \uad00\ub9ac","text":""},{"location":"guides/conversation/#_9","title":"\uc218\ub3d9 \ud788\uc2a4\ud1a0\ub9ac \uc81c\uc5b4","text":"<pre><code># \ud2b9\uc815 \uc2dc\uc810\uc758 \ub300\ud654\ub9cc \uc0ac\uc6a9\nllm = LLM.create(\"gpt-4o-mini\")\n\n# \uc5ec\ub7ec \ub300\ud654 \uc9c4\ud589\nllm.ask(\"\ud30c\uc774\uc36c\uc5d0 \ub300\ud574 \uc54c\ub824\uc8fc\uc138\uc694\")\nllm.ask(\"\uc7a5\uc810\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\")\ncheckpoint = len(llm.history)  # \uccb4\ud06c\ud3ec\uc778\ud2b8 \uc800\uc7a5\n\nllm.ask(\"\uc790\ubc14\uc2a4\ud06c\ub9bd\ud2b8\ub294 \uc5b4\ub5a4\uac00\uc694?\")\nllm.ask(\"\ucc28\uc774\uc810\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\")\n\n# \uccb4\ud06c\ud3ec\uc778\ud2b8\ub85c \ub864\ubc31\nllm.history = llm.history[:checkpoint]\nreply = llm.ask(\"\ub2e8\uc810\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\")  # \ud30c\uc774\uc36c\uc758 \ub2e8\uc810\uc744 \ubb3c\uc5b4\ubd04\n</code></pre>"},{"location":"guides/conversation/#_10","title":"\ucee8\ud14d\uc2a4\ud2b8 \uc708\ub3c4\uc6b0 \uad00\ub9ac","text":"<pre><code>class ContextWindowManager:\n    def __init__(self, llm, max_messages=10):\n        self.llm = llm\n        self.max_messages = max_messages\n\n    def ask(self, prompt, **kwargs):\n        # \ucd5c\ub300 \uba54\uc2dc\uc9c0 \uc218 \uc720\uc9c0\n        if len(self.llm.history) &gt; self.max_messages:\n            # \uc2dc\uc2a4\ud15c \uba54\uc2dc\uc9c0 + \ucd5c\uadfc \uba54\uc2dc\uc9c0\ub9cc \uc720\uc9c0\n            system_msgs = [m for m in self.llm.history if m[\"role\"] == \"system\"]\n            recent_msgs = self.llm.history[-(self.max_messages - len(system_msgs)):]\n            self.llm.history = system_msgs + recent_msgs\n\n        return self.llm.ask(prompt, **kwargs)\n\n# \uc0ac\uc6a9\nllm = LLM.create(\"gpt-4o-mini\")\nmanager = ContextWindowManager(llm, max_messages=6)\n\n# \uae34 \ub300\ud654\ub97c \ud574\ub3c4 \ucd5c\uadfc 6\uac1c \uba54\uc2dc\uc9c0\ub9cc \uc720\uc9c0\nfor i in range(20):\n    manager.ask(f\"\uc9c8\ubb38 {i+1}\")\n    print(f\"\ud604\uc7ac \ud788\uc2a4\ud1a0\ub9ac \ud06c\uae30: {len(llm.history)}\")\n</code></pre>"},{"location":"guides/conversation/#_11","title":"\ub300\ud654 \uc800\uc7a5\uacfc \ubcf5\uc6d0","text":""},{"location":"guides/conversation/#json","title":"JSON\uc73c\ub85c \uc800\uc7a5/\ub85c\ub4dc","text":"<pre><code>import json\n\ndef save_conversation(llm, filename):\n    \"\"\"\ub300\ud654\ub97c JSON \ud30c\uc77c\ub85c \uc800\uc7a5\"\"\"\n    with open(filename, 'w', encoding='utf-8') as f:\n        json.dump({\n            'model': llm.model,\n            'history': llm.history,\n            'timestamp': time.time()\n        }, f, ensure_ascii=False, indent=2)\n\ndef load_conversation(filename, model=None):\n    \"\"\"JSON \ud30c\uc77c\uc5d0\uc11c \ub300\ud654 \ub85c\ub4dc\"\"\"\n    with open(filename, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n\n    llm = LLM.create(model or data['model'])\n    llm.history = data['history']\n    return llm\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nllm = LLM.create(\"gpt-4o-mini\")\nllm.ask(\"\uc548\ub155\ud558\uc138\uc694\")\nllm.ask(\"\ud30c\uc774\uc36c\uc5d0 \ub300\ud574 \uc54c\ub824\uc8fc\uc138\uc694\")\n\n# \uc800\uc7a5\nsave_conversation(llm, \"conversation.json\")\n\n# \ub098\uc911\uc5d0 \ub85c\ub4dc\nrestored_llm = load_conversation(\"conversation.json\")\nreply = restored_llm.ask(\"\ubc29\uae08 \ubb34\uc5c7\uc5d0 \ub300\ud574 \uc598\uae30\ud588\ub098\uc694?\")\nprint(reply.text)  # \ud30c\uc774\uc36c\uc5d0 \ub300\ud55c \ub300\ud654\ub97c \uae30\uc5b5\n</code></pre>"},{"location":"guides/conversation/#_12","title":"\ub300\ud654 \uc694\uc57d \ubc0f \uc555\ucd95","text":"<pre><code>def summarize_conversation(llm, keep_recent=4):\n    \"\"\"\uae34 \ub300\ud654\ub97c \uc694\uc57d\ud558\uc5ec \uc555\ucd95\"\"\"\n    if len(llm.history) &lt;= keep_recent + 1:  # +1 for system prompt\n        return\n\n    # \uc694\uc57d\ud560 \uba54\uc2dc\uc9c0\ub4e4\n    to_summarize = llm.history[1:-keep_recent]  # \uc2dc\uc2a4\ud15c \uc81c\uc678, \ucd5c\uadfc \uc81c\uc678\n\n    # \uc694\uc57d \uc0dd\uc131\n    summary_prompt = \"\ub2e4\uc74c \ub300\ud654\ub97c \ud575\uc2ec\ub9cc \uac04\ub2e8\ud788 \uc694\uc57d\ud574\uc8fc\uc138\uc694:\\n\\n\"\n    for msg in to_summarize:\n        summary_prompt += f\"{msg['role']}: {msg['content']}\\n\"\n\n    # Stateless\ub85c \uc694\uc57d (\ud604\uc7ac \ub300\ud654\uc5d0 \uc601\ud5a5 \uc5c6\uc74c)\n    summarizer = LLM.create(llm.model, stateless=True)\n    summary = summarizer.ask(summary_prompt).text\n\n    # \ud788\uc2a4\ud1a0\ub9ac \uc7ac\uad6c\uc131\n    system_msgs = [m for m in llm.history if m[\"role\"] == \"system\"]\n    summary_msg = {\"role\": \"assistant\", \"content\": f\"[\uc774\uc804 \ub300\ud654 \uc694\uc57d]\\n{summary}\"}\n    recent_msgs = llm.history[-keep_recent:]\n\n    llm.history = system_msgs + [summary_msg] + recent_msgs\n\n# \uc0ac\uc6a9\nllm = LLM.create(\"gpt-4o-mini\")\n\n# \uae34 \ub300\ud654 \uc2dc\ubbac\ub808\uc774\uc158\nfor i in range(20):\n    llm.ask(f\"\uc9c8\ubb38 {i+1}\uc5d0 \ub300\ud574 \uc124\uba85\ud574\uc8fc\uc138\uc694\")\n\nprint(f\"\uc555\ucd95 \uc804 \uba54\uc2dc\uc9c0 \uc218: {len(llm.history)}\")\nsummarize_conversation(llm)\nprint(f\"\uc555\ucd95 \ud6c4 \uba54\uc2dc\uc9c0 \uc218: {len(llm.history)}\")\n</code></pre>"},{"location":"guides/conversation/#_13","title":"\uba40\ud2f0\ud134 \ub300\ud654 \ud328\ud134","text":""},{"location":"guides/conversation/#_14","title":"\ub2e8\uacc4\ubcc4 \uc815\ubcf4 \uc218\uc9d1","text":"<pre><code>def collect_user_info(llm):\n    \"\"\"\ub300\ud654\ud615\uc73c\ub85c \uc0ac\uc6a9\uc790 \uc815\ubcf4 \uc218\uc9d1\"\"\"\n    info = {}\n\n    # \uc774\ub984\n    reply = llm.ask(\"\uc548\ub155\ud558\uc138\uc694! \uc131\ud568\uc774 \uc5b4\ub5bb\uac8c \ub418\uc2dc\ub098\uc694?\")\n    info['name'] = llm.ask(\"\uac10\uc0ac\ud569\ub2c8\ub2e4. \uc131\ud568\uc744 \ub2e4\uc2dc \ud55c \ubc88 \ub9d0\uc500\ud574 \uc8fc\uc2dc\uaca0\uc5b4\uc694?\").text\n\n    # \uad00\uc2ec\uc0ac\n    llm.ask(\"\uc5b4\ub5a4 \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\uc5d0 \uad00\uc2ec\uc774 \uc788\uc73c\uc2e0\uac00\uc694?\")\n    interests = llm.ask(\n        \"\uad00\uc2ec\uc788\ub294 \uc5b8\uc5b4\ub97c \ud558\ub098 \uc120\ud0dd\ud574\uc8fc\uc138\uc694\",\n        choices=[\"Python\", \"JavaScript\", \"Java\", \"Go\", \"Rust\"]\n    ).choice\n    info['interest'] = interests\n\n    # \uacbd\ud5d8\n    experience = llm.ask(\n        f\"{interests}\ub97c \uc5bc\ub9c8\ub098 \uc0ac\uc6a9\ud574\ubcf4\uc168\ub098\uc694?\",\n        choices=[\"\ucc98\uc74c\", \"1\ub144 \ubbf8\ub9cc\", \"1-3\ub144\", \"3\ub144 \uc774\uc0c1\"]\n    ).choice\n    info['experience'] = experience\n\n    # \uc694\uc57d\n    summary = llm.ask(\n        f\"\uc81c\uac00 \uc774\ud574\ud55c \ubc14\ub85c\ub294 {info['name']}\ub2d8\uc740 {interests}\uc5d0 \uad00\uc2ec\uc774 \uc788\uace0 \"\n        f\"{experience}\uc758 \uacbd\ud5d8\uc774 \uc788\uc73c\uc2dc\uad70\uc694. \ub9de\ub098\uc694?\"\n    )\n\n    return info\n\n# \uc0ac\uc6a9\nllm = LLM.create(\"gpt-4o-mini\", \n    system_prompt=\"\ub2f9\uc2e0\uc740 \uce5c\uc808\ud55c \ud504\ub85c\uadf8\ub798\ubc0d \uad50\uc721 \uc0c1\ub2f4\uc0ac\uc785\ub2c8\ub2e4.\"\n)\nuser_info = collect_user_info(llm)\nprint(user_info)\n</code></pre>"},{"location":"guides/conversation/#_15","title":"\ucee8\ud14d\uc2a4\ud2b8 \uae30\ubc18 \ucd94\ucc9c","text":"<pre><code>class ContextualRecommender:\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.llm = LLM.create(model)\n        self.preferences = []\n\n    def add_preference(self, item, liked: bool):\n        \"\"\"\uc0ac\uc6a9\uc790 \uc120\ud638\ub3c4 \ucd94\uac00\"\"\"\n        action = \"\uc88b\uc544\ud55c\ub2e4\" if liked else \"\uc2eb\uc5b4\ud55c\ub2e4\"\n        self.llm.ask(f\"\uc0ac\uc6a9\uc790\uac00 {item}\uc744/\ub97c {action}\uace0 \ud588\uc2b5\ub2c8\ub2e4.\")\n        self.preferences.append((item, liked))\n\n    def get_recommendation(self):\n        \"\"\"\ucee8\ud14d\uc2a4\ud2b8 \uae30\ubc18 \ucd94\ucc9c\"\"\"\n        if not self.preferences:\n            return \"\uc120\ud638\ub3c4 \uc815\ubcf4\uac00 \uc5c6\uc2b5\ub2c8\ub2e4.\"\n\n        return self.llm.ask(\n            \"\uc9c0\uae08\uae4c\uc9c0\uc758 \uc120\ud638\ub3c4\ub97c \ubc14\ud0d5\uc73c\ub85c \uc0ac\uc6a9\uc790\uac00 \uc88b\uc544\ud560 \ub9cc\ud55c \uac83\uc744 \ucd94\ucc9c\ud574\uc8fc\uc138\uc694.\"\n        ).text\n\n    def explain_recommendation(self):\n        \"\"\"\ucd94\ucc9c \uc774\uc720 \uc124\uba85\"\"\"\n        return self.llm.ask(\n            \"\uc65c \uadf8\uac83\uc744 \ucd94\ucc9c\ud588\ub294\uc9c0 \uc774\uc720\ub97c \uc124\uba85\ud574\uc8fc\uc138\uc694.\"\n        ).text\n\n# \uc0ac\uc6a9\nrecommender = ContextualRecommender()\n\n# \uc120\ud638\ub3c4 \uc785\ub825\nrecommender.add_preference(\"\ud30c\uc774\uc36c\", True)\nrecommender.add_preference(\"\ubcf5\uc7a1\ud55c \ubb38\ubc95\", False)\nrecommender.add_preference(\"\ub370\uc774\ud130 \ubd84\uc11d\", True)\nrecommender.add_preference(\"\uc6f9 \uac1c\ubc1c\", True)\n\n# \ucd94\ucc9c \ubc1b\uae30\nrecommendation = recommender.get_recommendation()\nprint(f\"\ucd94\ucc9c: {recommendation}\")\n\nexplanation = recommender.explain_recommendation()\nprint(f\"\uc774\uc720: {explanation}\")\n</code></pre>"},{"location":"guides/conversation/#_16","title":"\ub300\ud654 \ubd84\uae30 \ucc98\ub9ac","text":""},{"location":"guides/conversation/#_17","title":"\uc870\uac74\ubd80 \ub300\ud654 \ud750\ub984","text":"<pre><code>class ConversationFlow:\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.llm = LLM.create(model)\n        self.state = \"start\"\n\n    def handle_conversation(self, user_input=None):\n        if self.state == \"start\":\n            reply = self.llm.ask(\n                \"\ud504\ub85c\uadf8\ub798\ubc0d \ud559\uc2b5\uc5d0 \ub300\ud574 \uad81\uae08\ud55c \uc810\uc774 \uc788\ub098\uc694?\",\n                choices=[\"\uc5b8\uc5b4 \uc120\ud0dd\", \"\ud559\uc2b5 \ubc29\ubc95\", \"\ud504\ub85c\uc81d\ud2b8 \uc544\uc774\ub514\uc5b4\", \"\uae30\ud0c0\"]\n            )\n\n            if reply.choice == \"\uc5b8\uc5b4 \uc120\ud0dd\":\n                self.state = \"language_selection\"\n            elif reply.choice == \"\ud559\uc2b5 \ubc29\ubc95\":\n                self.state = \"learning_method\"\n            elif reply.choice == \"\ud504\ub85c\uc81d\ud2b8 \uc544\uc774\ub514\uc5b4\":\n                self.state = \"project_ideas\"\n            else:\n                self.state = \"other\"\n\n            return self.handle_conversation()\n\n        elif self.state == \"language_selection\":\n            level = self.llm.ask(\n                \"\ud504\ub85c\uadf8\ub798\ubc0d \uacbd\ud5d8\uc774 \uc5b4\ub290 \uc815\ub3c4 \ub418\uc2dc\ub098\uc694?\",\n                choices=[\"\uc644\uc804 \ucd08\ubcf4\", \"\uae30\ucd08 \uc218\uc900\", \"\uc911\uae09\", \"\uace0\uae09\"]\n            ).choice\n\n            if level in [\"\uc644\uc804 \ucd08\ubcf4\", \"\uae30\ucd08 \uc218\uc900\"]:\n                return self.llm.ask(\n                    \"\ucd08\ubcf4\uc790\uc5d0\uac8c\ub294 Python\uc774\ub098 JavaScript\ub97c \ucd94\ucc9c\ud569\ub2c8\ub2e4. \"\n                    \"\uc5b4\ub5a4 \ubd84\uc57c\uc5d0 \uad00\uc2ec\uc774 \uc788\uc73c\uc2e0\uac00\uc694?\"\n                ).text\n            else:\n                return self.llm.ask(\n                    \"\uacbd\ud5d8\uc774 \uc788\uc73c\uc2dc\uad70\uc694! \uc5b4\ub5a4 \ubd84\uc57c\uc758 \uc5b8\uc5b4\ub97c \ucc3e\uace0 \uacc4\uc2e0\uac00\uc694?\"\n                ).text\n\n        # ... \ub2e4\ub978 \uc0c1\ud0dc\ub4e4 \ucc98\ub9ac\n\n# \uc0ac\uc6a9\nflow = ConversationFlow()\nresponse = flow.handle_conversation()\nprint(response)\n</code></pre>"},{"location":"guides/conversation/#_18","title":"\uc131\ub2a5 \ucd5c\uc801\ud654 \ud301","text":""},{"location":"guides/conversation/#1","title":"1. \uc801\uc808\ud55c \ubaa8\ub4dc \uc120\ud0dd","text":"<pre><code># \ub300\ud654\ud615 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\nchatbot = LLM.create(\"gpt-4o-mini\")  # \uae30\ubcf8 \ubaa8\ub4dc\n\n# \ub3c5\ub9bd\uc801 \uc791\uc5c5 \ucc98\ub9ac\nprocessor = LLM.create(\"gpt-4o-mini\", stateless=True)  # Stateless \ubaa8\ub4dc\n\n# \ud558\uc774\ube0c\ub9ac\ub4dc \uc811\uadfc\nclass HybridAssistant:\n    def __init__(self):\n        self.conversation_llm = LLM.create(\"gpt-4o-mini\")\n        self.utility_llm = LLM.create(\"gpt-4o-mini\", stateless=True)\n\n    def chat(self, message):\n        \"\"\"\ub300\ud654\ud615 \uc751\ub2f5\"\"\"\n        return self.conversation_llm.ask(message).text\n\n    def analyze(self, text):\n        \"\"\"\ub3c5\ub9bd\uc801 \ubd84\uc11d\"\"\"\n        return self.utility_llm.ask(f\"\ubd84\uc11d: {text}\").text\n</code></pre>"},{"location":"guides/conversation/#2","title":"2. \uba54\ubaa8\ub9ac \ud6a8\uc728\uc801 \uad00\ub9ac","text":"<pre><code># \uc8fc\uae30\uc801 \uc815\ub9ac\ndef cleanup_old_conversations(llm, max_age_messages=50):\n    if len(llm.history) &gt; max_age_messages:\n        # \uc624\ub798\ub41c \uba54\uc2dc\uc9c0 \uc81c\uac70\n        llm.history = llm.history[-max_age_messages:]\n\n# \uc911\uc694 \uc815\ubcf4\ub9cc \ubcf4\uc874\ndef preserve_important_only(llm):\n    important_keywords = [\"\uc774\ub984\", \"\ubaa9\ud45c\", \"\uc911\uc694\", \"\uae30\uc5b5\"]\n\n    preserved = []\n    for msg in llm.history:\n        if any(keyword in msg[\"content\"] for keyword in important_keywords):\n            preserved.append(msg)\n\n    # \uc2dc\uc2a4\ud15c \uba54\uc2dc\uc9c0 + \uc911\uc694 \uba54\uc2dc\uc9c0 + \ucd5c\uadfc \uba54\uc2dc\uc9c0\n    system_msgs = [m for m in llm.history if m[\"role\"] == \"system\"]\n    recent_msgs = llm.history[-4:]  # \ucd5c\uadfc 4\uac1c\n\n    llm.history = system_msgs + preserved + recent_msgs\n</code></pre>"},{"location":"guides/conversation/#_19","title":"\ub2e4\uc74c \ub2e8\uacc4","text":"<ul> <li>\ud504\ub85c\ubc14\uc774\ub354 - \uac01 LLM \ud504\ub85c\ubc14\uc774\ub354\uc758 \ud2b9\uc9d5</li> <li>\uad6c\uc870\ud654\ub41c \ucd9c\ub825 - \uc815\ud615\ud654\ub41c \ub370\uc774\ud130 \ucc98\ub9ac</li> <li>\uace0\uae09 \uae30\ub2a5 - \uc2a4\ud2b8\ub9ac\ubc0d, \ube44\ub3d9\uae30 \ub4f1 \uace0\uae09 \ud328\ud134</li> </ul>"},{"location":"guides/providers/","title":"\ud504\ub85c\ubc14\uc774\ub354 \uac00\uc774\ub4dc","text":"<p>pyhub-llm\uc774 \uc9c0\uc6d0\ud558\ub294 \uac01 LLM \ud504\ub85c\ubc14\uc774\ub354\uc758 \ud2b9\uc9d5\uacfc \uc0ac\uc6a9\ubc95\uc744 \uc54c\uc544\ubd05\ub2c8\ub2e4.</p>"},{"location":"guides/providers/#_2","title":"\uc9c0\uc6d0 \ud504\ub85c\ubc14\uc774\ub354 \uac1c\uc694","text":"\ud504\ub85c\ubc14\uc774\ub354 \uc8fc\uc694 \ubaa8\ub378 \ud2b9\uc9d5 \uac00\uaca9\ub300 OpenAI GPT-4o, GPT-4o-mini \uac00\uc7a5 \ub110\ub9ac \uc0ac\uc6a9, \uc548\uc815\uc801 \uc911-\uace0 Anthropic Claude 3.5 Sonnet/Haiku \uae34 \ucee8\ud14d\uc2a4\ud2b8, \uc548\uc804\uc131 \uc911-\uace0 Google Gemini 2.0 Flash \uba40\ud2f0\ubaa8\ub2ec, \ubb34\ub8cc \ud2f0\uc5b4 \uc800-\uc911 Ollama Llama, Mistral \ub4f1 \ub85c\uceec \uc2e4\ud589, \ubb34\ub8cc \ubb34\ub8cc Upstage Solar \ud55c\uad6d\uc5b4 \ud2b9\ud654 \uc800-\uc911"},{"location":"guides/providers/#openai","title":"OpenAI","text":""},{"location":"guides/providers/#_3","title":"\uc124\uc815 \ubc0f \ucd08\uae30\ud654","text":"<pre><code>from pyhub.llm import OpenAILLM, LLM\n\n# \uc790\ub3d9 \uac10\uc9c0\nllm = LLM.create(\"gpt-4o-mini\")\n\n# \uba85\uc2dc\uc801 \uc0dd\uc131\nopenai_llm = OpenAILLM(\n    model=\"gpt-4o-mini\",\n    api_key=\"your-api-key\",  # \ub610\ub294 \ud658\uacbd\ubcc0\uc218 OPENAI_API_KEY\n    temperature=0.7,\n    max_tokens=1000\n)\n</code></pre>"},{"location":"guides/providers/#_4","title":"\uc9c0\uc6d0 \ubaa8\ub378","text":"<pre><code># GPT-4o \uc2dc\ub9ac\uc988 (\ucd5c\uc2e0, \ube60\ub984)\nllm_4o = LLM.create(\"gpt-4o\")          # \uace0\uc131\ub2a5\nllm_4o_mini = LLM.create(\"gpt-4o-mini\") # \uacbd\uc81c\uc801\n\n# GPT-4 Turbo\nllm_4_turbo = LLM.create(\"gpt-4-turbo\") # 128k \ucee8\ud14d\uc2a4\ud2b8\n\n# GPT-3.5 (\ub808\uac70\uc2dc)\nllm_35 = LLM.create(\"gpt-3.5-turbo\")   # \uc800\ub834, \ube60\ub984\n</code></pre>"},{"location":"guides/providers/#openai_1","title":"OpenAI \ud2b9\ud654 \uae30\ub2a5","text":"<pre><code># \ud568\uc218 \ud638\ucd9c (Function Calling)\nfrom pydantic import BaseModel\n\nclass WeatherParams(BaseModel):\n    location: str\n    unit: str = \"celsius\"\n\ndef get_weather(params: WeatherParams):\n    # \uc2e4\uc81c \ub0a0\uc528 API \ud638\ucd9c\n    return f\"{params.location}\uc758 \ub0a0\uc528\ub294 \ub9d1\uc74c, 22{params.unit[0].upper()}\"\n\n# \ub3c4\uad6c \uc815\uc758\ntools = [{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"get_weather\",\n        \"parameters\": WeatherParams.model_json_schema()\n    }\n}]\n\n# \ub3c4\uad6c\uc640 \ud568\uaed8 \uc9c8\ubb38\nreply = openai_llm.ask_with_tools(\n    \"\uc11c\uc6b8 \ub0a0\uc528 \uc5b4\ub54c?\",\n    tools=tools\n)\n\n# JSON \ubaa8\ub4dc\nreply = openai_llm.ask(\n    \"\ub2e4\uc74c \uc815\ubcf4\ub97c JSON\uc73c\ub85c \uc815\ub9ac\ud558\uc138\uc694: \uc774\ub984-\uae40\ucca0\uc218, \ub098\uc774-30\",\n    response_format={\"type\": \"json_object\"}\n)\n</code></pre>"},{"location":"guides/providers/#dall-e","title":"\uc774\ubbf8\uc9c0 \uc0dd\uc131 (DALL-E)","text":"<pre><code># \uc774\ubbf8\uc9c0 \uc0dd\uc131 (\ubcc4\ub3c4 \uad6c\ud604 \ud544\uc694)\nfrom openai import OpenAI\n\nclient = OpenAI()\nresponse = client.images.generate(\n    model=\"dall-e-3\",\n    prompt=\"\uadc0\uc5ec\uc6b4 \uace0\uc591\uc774\uac00 \ub178\ud2b8\ubd81\uc73c\ub85c \ucf54\ub529\ud558\ub294 \ubaa8\uc2b5\",\n    size=\"1024x1024\",\n    quality=\"standard\",\n    n=1,\n)\nimage_url = response.data[0].url\n</code></pre>"},{"location":"guides/providers/#anthropic-claude","title":"Anthropic Claude","text":""},{"location":"guides/providers/#_5","title":"\uc124\uc815 \ubc0f \ucd08\uae30\ud654","text":"<pre><code>from pyhub.llm import AnthropicLLM\n\n# \uc790\ub3d9 \uac10\uc9c0\nllm = LLM.create(\"claude-3-5-sonnet-latest\")\n\n# \uba85\uc2dc\uc801 \uc0dd\uc131\nclaude_llm = AnthropicLLM(\n    model=\"claude-3-5-haiku-latest\",\n    api_key=\"your-api-key\",  # \ub610\ub294 \ud658\uacbd\ubcc0\uc218 ANTHROPIC_API_KEY\n    max_tokens=4096\n)\n</code></pre>"},{"location":"guides/providers/#_6","title":"\uc9c0\uc6d0 \ubaa8\ub378","text":"<pre><code># Claude 3.5 \uc2dc\ub9ac\uc988 (\ucd5c\uc2e0)\nsonnet_35 = LLM.create(\"claude-3-5-sonnet-latest\")  # \ucd5c\uace0 \uc131\ub2a5\nhaiku_35 = LLM.create(\"claude-3-5-haiku-latest\")    # \ube60\ub974\uace0 \uacbd\uc81c\uc801\n\n# Claude 3 \uc2dc\ub9ac\uc988\nopus_3 = LLM.create(\"claude-3-opus-20240229\")       # \ucd5c\uace0\uae09\nsonnet_3 = LLM.create(\"claude-3-sonnet-20240229\")   # \uade0\ud615\nhaiku_3 = LLM.create(\"claude-3-haiku-20240307\")     # \uacbd\uc81c\uc801\n</code></pre>"},{"location":"guides/providers/#claude","title":"Claude \ud2b9\ud654 \uae30\ub2a5","text":"<pre><code># \uae34 \ucee8\ud14d\uc2a4\ud2b8 \ucc98\ub9ac (\ucd5c\ub300 200k \ud1a0\ud070)\nwith open(\"long_document.txt\", \"r\") as f:\n    long_text = f.read()\n\nreply = claude_llm.ask(f\"\"\"\n\ub2e4\uc74c \ubb38\uc11c\ub97c \ubd84\uc11d\ud574\uc8fc\uc138\uc694:\n\n{long_text}\n\n\uc8fc\uc694 \ub0b4\uc6a9\uc744 3\uac00\uc9c0\ub85c \uc694\uc57d\ud574\uc8fc\uc138\uc694.\n\"\"\")\n\n# \uc2dc\uc2a4\ud15c \ud504\ub86c\ud504\ud2b8 \ud65c\uc6a9\nethical_claude = AnthropicLLM(\n    model=\"claude-3-5-sonnet-latest\",\n    system_prompt=\"\"\"\n\ub2f9\uc2e0\uc740 \uc724\ub9ac\uc801\uc774\uace0 \ub3c4\uc6c0\uc774 \ub418\ub294 AI \uc5b4\uc2dc\uc2a4\ud134\ud2b8\uc785\ub2c8\ub2e4.\n\uc815\ud655\ud558\uace0 \uade0\ud615\uc7a1\ud78c \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\uba70, \ud574\ub85c\uc6b4 \ub0b4\uc6a9\uc740 \uac70\ubd80\ud569\ub2c8\ub2e4.\n\"\"\"\n)\n\n# Claude\uc758 \ucd94\ub860 \ub2a5\ub825 \ud65c\uc6a9\nreply = claude_llm.ask(\"\"\"\n\ub2e4\uc74c \ub17c\ub9ac \ud37c\uc990\uc744 \ud480\uc5b4\uc8fc\uc138\uc694:\n\n\uc138 \uba85\uc758 \uce5c\uad6c A, B, C\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n- A\ub294 \ud56d\uc0c1 \uc9c4\uc2e4\uc744 \ub9d0\ud569\ub2c8\ub2e4\n- B\ub294 \ud56d\uc0c1 \uac70\uc9d3\uc744 \ub9d0\ud569\ub2c8\ub2e4  \n- C\ub294 \uc9c4\uc2e4\uacfc \uac70\uc9d3\uc744 \ubc88\uac08\uc544 \ub9d0\ud569\ub2c8\ub2e4\n\n\ud55c \uba85\uc5d0\uac8c \"\ub2f9\uc2e0\uc740 A\uc785\ub2c8\uae4c?\"\ub77c\uace0 \ubb3c\uc5c8\ub354\ub2c8 \"\ub124\"\ub77c\uace0 \ub2f5\ud588\uc2b5\ub2c8\ub2e4.\n\uc774 \uc0ac\ub78c\uc740 \ub204\uad6c\uc77c\uae4c\uc694? \uc774\uc720\ub97c \uc124\uba85\ud574\uc8fc\uc138\uc694.\n\"\"\")\n</code></pre>"},{"location":"guides/providers/#google-gemini","title":"Google Gemini","text":""},{"location":"guides/providers/#_7","title":"\uc124\uc815 \ubc0f \ucd08\uae30\ud654","text":"<pre><code>from pyhub.llm import GoogleLLM\n\n# \uc790\ub3d9 \uac10\uc9c0\nllm = LLM.create(\"gemini-2.0-flash-exp\")\n\n# \uba85\uc2dc\uc801 \uc0dd\uc131  \ngemini_llm = GoogleLLM(\n    model=\"gemini-2.0-flash-exp\",\n    api_key=\"your-api-key\",  # \ub610\ub294 \ud658\uacbd\ubcc0\uc218 GOOGLE_API_KEY\n    temperature=0.9\n)\n</code></pre>"},{"location":"guides/providers/#_8","title":"\uc9c0\uc6d0 \ubaa8\ub378","text":"<pre><code># Gemini 2.0 \uc2dc\ub9ac\uc988 (\ucd5c\uc2e0)\nflash_2 = LLM.create(\"gemini-2.0-flash-exp\")        # \uc2e4\ud5d8\uc801, \ube60\ub984\n\n# Gemini 1.5 \uc2dc\ub9ac\uc988\npro_15 = LLM.create(\"gemini-1.5-pro\")               # \uace0\uc131\ub2a5\nflash_15 = LLM.create(\"gemini-1.5-flash\")           # \ube60\ub974\uace0 \ud6a8\uc728\uc801\n\n# Gemini 1.0 \uc2dc\ub9ac\uc988\npro_10 = LLM.create(\"gemini-1.0-pro\")               # \uc548\uc815\uc801\n</code></pre>"},{"location":"guides/providers/#gemini","title":"Gemini \ud2b9\ud654 \uae30\ub2a5","text":"<pre><code># \uba40\ud2f0\ubaa8\ub2ec \ub2a5\ub825 (\uc774\ubbf8\uc9c0, \ube44\ub514\uc624, \uc624\ub514\uc624)\nreply = gemini_llm.ask(\n    \"\uc774 \uc774\ubbf8\uc9c0\ub4e4\uc744 \ube44\uad50 \ubd84\uc11d\ud574\uc8fc\uc138\uc694\",\n    files=[\"image1.jpg\", \"image2.jpg\", \"image3.jpg\"]\n)\n\n# \uc548\uc804 \uc124\uc815\nfrom google.generativeai.types import HarmCategory, HarmBlockThreshold\n\ngemini_safe = GoogleLLM(\n    model=\"gemini-1.5-pro\",\n    safety_settings={\n        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    }\n)\n\n# \ubb34\ub8cc \ud2f0\uc5b4 \ud65c\uc6a9\n# Google AI Studio\uc5d0\uc11c \ubb34\ub8cc API \ud0a4 \ubc1c\uae09 \uac00\ub2a5\nfree_gemini = GoogleLLM(\n    model=\"gemini-1.5-flash\",\n    api_key=\"free-tier-api-key\"\n)\n</code></pre>"},{"location":"guides/providers/#ollama","title":"Ollama (\ub85c\uceec \ubaa8\ub378)","text":""},{"location":"guides/providers/#_9","title":"\uc124\uc815 \ubc0f \ucd08\uae30\ud654","text":"<pre><code>from pyhub.llm import OllamaLLM\n\n# Ollama \uc11c\ubc84\uac00 \ub85c\uceec\uc5d0\uc11c \uc2e4\ud589 \uc911\uc774\uc5b4\uc57c \ud568\n# ollama serve\n\n# \uc790\ub3d9 \uac10\uc9c0\nllm = LLM.create(\"llama3.2:latest\")\n\n# \uba85\uc2dc\uc801 \uc0dd\uc131\nollama_llm = OllamaLLM(\n    model=\"llama3.2:latest\",\n    base_url=\"http://localhost:11434\",  # \uae30\ubcf8\uac12\n    temperature=0.8\n)\n</code></pre>"},{"location":"guides/providers/#_10","title":"\uc9c0\uc6d0 \ubaa8\ub378","text":"<pre><code># \uc778\uae30 \ubaa8\ub378\ub4e4\nllama32 = LLM.create(\"llama3.2:latest\")         # Meta\uc758 \ucd5c\uc2e0 \ubaa8\ub378\nmistral = LLM.create(\"mistral:latest\")          # \uacbd\ub7c9 \uace0\uc131\ub2a5\ncodellama = LLM.create(\"codellama:latest\")      # \ucf54\ub4dc \ud2b9\ud654\nphi3 = LLM.create(\"phi3:latest\")                # Microsoft \uc18c\ud615 \ubaa8\ub378\n\n# \ud55c\uad6d\uc5b4 \ubaa8\ub378\nsolar = LLM.create(\"solar:latest\")              # \ud55c\uad6d\uc5b4 \uc9c0\uc6d0\n</code></pre>"},{"location":"guides/providers/#ollama_1","title":"Ollama \ud2b9\ud654 \uae30\ub2a5","text":"<pre><code># \ubaa8\ub378 \uad00\ub9ac\nimport subprocess\n\n# \ubaa8\ub378 \ub2e4\uc6b4\ub85c\ub4dc\nsubprocess.run([\"ollama\", \"pull\", \"llama3.2:latest\"])\n\n# \uc0ac\uc6a9 \uac00\ub2a5\ud55c \ubaa8\ub378 \ud655\uc778\nresult = subprocess.run([\"ollama\", \"list\"], capture_output=True, text=True)\nprint(result.stdout)\n\n# \ucee4\uc2a4\ud140 \ubaa8\ub378 \uc0dd\uc131\nmodelfile = \"\"\"\nFROM llama3.2:latest\nPARAMETER temperature 0.5\nSYSTEM \ub2f9\uc2e0\uc740 \ud55c\uad6d\uc5b4\ub97c \uc720\ucc3d\ud558\uac8c \uad6c\uc0ac\ud558\ub294 AI \uc5b4\uc2dc\uc2a4\ud134\ud2b8\uc785\ub2c8\ub2e4.\n\"\"\"\n\nwith open(\"Modelfile\", \"w\") as f:\n    f.write(modelfile)\n\nsubprocess.run([\"ollama\", \"create\", \"korean-llama\", \"-f\", \"Modelfile\"])\n\n# \ucee4\uc2a4\ud140 \ubaa8\ub378 \uc0ac\uc6a9\nkorean_llm = OllamaLLM(model=\"korean-llama\")\n</code></pre>"},{"location":"guides/providers/#upstage-solar","title":"Upstage Solar","text":""},{"location":"guides/providers/#_11","title":"\uc124\uc815 \ubc0f \ucd08\uae30\ud654","text":"<pre><code>from pyhub.llm import UpstageLLM\n\n# \uc790\ub3d9 \uac10\uc9c0\nllm = LLM.create(\"solar-pro\")\n\n# \uba85\uc2dc\uc801 \uc0dd\uc131\nsolar_llm = UpstageLLM(\n    model=\"solar-pro\",\n    api_key=\"your-api-key\",  # \ub610\ub294 \ud658\uacbd\ubcc0\uc218 UPSTAGE_API_KEY\n)\n</code></pre>"},{"location":"guides/providers/#_12","title":"\uc9c0\uc6d0 \ubaa8\ub378","text":"<pre><code># Solar \uc2dc\ub9ac\uc988\nsolar_pro = LLM.create(\"solar-pro\")      # \uace0\uc131\ub2a5\nsolar_mini = LLM.create(\"solar-mini\")    # \uacbd\ub7c9\ud654\n\n# \ud2b9\ud654 \ubaa8\ub378\nsolar_doc = LLM.create(\"solar-docvqa\")   # \ubb38\uc11c \ubd84\uc11d\n</code></pre>"},{"location":"guides/providers/#solar","title":"Solar \ud2b9\ud654 \uae30\ub2a5","text":"<pre><code># \ud55c\uad6d\uc5b4 \ucd5c\uc801\ud654\nreply = solar_llm.ask(\"\"\"\n\ub2e4\uc74c \ud55c\uad6d\uc5b4 \ubb38\uc7a5\uc744 \ubd84\uc11d\ud574\uc8fc\uc138\uc694:\n\"\uc544\ubc84\uc9c0\uac00 \ubc29\uc5d0 \ub4e4\uc5b4\uac00\uc2e0\ub2e4\"\n\n1. \ubb38\ubc95 \uad6c\uc870\n2. \uc874\ub313\ub9d0 \uc0ac\uc6a9\n3. \uc758\ubbf8 \ud574\uc11d\n\"\"\")\n\n# \ubb38\uc11c \ubd84\uc11d (DocVQA)\ndoc_solar = UpstageLLM(model=\"solar-docvqa\")\nreply = doc_solar.ask(\n    \"\uc774 \ubb38\uc11c\uc5d0\uc11c \uacc4\uc57d \uae08\uc561\uc744 \ucc3e\uc544\uc8fc\uc138\uc694\",\n    files=[\"contract.pdf\"]\n)\n</code></pre>"},{"location":"guides/providers/#_13","title":"\ud504\ub85c\ubc14\uc774\ub354 \uc120\ud0dd \uac00\uc774\ub4dc","text":""},{"location":"guides/providers/#_14","title":"\uc0ac\uc6a9 \uc0ac\ub840\ubcc4 \ucd94\ucc9c","text":"<pre><code># 1. \uc77c\ubc18 \ub300\ud654 \ubc0f \uc9c8\uc758\uc751\ub2f5\ngeneral_llm = LLM.create(\"gpt-4o-mini\")  # \ube44\uc6a9 \ud6a8\uc728\uc801\n# \ub610\ub294\ngeneral_llm = LLM.create(\"claude-3-5-haiku-latest\")  # \ube60\ub978 \uc751\ub2f5\n\n# 2. \ubcf5\uc7a1\ud55c \ucd94\ub860 \ubc0f \ubd84\uc11d\ncomplex_llm = LLM.create(\"gpt-4o\")  # OpenAI \ucd5c\uace0 \uc131\ub2a5\n# \ub610\ub294\ncomplex_llm = LLM.create(\"claude-3-5-sonnet-latest\")  # \ub6f0\uc5b4\ub09c \ucd94\ub860\n\n# 3. \ucf54\ub4dc \uc0dd\uc131 \ubc0f \uae30\uc220 \ubb38\uc11c\ncode_llm = LLM.create(\"gpt-4-turbo\")  # \ucf54\ub4dc \uc774\ud574\ub3c4 \ub192\uc74c\n# \ub610\ub294 \ncode_llm = LLM.create(\"codellama:latest\")  # \ub85c\uceec, \ubb34\ub8cc\n\n# 4. \ud55c\uad6d\uc5b4 \uc791\uc5c5\nkorean_llm = LLM.create(\"solar-pro\")  # \ud55c\uad6d\uc5b4 \ud2b9\ud654\n# \ub610\ub294\nkorean_llm = LLM.create(\"claude-3-5-sonnet-latest\")  # \ud55c\uad6d\uc5b4\ub3c4 \uc6b0\uc218\n\n# 5. \uba40\ud2f0\ubaa8\ub2ec (\uc774\ubbf8\uc9c0/\ube44\ub514\uc624)\nmultimodal_llm = LLM.create(\"gemini-2.0-flash-exp\")  # \ucd5c\uc2e0 \uba40\ud2f0\ubaa8\ub2ec\n# \ub610\ub294\nmultimodal_llm = LLM.create(\"gpt-4o\")  # \uc774\ubbf8\uc9c0 \uc774\ud574\n\n# 6. \ud504\ub77c\uc774\ubc84\uc2dc \uc911\uc2dc (\ub85c\uceec)\nprivate_llm = LLM.create(\"llama3.2:latest\")  # \uc644\uc804 \ub85c\uceec\n# \ub610\ub294\nprivate_llm = LLM.create(\"mistral:latest\")  # \uacbd\ub7c9 \ub85c\uceec\n</code></pre>"},{"location":"guides/providers/#_15","title":"\ube44\uc6a9 \ucd5c\uc801\ud654 \uc804\ub7b5","text":"<pre><code>class CostOptimizedLLM:\n    def __init__(self):\n        # \uc791\uc5c5\ubcc4 \ubaa8\ub378 \uad6c\ubd84\n        self.simple_llm = LLM.create(\"gpt-4o-mini\", stateless=True)\n        self.complex_llm = LLM.create(\"gpt-4o\")\n        self.local_llm = LLM.create(\"llama3.2:latest\")\n\n    def ask(self, prompt, complexity=\"auto\"):\n        if complexity == \"auto\":\n            # \ud504\ub86c\ud504\ud2b8 \uae38\uc774\ub85c \ubcf5\uc7a1\ub3c4 \ucd94\uc815\n            complexity = \"complex\" if len(prompt) &gt; 500 else \"simple\"\n\n        if complexity == \"simple\":\n            return self.simple_llm.ask(prompt)\n        elif complexity == \"complex\":\n            return self.complex_llm.ask(prompt)\n        elif complexity == \"local\":\n            return self.local_llm.ask(prompt)\n\n# \uc0ac\uc6a9\noptimizer = CostOptimizedLLM()\n\n# \uac04\ub2e8\ud55c \uc9c8\ubb38 - \uc800\ub834\ud55c \ubaa8\ub378 \uc0ac\uc6a9\nreply1 = optimizer.ask(\"\uc624\ub298 \ub0a0\uc9dc\ub294?\", complexity=\"simple\")\n\n# \ubcf5\uc7a1\ud55c \ubd84\uc11d - \uace0\uae09 \ubaa8\ub378 \uc0ac\uc6a9  \nreply2 = optimizer.ask(\"\uc774 \ucf54\ub4dc\uc758 \uc2dc\uac04\ubcf5\uc7a1\ub3c4\ub97c \ubd84\uc11d\ud558\uace0...\", complexity=\"complex\")\n\n# \ubbfc\uac10\ud55c \ub370\uc774\ud130 - \ub85c\uceec \ubaa8\ub378 \uc0ac\uc6a9\nreply3 = optimizer.ask(\"\uc774 \uac1c\uc778\uc815\ubcf4\ub97c \ubd84\uc11d\ud574\uc11c...\", complexity=\"local\")\n</code></pre>"},{"location":"guides/providers/#_16","title":"\ud504\ub85c\ubc14\uc774\ub354 \ub9c8\uc774\uadf8\ub808\uc774\uc158","text":""},{"location":"guides/providers/#_17","title":"\ud504\ub85c\ubc14\uc774\ub354 \uac04 \uc804\ud658","text":"<pre><code># \uae30\uc874 OpenAI \ucf54\ub4dc\nold_llm = LLM.create(\"gpt-4o-mini\")\nreply = old_llm.ask(\"\uc9c8\ubb38\")\n\n# Claude\ub85c \uc804\ud658 - \ucf54\ub4dc \ubcc0\uacbd \ucd5c\uc18c\ud654\nnew_llm = LLM.create(\"claude-3-5-haiku-latest\")  # \uc774 \uc904\ub9cc \ubcc0\uacbd\nreply = new_llm.ask(\"\uc9c8\ubb38\")  # \ub3d9\uc77c\ud55c \uc778\ud130\ud398\uc774\uc2a4\n\n# \ub3d9\uc801 \ud504\ub85c\ubc14\uc774\ub354 \uc804\ud658\ndef create_llm_with_fallback(primary_model, fallback_model):\n    try:\n        return LLM.create(primary_model)\n    except Exception as e:\n        print(f\"Primary model failed: {e}\")\n        return LLM.create(fallback_model)\n\n# \uc0ac\uc6a9\nllm = create_llm_with_fallback(\n    primary_model=\"gpt-4o\",\n    fallback_model=\"llama3.2:latest\"  # \ub85c\uceec \ud3f4\ubc31\n)\n</code></pre>"},{"location":"guides/providers/#ab","title":"A/B \ud14c\uc2a4\ud2b8","text":"<pre><code>import random\nfrom collections import defaultdict\n\nclass ABTestLLM:\n    def __init__(self, models, weights=None):\n        self.models = {name: LLM.create(name) for name in models}\n        self.weights = weights or [1] * len(models)\n        self.results = defaultdict(list)\n\n    def ask(self, prompt, **kwargs):\n        # \uac00\uc911\uce58 \uae30\ubc18 \ubaa8\ub378 \uc120\ud0dd\n        model_name = random.choices(\n            list(self.models.keys()),\n            weights=self.weights\n        )[0]\n\n        llm = self.models[model_name]\n        reply = llm.ask(prompt, **kwargs)\n\n        # \uacb0\uacfc \uae30\ub85d\n        self.results[model_name].append({\n            'prompt': prompt,\n            'response': reply.text,\n            'tokens': reply.usage.total_tokens if reply.usage else 0,\n            'time': reply.elapsed_time\n        })\n\n        return reply\n\n    def get_statistics(self):\n        stats = {}\n        for model, results in self.results.items():\n            if results:\n                avg_tokens = sum(r['tokens'] for r in results) / len(results)\n                avg_time = sum(r['time'] for r in results) / len(results)\n                stats[model] = {\n                    'count': len(results),\n                    'avg_tokens': avg_tokens,\n                    'avg_time': avg_time\n                }\n        return stats\n\n# \uc0ac\uc6a9\nab_test = ABTestLLM(\n    models=[\"gpt-4o-mini\", \"claude-3-5-haiku-latest\"],\n    weights=[0.5, 0.5]  # 50:50 \ubd84\ud560\n)\n\n# \ud14c\uc2a4\ud2b8 \uc2e4\ud589\nfor _ in range(100):\n    ab_test.ask(\"\ud30c\uc774\uc36c \ud301\uc744 \ud558\ub098 \uc54c\ub824\uc8fc\uc138\uc694\")\n\n# \uacb0\uacfc \ubd84\uc11d\nprint(ab_test.get_statistics())\n</code></pre>"},{"location":"guides/providers/#_18","title":"\ub2e4\uc74c \ub2e8\uacc4","text":"<ul> <li>\uad6c\uc870\ud654\ub41c \ucd9c\ub825 - JSON \uc2a4\ud0a4\ub9c8\uc640 Pydantic \ud65c\uc6a9</li> <li>\uace0\uae09 \uae30\ub2a5 - \uc2a4\ud2b8\ub9ac\ubc0d, \ube44\ub3d9\uae30, \uc784\ubca0\ub529 \ub4f1</li> <li>API \ub808\ud37c\ub7f0\uc2a4 - \uc804\uccb4 API \ubb38\uc11c</li> </ul>"},{"location":"guides/structured-output/","title":"\uad6c\uc870\ud654\ub41c \ucd9c\ub825","text":"<p>pyhub-llm\uc758 \uad6c\uc870\ud654\ub41c \ucd9c\ub825 \uae30\ub2a5\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud0c0\uc785 \uc548\uc804\ud55c \uc751\ub2f5\uc744 \ubc1b\ub294 \ubc29\ubc95\uc744 \uc54c\uc544\ubd05\ub2c8\ub2e4.</p>"},{"location":"guides/structured-output/#_2","title":"\uac1c\uc694","text":"<p>\uad6c\uc870\ud654\ub41c \ucd9c\ub825\uc740 LLM\uc758 \uc751\ub2f5\uc744 \ubbf8\ub9ac \uc815\uc758\ub41c \ud615\uc2dd\uc73c\ub85c \ubc1b\uc744 \uc218 \uc788\uac8c \ud574\uc8fc\ub294 \uae30\ub2a5\uc785\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574:</p> <ul> <li>\u2705 \ud0c0\uc785 \uc548\uc804\uc131 \ubcf4\uc7a5</li> <li>\u2705 \uc751\ub2f5 \ud615\uc2dd \uc77c\uad00\uc131</li> <li>\u2705 \uc790\ub3d9 \uac80\uc99d \ubc0f \ud30c\uc2f1</li> <li>\u2705 IDE \uc790\ub3d9 \uc644\uc131 \uc9c0\uc6d0</li> </ul>"},{"location":"guides/structured-output/#_3","title":"\uc120\ud0dd\uc9c0\uc5d0\uc11c \uace0\ub974\uae30","text":""},{"location":"guides/structured-output/#_4","title":"\uae30\ubcf8 \uc0ac\uc6a9\ubc95","text":"<pre><code>from pyhub.llm import LLM\n\nllm = LLM.create(\"gpt-4o-mini\")\n\n# \ub2e8\uc21c \uc120\ud0dd\nreply = llm.ask(\n    \"\ub2e4\uc74c \ud14d\uc2a4\ud2b8\uc758 \uac10\uc815\uc744 \ubd84\uc11d\ud558\uc138\uc694: '\uc624\ub298 \uc815\ub9d0 \ud589\ubcf5\ud55c \ud558\ub8e8\uc600\uc5b4\uc694!'\",\n    choices=[\"\uae0d\uc815\", \"\ubd80\uc815\", \"\uc911\ub9bd\"]\n)\n\nprint(f\"\uac10\uc815: {reply.choice}\")        # \"\uae0d\uc815\"\nprint(f\"\ud655\uc2e0\ub3c4: {reply.confidence}\")  # 0.95\nprint(f\"\uc778\ub371\uc2a4: {reply.choice_index}\") # 0\n</code></pre>"},{"location":"guides/structured-output/#_5","title":"\ub2e4\uc591\ud55c \uc120\ud0dd\uc9c0 \ud65c\uc6a9","text":"<pre><code># \uc758\ub3c4 \ubd84\ub958\nintents = [\"\uc9c8\ubb38\", \"\uc694\uccad\", \"\ubd88\ub9cc\", \"\uce6d\ucc2c\", \"\uc815\ubcf4\uc81c\uacf5\", \"\uae30\ud0c0\"]\n\nreply = llm.ask(\n    \"\uace0\uac1d: '\uc774 \uc81c\ud488 \uc5b8\uc81c \uc7ac\uc785\uace0 \ub418\ub098\uc694?'\",\n    choices=intents\n)\nprint(f\"\uc758\ub3c4: {reply.choice}\")  # \"\uc9c8\ubb38\"\n\n# \ub2e4\uc911 \ub808\uc774\ube14 \ubd84\ub958 (\uac01\uac01 \ucc98\ub9ac)\ntags = [\"\uae30\uc220\", \"\uacfc\ud559\", \"\uc815\uce58\", \"\uacbd\uc81c\", \"\ubb38\ud654\", \"\uc2a4\ud3ec\uce20\"]\narticle = \"AI \uae30\uc220\uc774 \uc758\ub8cc \ubd84\uc57c\uc5d0 \ud601\uc2e0\uc744 \uac00\uc838\uc624\uace0 \uc788\uc2b5\ub2c8\ub2e4...\"\n\nrelevant_tags = []\nfor tag in tags:\n    reply = llm.ask(\n        f\"\ub2e4\uc74c \uae30\uc0ac\uac00 '{tag}' \uce74\ud14c\uace0\ub9ac\uc5d0 \ud574\ub2f9\ud558\ub098\uc694?\\n\\n{article}\",\n        choices=[\"\uc608\", \"\uc544\ub2c8\uc624\"]\n    )\n    if reply.choice == \"\uc608\":\n        relevant_tags.append(tag)\n\nprint(f\"\uad00\ub828 \ud0dc\uadf8: {relevant_tags}\")  # [\"\uae30\uc220\", \"\uacfc\ud559\"]\n</code></pre>"},{"location":"guides/structured-output/#_6","title":"\ub3d9\uc801 \uc120\ud0dd\uc9c0 \uc0dd\uc131","text":"<pre><code># \uc0ac\uc6a9\uc790 \uc785\ub825 \uae30\ubc18 \uc120\ud0dd\uc9c0\ndef get_dynamic_choices(category):\n    if category == \"\uc74c\uc2dd\":\n        return [\"\ud55c\uc2dd\", \"\uc911\uc2dd\", \"\uc77c\uc2dd\", \"\uc591\uc2dd\", \"\uae30\ud0c0\"]\n    elif category == \"\uc6b4\ub3d9\":\n        return [\"\uc720\uc0b0\uc18c\", \"\uadfc\ub825\", \"\uc2a4\ud2b8\ub808\uce6d\", \"\uc694\uac00\", \"\ud544\ub77c\ud14c\uc2a4\"]\n    else:\n        return [\"\uc635\uc1581\", \"\uc635\uc1582\", \"\uc635\uc1583\"]\n\ncategory = \"\uc74c\uc2dd\"\nchoices = get_dynamic_choices(category)\n\nreply = llm.ask(\n    \"\uae40\uce58\ucc0c\uac1c\ub294 \uc5b4\ub5a4 \uc885\ub958\uc758 \uc74c\uc2dd\uc778\uac00\uc694?\",\n    choices=choices\n)\nprint(reply.choice)  # \"\ud55c\uc2dd\"\n</code></pre>"},{"location":"guides/structured-output/#pydantic","title":"Pydantic \uc2a4\ud0a4\ub9c8 \uc0ac\uc6a9","text":""},{"location":"guides/structured-output/#_7","title":"\uae30\ubcf8 \uc2a4\ud0a4\ub9c8 \uc815\uc758","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import List, Optional\nfrom datetime import datetime\n\nclass Person(BaseModel):\n    name: str = Field(description=\"\uc0ac\ub78c\uc758 \uc774\ub984\")\n    age: int = Field(description=\"\ub098\uc774\", ge=0, le=150)\n    email: Optional[str] = Field(None, description=\"\uc774\uba54\uc77c \uc8fc\uc18c\")\n    hobbies: List[str] = Field(default_factory=list, description=\"\ucde8\ubbf8 \ubaa9\ub85d\")\n\n# \uc2a4\ud0a4\ub9c8 \uc0ac\uc6a9\nreply = llm.ask(\n    \"\ub2e4\uc74c \uc815\ubcf4\ub85c \uc0ac\ub78c \ud504\ub85c\ud544\uc744 \ub9cc\ub4e4\uc5b4\uc8fc\uc138\uc694: \ud64d\uae38\ub3d9, 25\uc0b4, \ucd95\uad6c\uc640 \ub3c5\uc11c\ub97c \uc88b\uc544\ud568\",\n    schema=Person\n)\n\nperson = reply.structured_data\nprint(f\"\uc774\ub984: {person.name}\")\nprint(f\"\ub098\uc774: {person.age}\")\nprint(f\"\ucde8\ubbf8: {', '.join(person.hobbies)}\")\n</code></pre>"},{"location":"guides/structured-output/#_8","title":"\uc911\ucca9\ub41c \uc2a4\ud0a4\ub9c8","text":"<pre><code>class Address(BaseModel):\n    street: str\n    city: str\n    country: str\n    postal_code: Optional[str] = None\n\nclass Company(BaseModel):\n    name: str\n    industry: str\n    employee_count: int\n    address: Address\n    is_public: bool\n\nclass JobPosting(BaseModel):\n    title: str\n    company: Company\n    salary_range: tuple[int, int]\n    requirements: List[str]\n    benefits: List[str]\n    remote_allowed: bool\n    posted_date: datetime\n\n# \ubcf5\uc7a1\ud55c \uad6c\uc870 \ud30c\uc2f1\nreply = llm.ask(\n    \"\"\"\n    \ub2e4\uc74c \uad6c\uc778 \uacf5\uace0 \uc815\ubcf4\ub97c \uad6c\uc870\ud654\ud558\uc138\uc694:\n\n    \uc0bc\uc131\uc804\uc790\uc5d0\uc11c AI \uc5d4\uc9c0\ub2c8\uc5b4\ub97c \ubaa8\uc9d1\ud569\ub2c8\ub2e4.\n    - \uc5f0\ubd09: 6000-8000\ub9cc\uc6d0\n    - \uc694\uad6c\uc0ac\ud56d: Python, ML \uacbd\ud5d8 3\ub144 \uc774\uc0c1, \uc11d\uc0ac \uc6b0\ub300\n    - \ubcf5\uc9c0: 4\ub300\ubcf4\ud5d8, \uc2a4\ud1a1\uc635\uc158, \uc720\uc5f0\uadfc\ubb34\n    - \uadfc\ubb34\uc9c0: \uc11c\uc6b8 \uac15\ub0a8\uad6c, \uc7ac\ud0dd\uadfc\ubb34 \uac00\ub2a5\n    \"\"\",\n    schema=JobPosting\n)\n\njob = reply.structured_data\nprint(f\"\ud68c\uc0ac: {job.company.name}\")\nprint(f\"\uc9c1\ubb34: {job.title}\")\nprint(f\"\uc5f0\ubd09: {job.salary_range[0]:,}\ub9cc\uc6d0 ~ {job.salary_range[1]:,}\ub9cc\uc6d0\")\nprint(f\"\uc7ac\ud0dd\uadfc\ubb34: {'\uac00\ub2a5' if job.remote_allowed else '\ubd88\uac00'}\")\n</code></pre>"},{"location":"guides/structured-output/#enum","title":"Enum\uacfc \uc81c\uc57d \uc870\uac74","text":"<pre><code>from enum import Enum\nfrom pydantic import BaseModel, Field, validator\n\nclass Priority(str, Enum):\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    URGENT = \"urgent\"\n\nclass Status(str, Enum):\n    TODO = \"todo\"\n    IN_PROGRESS = \"in_progress\"\n    DONE = \"done\"\n    CANCELLED = \"cancelled\"\n\nclass Task(BaseModel):\n    title: str = Field(..., min_length=1, max_length=100)\n    description: str\n    priority: Priority\n    status: Status = Status.TODO\n    estimated_hours: float = Field(..., gt=0, le=100)\n    assigned_to: Optional[str] = None\n    due_date: Optional[datetime] = None\n\n    @validator('due_date')\n    def due_date_must_be_future(cls, v):\n        if v and v &lt; datetime.now():\n            raise ValueError('Due date must be in the future')\n        return v\n\n# \uc0ac\uc6a9\nreply = llm.ask(\n    \"\ubc84\uadf8 \uc218\uc815 \uc791\uc5c5\uc744 \uc0dd\uc131\ud574\uc8fc\uc138\uc694. \ub85c\uadf8\uc778 \ud398\uc774\uc9c0 \uc5d0\ub7ec, \uae34\uae09, 3\uc2dc\uac04 \uc608\uc0c1\",\n    schema=Task\n)\n\ntask = reply.structured_data\nprint(f\"\uc791\uc5c5: {task.title}\")\nprint(f\"\uc6b0\uc120\uc21c\uc704: {task.priority.value}\")\nprint(f\"\uc608\uc0c1 \uc2dc\uac04: {task.estimated_hours}\uc2dc\uac04\")\n</code></pre>"},{"location":"guides/structured-output/#_9","title":"\uace0\uae09 \uc2a4\ud0a4\ub9c8 \ud328\ud134","text":""},{"location":"guides/structured-output/#union","title":"Union \ud0c0\uc785 \ucc98\ub9ac","text":"<pre><code>from typing import Union, Literal\n\nclass TextContent(BaseModel):\n    type: Literal[\"text\"]\n    content: str\n\nclass ImageContent(BaseModel):\n    type: Literal[\"image\"]\n    url: str\n    alt_text: Optional[str] = None\n\nclass VideoContent(BaseModel):\n    type: Literal[\"video\"]\n    url: str\n    duration_seconds: int\n    thumbnail_url: Optional[str] = None\n\nContent = Union[TextContent, ImageContent, VideoContent]\n\nclass Article(BaseModel):\n    title: str\n    author: str\n    contents: List[Content]\n    tags: List[str]\n\n# \uba40\ud2f0\ubbf8\ub514\uc5b4 \uae30\uc0ac \ud30c\uc2f1\nreply = llm.ask(\n    \"\"\"\n    \ub2e4\uc74c \uae30\uc0ac\ub97c \uad6c\uc870\ud654\ud558\uc138\uc694:\n\n    \uc81c\ubaa9: AI\uc758 \ubbf8\ub798\n    \uc800\uc790: \uae40\ucca0\uc218\n\n    \ub0b4\uc6a9:\n    1. AI\ub294 \uc6b0\ub9ac\uc758 \ubbf8\ub798\uc785\ub2c8\ub2e4. (\ud14d\uc2a4\ud2b8)\n    2. [AI \ub85c\ubd07 \uc774\ubbf8\uc9c0] (\uc774\ubbf8\uc9c0)\n    3. AI \ub370\ubaa8 \uc601\uc0c1 (2\ubd84 30\ucd08) (\ube44\ub514\uc624)\n\n    \ud0dc\uadf8: AI, \ubbf8\ub798, \uae30\uc220\n    \"\"\",\n    schema=Article\n)\n\narticle = reply.structured_data\nfor content in article.contents:\n    print(f\"\ucf58\ud150\uce20 \ud0c0\uc785: {content.type}\")\n</code></pre>"},{"location":"guides/structured-output/#_10","title":"\uc7ac\uadc0\uc801 \uad6c\uc870","text":"<pre><code>from typing import List, Optional\n\nclass TreeNode(BaseModel):\n    name: str\n    value: Optional[int] = None\n    children: List['TreeNode'] = Field(default_factory=list)\n\n# Forward reference \ud574\uacb0\nTreeNode.model_rebuild()\n\nclass FileSystem(BaseModel):\n    root: TreeNode\n\n# \ud30c\uc77c \uc2dc\uc2a4\ud15c \uad6c\uc870 \ud30c\uc2f1\nreply = llm.ask(\n    \"\"\"\n    \ub2e4\uc74c \ub514\ub809\ud1a0\ub9ac \uad6c\uc870\ub97c \ud2b8\ub9ac\ub85c \ub9cc\ub4e4\uc5b4\uc8fc\uc138\uc694:\n\n    project/\n    \u251c\u2500\u2500 src/\n    \u2502   \u251c\u2500\u2500 main.py (100)\n    \u2502   \u2514\u2500\u2500 utils.py (50)\n    \u251c\u2500\u2500 tests/\n    \u2502   \u2514\u2500\u2500 test_main.py (80)\n    \u2514\u2500\u2500 README.md (20)\n\n    \uad04\ud638 \uc548\uc740 \ud30c\uc77c \ud06c\uae30(KB)\uc785\ub2c8\ub2e4.\n    \"\"\",\n    schema=FileSystem\n)\n\ndef print_tree(node: TreeNode, indent: int = 0):\n    print(\"  \" * indent + f\"{node.name}\" + (f\" ({node.value}KB)\" if node.value else \"\"))\n    for child in node.children:\n        print_tree(child, indent + 1)\n\nprint_tree(reply.structured_data.root)\n</code></pre>"},{"location":"guides/structured-output/#_11","title":"\ub3d9\uc801 \uc2a4\ud0a4\ub9c8 \uc0dd\uc131","text":"<pre><code>from typing import Dict, Any\n\ndef create_form_schema(fields: Dict[str, str]):\n    \"\"\"\ub3d9\uc801\uc73c\ub85c Pydantic \ubaa8\ub378 \uc0dd\uc131\"\"\"\n    field_definitions = {}\n\n    for field_name, field_type in fields.items():\n        if field_type == \"string\":\n            field_definitions[field_name] = (str, Field(...))\n        elif field_type == \"integer\":\n            field_definitions[field_name] = (int, Field(...))\n        elif field_type == \"boolean\":\n            field_definitions[field_name] = (bool, Field(...))\n        elif field_type == \"list\":\n            field_definitions[field_name] = (List[str], Field(default_factory=list))\n\n    # \ub3d9\uc801 \ubaa8\ub378 \uc0dd\uc131\n    DynamicModel = type(\n        'DynamicModel',\n        (BaseModel,),\n        {\n            '__annotations__': {k: v[0] for k, v in field_definitions.items()},\n            **{k: v[1] for k, v in field_definitions.items()}\n        }\n    )\n\n    return DynamicModel\n\n# \uc0ac\uc6a9 \uc608\uc2dc\nform_fields = {\n    \"name\": \"string\",\n    \"age\": \"integer\",\n    \"is_student\": \"boolean\",\n    \"interests\": \"list\"\n}\n\nDynamicForm = create_form_schema(form_fields)\n\nreply = llm.ask(\n    \"\ub2e4\uc74c \uc815\ubcf4\ub85c \ud3fc\uc744 \ucc44\uc6cc\uc8fc\uc138\uc694: \uae40\uc601\ud76c, 22\uc0b4, \ub300\ud559\uc0dd, \ud504\ub85c\uadf8\ub798\ubc0d\uacfc \ub514\uc790\uc778\uc5d0 \uad00\uc2ec\",\n    schema=DynamicForm\n)\n\nform_data = reply.structured_data\nprint(form_data.model_dump())\n</code></pre>"},{"location":"guides/structured-output/#_12","title":"\uc2e4\uc804 \ud65c\uc6a9 \uc608\uc81c","text":""},{"location":"guides/structured-output/#_13","title":"\ub370\uc774\ud130 \ucd94\ucd9c \ud30c\uc774\ud504\ub77c\uc778","text":"<pre><code>class ExtractedEntity(BaseModel):\n    name: str\n    type: str\n    confidence: float = Field(..., ge=0, le=1)\n\nclass DocumentAnalysis(BaseModel):\n    summary: str = Field(..., max_length=200)\n    entities: List[ExtractedEntity]\n    key_phrases: List[str]\n    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]\n    language: str\n\ndef analyze_document(text: str) -&gt; DocumentAnalysis:\n    llm = LLM.create(\"gpt-4o-mini\")\n\n    reply = llm.ask(\n        f\"\"\"\n        \ub2e4\uc74c \ubb38\uc11c\ub97c \ubd84\uc11d\ud558\uc138\uc694:\n\n        {text}\n\n        \uc694\uc57d, \uc8fc\uc694 \uc5d4\ud2f0\ud2f0, \ud575\uc2ec \uad6c\ubb38, \uac10\uc815, \uc5b8\uc5b4\ub97c \ucd94\ucd9c\ud558\uc138\uc694.\n        \"\"\",\n        schema=DocumentAnalysis\n    )\n\n    return reply.structured_data\n\n# \uc0ac\uc6a9\ndocument = \"\"\"\n\uc560\ud50c\uc774 \uc0c8\ub85c\uc6b4 \uc544\uc774\ud3f0 16\uc744 \ubc1c\ud45c\ud588\uc2b5\ub2c8\ub2e4. \n\ud300 \ucfe1 CEO\ub294 \"\uc774\ubc88 \uc81c\ud488\uc740 \ud601\uc2e0\uc758 \uc815\uc810\"\uc774\ub77c\uace0 \ub9d0\ud588\uc2b5\ub2c8\ub2e4.\n\uac00\uaca9\uc740 $999\ubd80\ud130 \uc2dc\uc791\ud558\uba70, 9\uc6d4 15\uc77c \ucd9c\uc2dc \uc608\uc815\uc785\ub2c8\ub2e4.\n\"\"\"\n\nanalysis = analyze_document(document)\nprint(f\"\uc694\uc57d: {analysis.summary}\")\nprint(f\"\uac10\uc815: {analysis.sentiment}\")\nprint(f\"\uc5d4\ud2f0\ud2f0: {[f'{e.name}({e.type})' for e in analysis.entities]}\")\n</code></pre>"},{"location":"guides/structured-output/#api","title":"API \uc751\ub2f5 \ubcc0\ud658","text":"<pre><code>class APIResponse(BaseModel):\n    \"\"\"\uc678\ubd80 API \uc751\ub2f5\uc744 \ud45c\uc900\ud654\"\"\"\n    success: bool\n    data: Optional[Dict[str, Any]] = None\n    error: Optional[str] = None\n    timestamp: datetime = Field(default_factory=datetime.now)\n\nclass UserData(BaseModel):\n    id: int\n    username: str\n    email: str\n    is_active: bool\n    created_at: datetime\n\ndef parse_api_response(raw_response: str) -&gt; UserData:\n    llm = LLM.create(\"gpt-4o-mini\")\n\n    # \uba3c\uc800 API \uc751\ub2f5 \ud30c\uc2f1\n    api_reply = llm.ask(\n        f\"\ub2e4\uc74c API \uc751\ub2f5\uc744 \ud30c\uc2f1\ud558\uc138\uc694:\\n{raw_response}\",\n        schema=APIResponse\n    )\n\n    if not api_reply.structured_data.success:\n        raise ValueError(f\"API \uc5d0\ub7ec: {api_reply.structured_data.error}\")\n\n    # \uc0ac\uc6a9\uc790 \ub370\uc774\ud130 \ucd94\ucd9c\n    user_reply = llm.ask(\n        f\"\ub2e4\uc74c \ub370\uc774\ud130\uc5d0\uc11c \uc0ac\uc6a9\uc790 \uc815\ubcf4\ub97c \ucd94\ucd9c\ud558\uc138\uc694:\\n{api_reply.structured_data.data}\",\n        schema=UserData\n    )\n\n    return user_reply.structured_data\n</code></pre>"},{"location":"guides/structured-output/#_14","title":"\uc124\uc815 \ud30c\uc77c \uc0dd\uc131","text":"<pre><code>class DatabaseConfig(BaseModel):\n    host: str\n    port: int = 5432\n    database: str\n    username: str\n    ssl_enabled: bool = True\n\nclass CacheConfig(BaseModel):\n    type: Literal[\"redis\", \"memcached\", \"in-memory\"]\n    ttl_seconds: int = 3600\n    max_size_mb: Optional[int] = None\n\nclass LoggingConfig(BaseModel):\n    level: Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"]\n    format: str = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    file_path: Optional[str] = None\n\nclass AppConfig(BaseModel):\n    app_name: str\n    version: str\n    debug_mode: bool\n    database: DatabaseConfig\n    cache: CacheConfig\n    logging: LoggingConfig\n\ndef generate_config(requirements: str) -&gt; AppConfig:\n    llm = LLM.create(\"gpt-4o-mini\")\n\n    reply = llm.ask(\n        f\"\"\"\n        \ub2e4\uc74c \uc694\uad6c\uc0ac\ud56d\uc73c\ub85c \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \uc124\uc815\uc744 \uc0dd\uc131\ud558\uc138\uc694:\n\n        {requirements}\n\n        \ubaa8\ub4e0 \ud544\uc218 \uc124\uc815\uc744 \ud3ec\ud568\ud558\uace0 \ubcf4\uc548\uc744 \uace0\ub824\ud558\uc138\uc694.\n        \"\"\",\n        schema=AppConfig\n    )\n\n    return reply.structured_data\n\n# \uc0ac\uc6a9\nrequirements = \"\"\"\n- \ud504\ub85c\ub355\uc158 \ud658\uacbd\uc6a9 \uc6f9 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\n- PostgreSQL \ub370\uc774\ud130\ubca0\uc774\uc2a4 \uc0ac\uc6a9\n- Redis \uce90\uc2f1 \ud544\uc694\n- \uc5d0\ub7ec \ub808\ubca8 \ub85c\uae45\n\"\"\"\n\nconfig = generate_config(requirements)\nprint(f\"\uc571 \uc774\ub984: {config.app_name}\")\nprint(f\"DB \ud638\uc2a4\ud2b8: {config.database.host}\")\nprint(f\"\uce90\uc2dc \ud0c0\uc785: {config.cache.type}\")\n</code></pre>"},{"location":"guides/structured-output/#_15","title":"\uc5d0\ub7ec \ucc98\ub9ac\uc640 \uac80\uc99d","text":""},{"location":"guides/structured-output/#_16","title":"\uc2a4\ud0a4\ub9c8 \uac80\uc99d \uc2e4\ud328 \ucc98\ub9ac","text":"<pre><code>from pydantic import ValidationError\n\nclass StrictUserProfile(BaseModel):\n    name: str = Field(..., min_length=2, max_length=50)\n    age: int = Field(..., ge=18, le=100)\n    email: str = Field(..., regex=r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$')\n\ndef safe_parse_profile(text: str) -&gt; Optional[StrictUserProfile]:\n    llm = LLM.create(\"gpt-4o-mini\")\n\n    try:\n        reply = llm.ask(\n            f\"\ub2e4\uc74c\uc5d0\uc11c \uc0ac\uc6a9\uc790 \ud504\ub85c\ud544 \uc815\ubcf4\ub97c \ucd94\ucd9c\ud558\uc138\uc694: {text}\",\n            schema=StrictUserProfile\n        )\n        return reply.structured_data\n    except ValidationError as e:\n        print(f\"\uac80\uc99d \uc2e4\ud328: {e}\")\n\n        # \uc7ac\uc2dc\ub3c4 with \ud78c\ud2b8\n        retry_reply = llm.ask(\n            f\"\"\"\n            \ub2e4\uc74c\uc5d0\uc11c \uc0ac\uc6a9\uc790 \ud504\ub85c\ud544\uc744 \ucd94\ucd9c\ud558\uc138\uc694: {text}\n\n            \uc8fc\uc758\uc0ac\ud56d:\n            - \uc774\ub984\uc740 2-50\uc790\n            - \ub098\uc774\ub294 18-100\n            - \uc774\uba54\uc77c\uc740 \uc720\ud6a8\ud55c \ud615\uc2dd\n\n            \uac80\uc99d \uc5d0\ub7ec: {e}\n            \"\"\",\n            schema=StrictUserProfile\n        )\n        return retry_reply.structured_data\n    except Exception as e:\n        print(f\"\ud30c\uc2f1 \uc2e4\ud328: {e}\")\n        return None\n</code></pre>"},{"location":"guides/structured-output/#_17","title":"\ubd80\ubd84 \uc2a4\ud0a4\ub9c8 \ub9e4\uce6d","text":"<pre><code>from typing import Any\n\nclass PartialData(BaseModel):\n    class Config:\n        extra = \"allow\"  # \ucd94\uac00 \ud544\ub4dc \ud5c8\uc6a9\n\n    required_field: str\n    optional_field: Optional[str] = None\n\ndef extract_partial_data(text: str) -&gt; Dict[str, Any]:\n    llm = LLM.create(\"gpt-4o-mini\")\n\n    reply = llm.ask(\n        f\"\ub2e4\uc74c\uc5d0\uc11c \uac00\ub2a5\ud55c \ubaa8\ub4e0 \uc815\ubcf4\ub97c \ucd94\ucd9c\ud558\uc138\uc694: {text}\",\n        schema=PartialData\n    )\n\n    data = reply.structured_data\n    # \ubaa8\ub4e0 \ud544\ub4dc (extra \ud3ec\ud568) \uac00\uc838\uc624\uae30\n    all_data = data.model_dump()\n\n    return all_data\n</code></pre>"},{"location":"guides/structured-output/#_18","title":"\uc131\ub2a5 \ucd5c\uc801\ud654","text":""},{"location":"guides/structured-output/#_19","title":"\uc2a4\ud0a4\ub9c8 \uce90\uc2f1","text":"<pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=100)\ndef get_cached_schema(schema_name: str) -&gt; type[BaseModel]:\n    \"\"\"\uc790\uc8fc \uc0ac\uc6a9\ud558\ub294 \uc2a4\ud0a4\ub9c8 \uce90\uc2f1\"\"\"\n    schemas = {\n        \"person\": Person,\n        \"task\": Task,\n        \"article\": Article,\n    }\n    return schemas.get(schema_name)\n\n# Stateless \ubaa8\ub4dc\uc640 \ud568\uaed8 \uc0ac\uc6a9\nextractor = LLM.create(\"gpt-4o-mini\", stateless=True)\n\n# \ubc18\ubcf5 \uc791\uc5c5\uc5d0\uc11c \uc2a4\ud0a4\ub9c8 \uc7ac\uc0ac\uc6a9\nschema = get_cached_schema(\"person\")\nfor text in large_text_list:\n    reply = extractor.ask(f\"Extract: {text}\", schema=schema)\n    process_person(reply.structured_data)\n</code></pre>"},{"location":"guides/structured-output/#_20","title":"\ubc30\uce58 \ucc98\ub9ac","text":"<pre><code>async def batch_extract(texts: List[str], schema: type[BaseModel]):\n    \"\"\"\ube44\ub3d9\uae30 \ubc30\uce58 \ucc98\ub9ac\"\"\"\n    llm = LLM.create(\"gpt-4o-mini\", stateless=True)\n\n    tasks = []\n    for text in texts:\n        task = llm.ask_async(\n            f\"Extract information from: {text}\",\n            schema=schema\n        )\n        tasks.append(task)\n\n    results = await asyncio.gather(*tasks)\n    return [r.structured_data for r in results]\n\n# \uc0ac\uc6a9\ntexts = [\"\ubb38\uc11c1\", \"\ubb38\uc11c2\", \"\ubb38\uc11c3\", ...]\nextracted_data = asyncio.run(batch_extract(texts, DocumentAnalysis))\n</code></pre>"},{"location":"guides/structured-output/#_21","title":"\ubaa8\ubc94 \uc0ac\ub840","text":""},{"location":"guides/structured-output/#1","title":"1. \uba85\ud655\ud55c \ud544\ub4dc \uc124\uba85","text":"<pre><code>class WellDocumentedSchema(BaseModel):\n    \"\"\"\uc0ac\uc6a9\uc790 \uc8fc\ubb38 \uc815\ubcf4\"\"\"\n\n    order_id: str = Field(\n        ...,\n        description=\"\uc8fc\ubb38 \uace0\uc720 ID (\uc608: ORD-2024-001)\",\n        example=\"ORD-2024-001\"\n    )\n\n    total_amount: float = Field(\n        ...,\n        description=\"\ucd1d \uc8fc\ubb38 \uae08\uc561 (\uc6d0\ud654)\",\n        ge=0,\n        example=50000\n    )\n\n    items: List[str] = Field(\n        ...,\n        description=\"\uc8fc\ubb38\ud55c \uc0c1\ud488\uba85 \ubaa9\ub85d\",\n        min_items=1,\n        example=[\"\ub178\ud2b8\ubd81\", \"\ub9c8\uc6b0\uc2a4\"]\n    )\n</code></pre>"},{"location":"guides/structured-output/#2","title":"2. \uc810\uc9c4\uc801 \ubcf5\uc7a1\ub3c4","text":"<pre><code># \uac04\ub2e8\ud55c \uc2a4\ud0a4\ub9c8\ubd80\ud130 \uc2dc\uc791\nclass SimpleProduct(BaseModel):\n    name: str\n    price: float\n\n# \ud544\uc694\uc5d0 \ub530\ub77c \ud655\uc7a5\nclass DetailedProduct(SimpleProduct):\n    description: str\n    category: str\n    in_stock: bool\n\n# \ucd5c\uc885\uc801\uc73c\ub85c \ubcf5\uc7a1\ud55c \uc2a4\ud0a4\ub9c8\nclass FullProduct(DetailedProduct):\n    sku: str\n    manufacturer: Company\n    specifications: Dict[str, str]\n    reviews: List[Review]\n</code></pre>"},{"location":"guides/structured-output/#3","title":"3. \ud504\ub86c\ud504\ud2b8 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1","text":"<pre><code>def create_extraction_prompt(text: str, schema: type[BaseModel]) -&gt; str:\n    \"\"\"\uc2a4\ud0a4\ub9c8 \uae30\ubc18 \ud504\ub86c\ud504\ud2b8 \uc0dd\uc131\"\"\"\n\n    schema_description = schema.schema_json(indent=2)\n\n    return f\"\"\"\n    \ub2e4\uc74c \ud14d\uc2a4\ud2b8\uc5d0\uc11c \uc815\ubcf4\ub97c \ucd94\ucd9c\ud558\uc5ec JSON\uc73c\ub85c \ubcc0\ud658\ud558\uc138\uc694.\n\n    \ud14d\uc2a4\ud2b8:\n    {text}\n\n    \uc694\uad6c\ub418\ub294 JSON \uc2a4\ud0a4\ub9c8:\n    {schema_description}\n\n    \uaddc\uce59:\n    1. \uc815\ud655\ud788 \uc2a4\ud0a4\ub9c8\uc5d0 \ub9de\ucdb0 \ucd94\ucd9c\n    2. \ucc3e\uc744 \uc218 \uc5c6\ub294 \uc815\ubcf4\ub294 null \ub610\ub294 \uae30\ubcf8\uac12 \uc0ac\uc6a9\n    3. \ud0c0\uc785\uc744 \uc815\ud655\ud788 \ub9de\ucdb0\uc8fc\uc138\uc694\n    \"\"\"\n</code></pre>"},{"location":"guides/structured-output/#_22","title":"\ub2e4\uc74c \ub2e8\uacc4","text":"<ul> <li>\uace0\uae09 \uae30\ub2a5 - \uc2a4\ud2b8\ub9ac\ubc0d, \ube44\ub3d9\uae30, \uce90\uc2f1 \ub4f1</li> <li>API \ub808\ud37c\ub7f0\uc2a4 - \uc804\uccb4 API \ubb38\uc11c</li> <li>\uc608\uc81c - \uc2e4\uc81c \uc0ac\uc6a9 \uc0ac\ub840</li> </ul>"}]}