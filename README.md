# pyhub-llm

ë‹¤ì–‘í•œ LLM ì œê³µì—…ì²´ë¥¼ ìœ„í•œ í†µí•© Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. OpenAI, Anthropic, Google, Ollama ë“±ì˜ APIë¥¼ ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì£¼ìš” ê¸°ëŠ¥

- ğŸ”Œ **í†µí•© ì¸í„°í˜ì´ìŠ¤**: ëª¨ë“  LLM ì œê³µì—…ì²´ë¥¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©
- ğŸš€ **ê°„í¸í•œ ì „í™˜**: ì½”ë“œ ë³€ê²½ ì—†ì´ ëª¨ë¸ ì „í™˜ ê°€ëŠ¥
- ğŸ’¾ **ìºì‹± ì§€ì›**: ì‘ë‹µ ìºì‹±ìœ¼ë¡œ ë¹„ìš© ì ˆê° ë° ì„±ëŠ¥ í–¥ìƒ
- ğŸ”„ **ìŠ¤íŠ¸ë¦¬ë° ì§€ì›**: ì‹¤ì‹œê°„ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
- ğŸ› ï¸ **ë„êµ¬/í•¨ìˆ˜ í˜¸ì¶œ**: Function calling ì§€ì›
- ğŸ“· **ì´ë¯¸ì§€ ì²˜ë¦¬**: ì´ë¯¸ì§€ ì„¤ëª… ë° ë¶„ì„ ê¸°ëŠ¥
- âš¡ **ë¹„ë™ê¸° ì§€ì›**: ë™ê¸°/ë¹„ë™ê¸° ëª¨ë‘ ì§€ì›
- ğŸ”— **ì²´ì´ë‹**: ì—¬ëŸ¬ LLMì„ ì—°ê²°í•˜ì—¬ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° êµ¬ì„±

## ì„¤ì¹˜

### ê¸°ë³¸ ì„¤ì¹˜

```bash
pip install pyhub-llm
```

### íŠ¹ì • ì œê³µì—…ì²´ë§Œ ì„¤ì¹˜

```bash
# OpenAIë§Œ
pip install "pyhub-llm[openai]"

# Anthropicë§Œ
pip install "pyhub-llm[anthropic]"

# ëª¨ë“  ì œê³µì—…ì²´
pip install "pyhub-llm[all]"
```

### ê°œë°œ í™˜ê²½ ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/pyhub-kr/pyhub-llm.git
cd pyhub-llm

# ê°œë°œ í™˜ê²½ ì„¤ì¹˜
pip install -e ".[dev,all]"
# í˜¹ì€ make install
```

## ë¹ ë¥¸ ì‹œì‘

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from pyhub.llm import LLM

# LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
llm = LLM.create("gpt-4o-mini")

# ì§ˆë¬¸í•˜ê¸°
reply = llm.ask("Pythonì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?")
print(reply.text)
```

### ëª¨ë¸ë³„ ì§ì ‘ ì‚¬ìš©

ê° í”„ë¡œë°”ì´ë”ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ í•´ë‹¹ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¨¼ì € ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:

```bash
# OpenAI ì‚¬ìš©ì‹œ
pip install "pyhub-llm[openai]"

# Anthropic ì‚¬ìš©ì‹œ
pip install "pyhub-llm[anthropic]"

# Google ì‚¬ìš©ì‹œ
pip install "pyhub-llm[google]"

# Ollama ì‚¬ìš©ì‹œ (ë¡œì»¬ ì‹¤í–‰)
pip install "pyhub-llm[ollama]"
```

```python
from pyhub.llm import OpenAILLM, AnthropicLLM, GoogleLLM

# OpenAI (OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”)
openai_llm = OpenAILLM(model="gpt-4o-mini")
reply = openai_llm.ask("ì•ˆë…•í•˜ì„¸ìš”!")

# API í‚¤ ì§ì ‘ ì „ë‹¬
openai_llm = OpenAILLM(model="gpt-4o-mini", api_key="your-api-key")

# Anthropic (ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”)
claude_llm = AnthropicLLM(model="claude-3-haiku-20240307")
reply = claude_llm.ask("ì•ˆë…•í•˜ì„¸ìš”!")

# Google (GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”)
gemini_llm = GoogleLLM(model="gemini-1.5-flash")
reply = gemini_llm.ask("ì•ˆë…•í•˜ì„¸ìš”!")
```

## ì£¼ìš” ê¸°ëŠ¥ ì˜ˆì œ

### 1. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ

```python
# ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°
for chunk in llm.ask("ê¸´ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”", stream=True):
    print(chunk.text, end="", flush=True)

# ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°
async for chunk in await llm.ask_async("ê¸´ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”", stream=True):
    print(chunk.text, end="", flush=True)
```

### 2. ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬

```python
# ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
llm = LLM.create("gpt-4o-mini")

# ì²« ë²ˆì§¸ ì§ˆë¬¸
llm.ask("ì œ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤", use_history=True)

# ë‘ ë²ˆì§¸ ì§ˆë¬¸ (ì´ì „ ëŒ€í™” ê¸°ì–µ)
reply = llm.ask("ì œ ì´ë¦„ì´ ë­ë¼ê³  í–ˆì£ ?", use_history=True)
print(reply.text)  # "ê¹€ì² ìˆ˜ë¼ê³  í•˜ì…¨ìŠµë‹ˆë‹¤"

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
llm.clear()
```

### 3. ì´ë¯¸ì§€ ì²˜ë¦¬

```python
# ë‹¨ì¼ ì´ë¯¸ì§€ ì„¤ëª…
reply = llm.describe_image("photo.jpg")
print(reply.text)

# ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ ë¶„ì„
reply = llm.describe_image(
    "photo.jpg",
    prompt="ì´ ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ìƒ‰ìƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
)

# ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ì²˜ë¦¬
responses = llm.describe_images([
    "image1.jpg",
    "image2.jpg",
    "image3.jpg"
])

# ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
text = llm.extract_text_from_image("document.jpg")
```

### 4. ì„ íƒì§€ ì œí•œ

```python
# ì„ íƒì§€ ì¤‘ì—ì„œë§Œ ì‘ë‹µ
reply = llm.ask(
    "ì´ ë¦¬ë·°ì˜ ê°ì •ì€?",
    context={"review": "ì •ë§ ìµœê³ ì˜ ì œí’ˆì…ë‹ˆë‹¤!"},
    choices=["ê¸ì •", "ë¶€ì •", "ì¤‘ë¦½"]
)
print(reply.choice)  # "ê¸ì •"
print(reply.confidence)  # 0.95
```

### 5. ë„êµ¬/í•¨ìˆ˜ í˜¸ì¶œ

```python
from pyhub.llm.tools import Tool

# ë„êµ¬ ì •ì˜
def get_weather(city: str) -> str:
    return f"{city}ì˜ ë‚ ì”¨ëŠ” ë§‘ìŒì…ë‹ˆë‹¤."

weather_tool = Tool(
    name="get_weather",
    description="ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤",
    func=get_weather,
    parameters={
        "type": "object",
        "properties": {
            "city": {"type": "string", "description": "ë„ì‹œ ì´ë¦„"}
        },
        "required": ["city"]
    }
)

# ë„êµ¬ì™€ í•¨ê»˜ LLM ì‚¬ìš©
reply = llm.ask(
    "ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì–´ë•Œ?",
    tools=[weather_tool]
)
print(reply.text)  # "ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ë§‘ìŒì…ë‹ˆë‹¤."
```

### 6. LLM ì²´ì´ë‹

```python
# ë²ˆì—­ ì²´ì¸ êµ¬ì„±
translator = LLM.create(
    "gpt-4o-mini",
    prompt="ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”: {text}"
)

summarizer = LLM.create(
    "gpt-4o-mini",
    prompt="ë‹¤ìŒ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”: {text}"
)

# ì²´ì¸ ì—°ê²°
chain = translator | summarizer

# ì‹¤í–‰
result = chain.ask({"text": "ì¸ê³µì§€ëŠ¥ì€ ìš°ë¦¬ì˜ ë¯¸ë˜ë¥¼ ë°”ê¿€ ê²ƒì…ë‹ˆë‹¤..."})
print(result.values["text"])  # ë²ˆì—­ í›„ ìš”ì•½ëœ ê²°ê³¼
```

### 7. ìºì‹± ì‚¬ìš©

```python
# ìºì‹± í™œì„±í™”
reply = llm.ask("ë³µì¡í•œ ì§ˆë¬¸...", enable_cache=True)

# ê°™ì€ ì§ˆë¬¸ ì¬ìš”ì²­ì‹œ ìºì‹œì—ì„œ ë°˜í™˜ (ë¹ ë¥´ê³  ë¹„ìš© ì—†ìŒ)
cached_response = llm.ask("ë³µì¡í•œ ì§ˆë¬¸...", enable_cache=True)
```

### 8. í…œí”Œë¦¿ ì‚¬ìš©

```python
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
llm = LLM.create(
    "gpt-4o-mini",
    system_prompt="ë‹¹ì‹ ì€ {role}ì…ë‹ˆë‹¤.",
    prompt="ì§ˆë¬¸: {question}\në‹µë³€:"
)

# í…œí”Œë¦¿ ë³€ìˆ˜ì™€ í•¨ê»˜ ì‚¬ìš©
reply = llm.ask({
    "role": "ìˆ˜í•™ êµì‚¬",
    "question": "í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ë€?"
})
```

## API í‚¤ ì„¤ì •

### í•„ìš”í•œ API í‚¤

ê° í”„ë¡œë°”ì´ë”ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ í•´ë‹¹ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤:

- **OpenAI**: `OPENAI_API_KEY` - [API í‚¤ ë°œê¸‰](https://platform.openai.com/api-keys)
- **Anthropic**: `ANTHROPIC_API_KEY` - [API í‚¤ ë°œê¸‰](https://console.anthropic.com/settings/keys)
- **Google**: `GOOGLE_API_KEY` - [API í‚¤ ë°œê¸‰](https://makersuite.google.com/app/apikey)
- **Upstage**: `UPSTAGE_API_KEY` - [API í‚¤ ë°œê¸‰](https://console.upstage.ai/)

### ì„¤ì • ë°©ë²•

#### 1. í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •
```bash
export OPENAI_API_KEY="your-openai-key"
export ANTHROPIC_API_KEY="your-anthropic-key"
export GOOGLE_API_KEY="your-google-key"
```

#### 2. .env íŒŒì¼ ì‚¬ìš©
```bash
# .env íŒŒì¼ ìƒì„±
OPENAI_API_KEY=your-openai-key
ANTHROPIC_API_KEY=your-anthropic-key
GOOGLE_API_KEY=your-google-key
```

#### 3. ì½”ë“œì—ì„œ ì§ì ‘ ì „ë‹¬
```python
from pyhub.llm import OpenAILLM, AnthropicLLM, GoogleLLM

# API í‚¤ë¥¼ ì§ì ‘ ì „ë‹¬
llm = OpenAILLM(api_key="your-api-key")
llm = AnthropicLLM(api_key="your-api-key")
llm = GoogleLLM(api_key="your-api-key")
```

## í™˜ê²½ ì„¤ì •

### pyproject.toml ì„¤ì •

```toml
[tool.pyhub.llm]
# ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
default_model = "gpt-4o-mini"
default_embedding_model = "text-embedding-3-small"

# ê¸°ë³¸ íŒŒë¼ë¯¸í„°
temperature = 0.7
max_tokens = 1000

# ìºì‹œ ì„¤ì •
cache_ttl = 3600
cache_dir = ".cache/llm"
```

## CLI ì‚¬ìš©ë²•

### ëŒ€í™”í˜• ì±„íŒ…
```bash
# ê¸°ë³¸ ëª¨ë¸ë¡œ ì±„íŒ…
pyhub-llm chat

# íŠ¹ì • ëª¨ë¸ë¡œ ì±„íŒ…
pyhub-llm chat --model claude-3-haiku-20240307

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
pyhub-llm chat --system "ë‹¹ì‹ ì€ íŒŒì´ì¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤"
```

### ë‹¨ì¼ ì§ˆë¬¸
```bash
# ì§ˆë¬¸í•˜ê³  ì‘ë‹µ ë°›ê¸°
pyhub-llm ask "Pythonê³¼ Goì˜ ì°¨ì´ì ì€?"

# íŒŒì¼ ë‚´ìš©ê³¼ í•¨ê»˜ ì§ˆë¬¸
pyhub-llm ask "ì´ ì½”ë“œë¥¼ ë¦¬ë·°í•´ì£¼ì„¸ìš”" --file main.py
```

### ì´ë¯¸ì§€ ì„¤ëª…
```bash
# ì´ë¯¸ì§€ ì„¤ëª…
pyhub-llm describe image.jpg

# ì—¬ëŸ¬ ì´ë¯¸ì§€ ì„¤ëª…
pyhub-llm describe *.jpg --output descriptions.json
```

### ì„ë² ë”© ìƒì„±
```bash
# í…ìŠ¤íŠ¸ ì„ë² ë”©
pyhub-llm embed "ì„ë² ë”©í•  í…ìŠ¤íŠ¸"

# íŒŒì¼ ë‚´ìš© ì„ë² ë”©
pyhub-llm embed --file document.txt
```

## ê³ ê¸‰ ê¸°ëŠ¥

### ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬

```python
from pyhub.llm.agents import ReactAgent
from pyhub.llm.tools import WebSearchTool, CalculatorTool

# ë„êµ¬ë¥¼ ê°€ì§„ ì—ì´ì „íŠ¸ ìƒì„±
agent = ReactAgent(
    llm=LLM.create("gpt-4o"),
    tools=[WebSearchTool(), CalculatorTool()],
    max_iterations=5
)

# ë³µì¡í•œ ì‘ì—… ìˆ˜í–‰
result = agent.run(
    "2024ë…„ í•œêµ­ì˜ GDPëŠ” ì–¼ë§ˆì´ê³ , "
    "ì´ë¥¼ ì›í™”ë¡œ í™˜ì‚°í•˜ë©´ ì–¼ë§ˆì¸ê°€ìš”?"
)
```

### MCP (Model Context Protocol) í†µí•©

```python
from pyhub.llm.agents.mcp import MCPClient

# MCP ì„œë²„ ì—°ê²°
mcp_client = MCPClient("localhost:8080")

# MCP ë„êµ¬ë¥¼ LLMê³¼ í•¨ê»˜ ì‚¬ìš©
llm = LLM.create("gpt-4o", tools=mcp_client.get_tools())
reply = llm.ask("í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”")
```

## ê°œë°œ

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ëª¨ë“  í…ŒìŠ¤íŠ¸
make test

# íŠ¹ì • í…ŒìŠ¤íŠ¸
make test tests/test_openai.py

# ì»¤ë²„ë¦¬ì§€ í¬í•¨ í…ŒìŠ¤íŠ¸
make test-cov
# ë˜ëŠ”
make cov

# ì»¤ë²„ë¦¬ì§€ HTML ë¦¬í¬íŠ¸ ë³´ê¸°
make test-cov-report

# íŠ¹ì • íŒŒì¼ë§Œ ì»¤ë²„ë¦¬ì§€ í…ŒìŠ¤íŠ¸
make cov tests/test_optional_dependencies.py

# pytest ì§ì ‘ ì‹¤í–‰
pytest --cov=src/pyhub/llm --cov-report=term --cov-report=html
```

### ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬

```bash
# í¬ë§·íŒ… ë° ë¦°íŒ…
make format
make lint

# íƒ€ì… ì²´í¬
mypy src/
```

### ë¹Œë“œ ë° ë°°í¬

```bash
# íŒ¨í‚¤ì§€ ë¹Œë“œ
make build

# PyPI ë°°í¬ (ê¶Œí•œ í•„ìš”)
make release
```

## ê¸°ì—¬í•˜ê¸°

1. ì´ ì €ì¥ì†Œë¥¼ í¬í¬í•©ë‹ˆë‹¤
2. ê¸°ëŠ¥ ë¸Œëœì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (`git checkout -b feature/amazing-feature`)
3. ë³€ê²½ì‚¬í•­ì„ ì»¤ë°‹í•©ë‹ˆë‹¤ (`git commit -m 'Add amazing feature'`)
4. ë¸Œëœì¹˜ì— í‘¸ì‹œí•©ë‹ˆë‹¤ (`git push origin feature/amazing-feature`)
5. Pull Requestë¥¼ ìƒì„±í•©ë‹ˆë‹¤

### ê¸°ì—¬ ê°€ì´ë“œë¼ì¸

- ëª¨ë“  ìƒˆ ê¸°ëŠ¥ì—ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”
- ì½”ë“œ ìŠ¤íƒ€ì¼ì€ Blackê³¼ Ruffë¥¼ ë”°ë¦…ë‹ˆë‹¤
- íƒ€ì… íŒíŠ¸ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”
- ë¬¸ì„œë¥¼ ì—…ë°ì´íŠ¸í•´ì£¼ì„¸ìš”

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

**Q: API í‚¤ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤**

```python
# í•´ê²° ë°©ë²• 1: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
import os
os.environ["OPENAI_API_KEY"] = "your-key"

# í•´ê²° ë°©ë²• 2: ì§ì ‘ ì „ë‹¬
llm = OpenAILLM(api_key="your-key")
```

**Q: ì†ë„ê°€ ëŠë¦½ë‹ˆë‹¤**

```python
# ìºì‹± í™œì„±í™”
reply = llm.ask("...", enable_cache=True)

# ë” ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©
llm = LLM.create("gpt-3.5-turbo")
```

**Q: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤**

```python
# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì œí•œ
llm = LLM.create(
    "gpt-4o-mini",
    initial_messages=[]  # íˆìŠ¤í† ë¦¬ ì—†ì´ ì‹œì‘
)

# ì£¼ê¸°ì ìœ¼ë¡œ íˆìŠ¤í† ë¦¬ ì •ë¦¬
if len(llm) > 10:
    llm.clear()
```

## ë§í¬

- [ë¬¸ì„œ](https://pyhub-llm.readthedocs.io)
- [PyPI](https://pypi.org/project/pyhub-llm)
- [GitHub](https://github.com/pyhub-kr/pyhub-llm)
- [ì´ìŠˆ íŠ¸ë˜ì»¤](https://github.com/pyhub-kr/pyhub-llm/issues)

