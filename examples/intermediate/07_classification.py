#!/usr/bin/env python3
"""
ì˜ˆì œ: ë¶„ë¥˜ ë° ì„ íƒ
ë‚œì´ë„: ì¤‘ê¸‰
ì„¤ëª…: LLMì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ë¶„ë¥˜, ê°ì • ë¶„ì„, ì˜ë„ íŒŒì•…
ìš”êµ¬ì‚¬í•­:
  - pyhub-llm (pip install "pyhub-llm[all]")
  - OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜

ì˜ˆì œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ me@pyhub.krë¡œ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤.
"""

import json
import os
import sys

from pyhub.llm import LLM


def example_sentiment_analysis():
    """ê°ì • ë¶„ì„ ì˜ˆì œ"""
    print("\nğŸ˜Š ê°ì • ë¶„ì„")
    print("-" * 50)

    llm = LLM.create("gpt-4o-mini")

    # ë¶„ì„í•  í…ìŠ¤íŠ¸ë“¤
    texts = [
        "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„ìš”! ìµœê³ ì˜ í•˜ë£¨ì˜€ìŠµë‹ˆë‹¤.",
        "ì´ ì œí’ˆ ì •ë§ ì‹¤ë§ìŠ¤ëŸ½ë„¤ìš”. ëˆì´ ì•„ê¹ìŠµë‹ˆë‹¤.",
        "ê·¸ëƒ¥ í‰ë²”í•œ í•˜ë£¨ì˜€ì–´ìš”. íŠ¹ë³„í•œ ì¼ì€ ì—†ì—ˆìŠµë‹ˆë‹¤.",
        "ì²˜ìŒì—” ë³„ë¡œì˜€ëŠ”ë° ì“°ë‹¤ë³´ë‹ˆ ê´œì°®ë„¤ìš”. ë‚˜ì˜ì§€ ì•Šì•„ìš”.",
        "ì™€! ëŒ€ë°•! ì´ëŸ° ê±´ ì²˜ìŒ ë´ìš”! ì™„ì „ ê°•ì¶”!",
    ]

    print("í…ìŠ¤íŠ¸ë³„ ê°ì • ë¶„ì„ ê²°ê³¼:\n")

    for text in texts:
        # choices íŒŒë¼ë¯¸í„°ë¡œ ê°ì • ë¶„ë¥˜
        prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ì„¸ìš”: '{text}'"

        # ë‹¨ìˆœ ë¶„ë¥˜
        reply = llm.ask(prompt, choices=["ê¸ì •", "ë¶€ì •", "ì¤‘ë¦½"])

        print(f"í…ìŠ¤íŠ¸: {text}")
        print(f"ê°ì •: {reply.choice}")

        # ìƒì„¸ ë¶„ì„ (JSON í˜•ì‹)
        detailed_prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ìƒì„¸íˆ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
í…ìŠ¤íŠ¸: {text}

í˜•ì‹:
{{
    "sentiment": "ê¸ì •/ë¶€ì •/ì¤‘ë¦½",
    "confidence": 0.0-1.0,
    "emotions": ["ê°ì •1", "ê°ì •2"],
    "intensity": "ì•½í•¨/ë³´í†µ/ê°•í•¨"
}}
"""

        detailed_reply = llm.ask(detailed_prompt)
        try:
            analysis = json.loads(detailed_reply.text)
            print(f"ìƒì„¸ ë¶„ì„: {analysis}")
        except json.JSONDecodeError:
            print(f"ìƒì„¸ ë¶„ì„: {detailed_reply.text[:100]}")

        print("-" * 30)


def example_intent_classification():
    """ì˜ë„ ë¶„ë¥˜ ì˜ˆì œ"""
    print("\nğŸ¯ ì˜ë„ ë¶„ë¥˜")
    print("-" * 50)

    llm = LLM.create("gpt-4o-mini")

    # ê³ ê° ë¬¸ì˜ ì˜ˆì‹œ
    customer_queries = [
        "ì´ ì œí’ˆ í™˜ë¶ˆí•˜ê³  ì‹¶ì€ë°ìš”",
        "ë°°ì†¡ì´ ì–¸ì œì¯¤ ë„ì°©í•˜ë‚˜ìš”?",
        "ì œí’ˆ ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
        "ê°€ê²© í• ì¸ì€ ì•ˆ ë˜ë‚˜ìš”?",
        "A/S ì‹ ì²­í•˜ë ¤ê³  í•˜ëŠ”ë°ìš”",
        "ë‹¤ë¥¸ ìƒ‰ìƒë„ ìˆë‚˜ìš”?",
        "ëŒ€ëŸ‰ êµ¬ë§¤ ì‹œ í• ì¸ ê°€ëŠ¥í•œê°€ìš”?",
    ]

    # ì˜ë„ ì¹´í…Œê³ ë¦¬
    intent_categories = ["í™˜ë¶ˆ/ë°˜í’ˆ", "ë°°ì†¡ë¬¸ì˜", "ì‚¬ìš©ë°©ë²•", "ê°€ê²©ë¬¸ì˜", "A/Sìš”ì²­", "ì œí’ˆì •ë³´", "êµ¬ë§¤ìƒë‹´", "ê¸°íƒ€"]

    print("ê³ ê° ë¬¸ì˜ ì˜ë„ ë¶„ë¥˜:\n")

    for query in customer_queries:
        reply = llm.ask(f"ë‹¤ìŒ ê³ ê° ë¬¸ì˜ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”: '{query}'", choices=intent_categories)

        print(f"ë¬¸ì˜: {query}")
        print(f"ì˜ë„: {reply.choice}")

        # ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
        info_prompt = f"""
ê³ ê° ë¬¸ì˜: {query}

ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
{{
    "intent": "ì£¼ìš” ì˜ë„",
    "urgency": "ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ",
    "sentiment": "ê¸ì •/ì¤‘ë¦½/ë¶€ì •",
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
}}
"""

        info_reply = llm.ask(info_prompt)
        try:
            info = json.loads(info_reply.text)
            print(
                f"ì¶”ê°€ ì •ë³´: ê¸´ê¸‰ë„={info.get('urgency', 'N/A')}, "
                f"ê°ì •={info.get('sentiment', 'N/A')}, "
                f"í‚¤ì›Œë“œ={info.get('keywords', [])}"
            )
        except json.JSONDecodeError:
            pass

        print("-" * 30)


def example_topic_classification():
    """ì£¼ì œ ë¶„ë¥˜ ì˜ˆì œ"""
    print("\nğŸ“š ì£¼ì œ ë¶„ë¥˜")
    print("-" * 50)

    llm = LLM.create("gpt-4o-mini")

    # ë‰´ìŠ¤ í—¤ë“œë¼ì¸
    headlines = [
        "ì½”ìŠ¤í”¼ 3000 ëŒíŒŒ, ì™¸êµ­ì¸ ë§¤ìˆ˜ì„¸ ì§€ì†",
        "íŒŒì´ì¬ 3.13 ë¦´ë¦¬ì¦ˆ, ì„±ëŠ¥ 50% í–¥ìƒ",
        "ì†í¥ë¯¼ ì‹œì¦Œ 15í˜¸ê³¨, íŒ€ ìŠ¹ë¦¬ ê²¬ì¸",
        "ì„œìš¸ ì•„íŒŒíŠ¸ê°’ 0.5% ìƒìŠ¹, ì „ì„¸ëŠ” í•˜ë½",
        "ì• í”Œ ë¹„ì „í”„ë¡œ êµ­ë‚´ ì¶œì‹œ ì„ë°•",
        "ê¸°í›„ë³€í™”ë¡œ ë¶ê·¹ê³° ì„œì‹ì§€ 30% ê°ì†Œ",
    ]

    # ì£¼ì œ ì¹´í…Œê³ ë¦¬
    topics = ["ê²½ì œ", "ê¸°ìˆ ", "ìŠ¤í¬ì¸ ", "ë¶€ë™ì‚°", "í™˜ê²½", "ì •ì¹˜", "ì‚¬íšŒ", "ë¬¸í™”"]

    print("ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ì£¼ì œ ë¶„ë¥˜:\n")

    results = []
    for headline in headlines:
        # ë‹¨ì¼ ì£¼ì œ ë¶„ë¥˜
        reply = llm.ask(f"ë‹¤ìŒ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì˜ ì£¼ì œë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”: '{headline}'", choices=topics)

        results.append({"headline": headline, "topic": reply.choice})

        print(f"ğŸ“° {headline}")
        print(f"   â†’ ì£¼ì œ: {reply.choice}")

    # ì£¼ì œë³„ í†µê³„
    print("\nğŸ“Š ì£¼ì œë³„ ë¶„í¬:")
    topic_count = {}
    for result in results:
        topic = result["topic"]
        topic_count[topic] = topic_count.get(topic, 0) + 1

    for topic, count in sorted(topic_count.items(), key=lambda x: x[1], reverse=True):
        print(f"  - {topic}: {count}ê±´")


def example_multi_label_classification():
    """ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜ ì˜ˆì œ"""
    print("\nğŸ·ï¸ ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜")
    print("-" * 50)

    llm = LLM.create("gpt-4o-mini")

    # ì˜í™” ì„¤ëª…
    movies = [
        {
            "title": "ì¸í„°ìŠ¤í…”ë¼",
            "description": "ì§€êµ¬ì˜ ë¯¸ë˜ë¥¼ ìœ„í•´ ìš°ì£¼ë¡œ ë– ë‚˜ëŠ” ê³¼í•™ìë“¤ì˜ ì´ì•¼ê¸°. ê°€ì¡±ì• ì™€ ì‹œê°„ì˜ ì˜ë¯¸ë¥¼ ë‹¤ë£¬ë‹¤.",
        },
        {
            "title": "ê¸°ìƒì¶©",
            "description": "ë°˜ì§€í•˜ì— ì‚¬ëŠ” ê°€ë‚œí•œ ê°€ì¡±ì´ ë¶€ìœ í•œ ê°€ì¡±ì˜ ì‚¶ì— ì¹¨íˆ¬í•˜ëŠ” ë¸”ë™ ì½”ë¯¸ë”” ìŠ¤ë¦´ëŸ¬.",
        },
        {
            "title": "ë¼ë¼ëœë“œ",
            "description": "LAì—ì„œ ê¿ˆì„ ì«“ëŠ” ì¬ì¦ˆ í”¼ì•„ë‹ˆìŠ¤íŠ¸ì™€ ë°°ìš° ì§€ë§ìƒì˜ ì‚¬ë‘ ì´ì•¼ê¸°ë¥¼ ê·¸ë¦° ë®¤ì§€ì»¬.",
        },
    ]

    # ê°€ëŠ¥í•œ ì¥ë¥´ë“¤
    all_genres = [
        "ì•¡ì…˜",
        "ë“œë¼ë§ˆ",
        "ì½”ë¯¸ë””",
        "ë¡œë§¨ìŠ¤",
        "SF",
        "íŒíƒ€ì§€",
        "ìŠ¤ë¦´ëŸ¬",
        "ê³µí¬",
        "ë®¤ì§€ì»¬",
        "ë‹¤íë©˜í„°ë¦¬",
        "ê°€ì¡±",
        "ëª¨í—˜",
    ]

    print("ì˜í™” ì¥ë¥´ ë¶„ë¥˜ (ë³µìˆ˜ ì„ íƒ):\n")

    for movie in movies:
        prompt = f"""
ë‹¤ìŒ ì˜í™”ì˜ ì¥ë¥´ë¥¼ ëª¨ë‘ ì„ íƒí•˜ì—¬ JSON ë°°ì—´ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
ê°€ëŠ¥í•œ ì¥ë¥´: {', '.join(all_genres)}

ì˜í™”: {movie['title']}
ì„¤ëª…: {movie['description']}

ì„ íƒëœ ì¥ë¥´ë§Œ JSON ë°°ì—´ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆ: ["ë“œë¼ë§ˆ", "ë¡œë§¨ìŠ¤"]
"""

        reply = llm.ask(prompt)

        try:
            genres = json.loads(reply.text)
            print(f"ğŸ¬ {movie['title']}")
            print(f"   ì¥ë¥´: {', '.join(genres)}")

            # ì£¼ìš” ì¥ë¥´ ê²°ì •
            main_genre_prompt = f"ì˜í™” '{movie['title']}'ì˜ ê°€ì¥ ì£¼ìš”í•œ ì¥ë¥´ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì„¸ìš”."
            main_reply = llm.ask(main_genre_prompt, choices=genres)
            print(f"   ì£¼ìš” ì¥ë¥´: {main_reply.choice}")

        except json.JSONDecodeError:
            print(f"ğŸ¬ {movie['title']}")
            print("   ì¥ë¥´ ë¶„ì„ ì‹¤íŒ¨")

        print("-" * 30)


def example_confidence_scoring():
    """ì‹ ë¢°ë„ ì ìˆ˜ í¬í•¨ ë¶„ë¥˜"""
    print("\nğŸ“Š ì‹ ë¢°ë„ ì ìˆ˜ í¬í•¨ ë¶„ë¥˜")
    print("-" * 50)

    llm = LLM.create("gpt-4o-mini")

    # ì• ë§¤í•œ í…ìŠ¤íŠ¸ë“¤
    ambiguous_texts = [
        "ìŒ... ê¸€ì„ìš”. ë‚˜ì˜ì§„ ì•Šì€ë° ê·¸ë ‡ë‹¤ê³  ì¢‹ì§€ë„ ì•Šë„¤ìš”.",
        "ì™„ì „ ìµœê³ ! ë‹¤ì‹œëŠ” ì•ˆ ì‚´ ê±°ì˜ˆìš”!",  # ëª¨ìˆœì 
        "ê°€ê²©ëŒ€ë¹„ í›Œë¥­í•©ë‹ˆë‹¤.",
        "ì¡°ê¸ˆ ì•„ì‰½ì§€ë§Œ ë§Œì¡±í•©ë‹ˆë‹¤.",
        "?",  # ë§¤ìš° ì• ë§¤í•œ ê²½ìš°
    ]

    print("ì• ë§¤í•œ í…ìŠ¤íŠ¸ì˜ ê°ì • ë¶„ì„ (ì‹ ë¢°ë„ í¬í•¨):\n")

    for text in ambiguous_texts:
        prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³  ì‹ ë¢°ë„ë¥¼ í¬í•¨í•˜ì—¬ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
í…ìŠ¤íŠ¸: "{text}"

í˜•ì‹:
{{
    "sentiment": "ê¸ì •/ë¶€ì •/ì¤‘ë¦½",
    "confidence": 0.0-1.0,
    "reasoning": "íŒë‹¨ ê·¼ê±°",
    "alternative": "ëŒ€ì•ˆ í•´ì„ (ìˆëŠ” ê²½ìš°)"
}}
"""

        reply = llm.ask(prompt)

        try:
            result = json.loads(reply.text)
            print(f"í…ìŠ¤íŠ¸: {text}")
            print(f"ë¶„ë¥˜: {result['sentiment']} (ì‹ ë¢°ë„: {result['confidence']})")
            print(f"ê·¼ê±°: {result['reasoning']}")
            if result.get("alternative"):
                print(f"ëŒ€ì•ˆ: {result['alternative']}")
        except json.JSONDecodeError:
            print(f"í…ìŠ¤íŠ¸: {text}")
            print("ë¶„ì„ ì‹¤íŒ¨")

        print("-" * 30)


def example_hierarchical_classification():
    """ê³„ì¸µì  ë¶„ë¥˜ ì˜ˆì œ"""
    print("\nğŸŒ³ ê³„ì¸µì  ë¶„ë¥˜")
    print("-" * 50)

    llm = LLM.create("gpt-4o-mini")

    # ì œí’ˆ ì„¤ëª…
    products = [
        "ì‚¼ì„± ê°¤ëŸ­ì‹œ S24 ìš¸íŠ¸ë¼ 256GB ë¸”ë™",
        "ë‚˜ì´í‚¤ ì—ì–´ë§¥ìŠ¤ 270 ëŸ°ë‹í™” í™”ì´íŠ¸",
        "LG ì˜¬ë ˆë“œ TV 65ì¸ì¹˜ 4K",
        "ì•„ì´íŒ¨ë“œ í”„ë¡œ 12.9 M2 ì™€ì´íŒŒì´ ëª¨ë¸",
        "ë‹¤ì´ìŠ¨ V15 ë¬´ì„ ì²­ì†Œê¸°",
    ]

    print("ì œí’ˆ ê³„ì¸µì  ë¶„ë¥˜:\n")

    for product in products:
        # 1ë‹¨ê³„: ëŒ€ë¶„ë¥˜
        major_categories = ["ì „ìì œí’ˆ", "ì˜ë¥˜/ì‹ ë°œ", "ê°€ì „ì œí’ˆ", "ê°€êµ¬", "ì‹í’ˆ"]
        reply1 = llm.ask(f"ì œí’ˆ '{product}'ì˜ ëŒ€ë¶„ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.", choices=major_categories)
        major = reply1.choice

        # 2ë‹¨ê³„: ì¤‘ë¶„ë¥˜ (ëŒ€ë¶„ë¥˜ì— ë”°ë¼ ë‹¤ë¦„)
        if major == "ì „ìì œí’ˆ":
            sub_categories = ["ìŠ¤ë§ˆíŠ¸í°", "íƒœë¸”ë¦¿", "ë…¸íŠ¸ë¶", "ì¹´ë©”ë¼", "ê¸°íƒ€"]
        elif major == "ì˜ë¥˜/ì‹ ë°œ":
            sub_categories = ["ìš´ë™í™”", "êµ¬ë‘", "ì˜ë¥˜", "ì•¡ì„¸ì„œë¦¬", "ê¸°íƒ€"]
        elif major == "ê°€ì „ì œí’ˆ":
            sub_categories = ["TV", "ëƒ‰ì¥ê³ ", "ì„¸íƒê¸°", "ì²­ì†Œê¸°", "ì£¼ë°©ê°€ì „"]
        else:
            sub_categories = ["ê¸°íƒ€"]

        reply2 = llm.ask(f"ì œí’ˆ '{product}'ì˜ ì¤‘ë¶„ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.", choices=sub_categories)

        print(f"ğŸ“¦ {product}")
        print(f"   ëŒ€ë¶„ë¥˜: {major}")
        print(f"   ì¤‘ë¶„ë¥˜: {reply2.choice}")

        # ì¶”ê°€ ì†ì„± ì¶”ì¶œ
        attr_prompt = f"""
ì œí’ˆ '{product}'ì˜ ì£¼ìš” ì†ì„±ì„ ì¶”ì¶œí•˜ì—¬ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
{{
    "brand": "ë¸Œëœë“œëª…",
    "model": "ëª¨ë¸ëª…",
    "key_features": ["íŠ¹ì§•1", "íŠ¹ì§•2"]
}}
"""
        attr_reply = llm.ask(attr_prompt)
        try:
            attrs = json.loads(attr_reply.text)
            print(f"   ë¸Œëœë“œ: {attrs.get('brand', 'N/A')}")
            print(f"   íŠ¹ì§•: {', '.join(attrs.get('key_features', []))}")
        except json.JSONDecodeError:
            pass

        print("-" * 30)


def main():
    """ë¶„ë¥˜ ì˜ˆì œ ë©”ì¸ í•¨ìˆ˜"""

    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

    print("ğŸ·ï¸ ë¶„ë¥˜ ë° ì„ íƒ ì˜ˆì œ")
    print("=" * 50)

    try:
        # 1. ê°ì • ë¶„ì„
        example_sentiment_analysis()

        # 2. ì˜ë„ ë¶„ë¥˜
        example_intent_classification()

        # 3. ì£¼ì œ ë¶„ë¥˜
        example_topic_classification()

        # 4. ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜
        example_multi_label_classification()

        # 5. ì‹ ë¢°ë„ ì ìˆ˜
        example_confidence_scoring()

        # 6. ê³„ì¸µì  ë¶„ë¥˜
        example_hierarchical_classification()

        print("\nâœ… ëª¨ë“  ë¶„ë¥˜ ì˜ˆì œ ì™„ë£Œ!")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
