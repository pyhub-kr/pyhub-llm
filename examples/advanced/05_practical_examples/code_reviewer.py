#!/usr/bin/env python3
"""
ì˜ˆì œ: AI ì½”ë“œ ë¦¬ë·°ì–´
ë‚œì´ë„: ê³ ê¸‰
ì„¤ëª…: Python ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  ê°œì„  ì œì•ˆì„ ì œê³µí•˜ëŠ” ì‹œìŠ¤í…œ
ìš”êµ¬ì‚¬í•­:
  - pyhub-llm (pip install "pyhub-llm[all]")
  - ast (ë‚´ì¥ ëª¨ë“ˆ)
  - OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜

ì˜ˆì œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ me@pyhub.krë¡œ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤.
"""

import ast
import json
import os
import re
import sys
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from pyhub.llm import LLM

# from pyhub.llm.cache import MemoryCache  # ìºì‹œ ê¸°ëŠ¥ì€ í˜„ì¬ ì˜ˆì œì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ


class IssueSeverity(Enum):
    """ì´ìŠˆ ì‹¬ê°ë„"""

    ERROR = "error"  # ë²„ê·¸ë‚˜ ì˜¤ë¥˜
    WARNING = "warning"  # ì ì¬ì  ë¬¸ì œ
    INFO = "info"  # ê°œì„  ì œì•ˆ
    STYLE = "style"  # ìŠ¤íƒ€ì¼ ê´€ë ¨


class IssueCategory(Enum):
    """ì´ìŠˆ ì¹´í…Œê³ ë¦¬"""

    BUG = "bug"
    PERFORMANCE = "performance"
    SECURITY = "security"
    MAINTAINABILITY = "maintainability"
    STYLE = "style"
    BEST_PRACTICE = "best_practice"


@dataclass
class CodeIssue:
    """ì½”ë“œ ì´ìŠˆ"""

    line: int
    column: int
    severity: IssueSeverity
    category: IssueCategory
    message: str
    suggestion: Optional[str] = None
    code_snippet: Optional[str] = None


@dataclass
class CodeMetrics:
    """ì½”ë“œ ë©”íŠ¸ë¦­"""

    lines_of_code: int
    cyclomatic_complexity: int
    function_count: int
    class_count: int
    import_count: int
    comment_ratio: float
    test_coverage: Optional[float] = None


@dataclass
class ReviewResult:
    """ë¦¬ë·° ê²°ê³¼"""

    file_path: str
    issues: List[CodeIssue] = field(default_factory=list)
    metrics: Optional[CodeMetrics] = None
    score: float = 0.0
    summary: str = ""
    improvements: List[str] = field(default_factory=list)


class CodeReviewer:
    """AI ì½”ë“œ ë¦¬ë·°ì–´"""

    def __init__(self, model: str = "gpt-4o"):
        self.llm = LLM.create(model)
        # self.cache = MemoryCache()  # ìºì‹œ ê¸°ëŠ¥ì€ í˜„ì¬ ì˜ˆì œì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        self.style_guide = self._load_style_guide()

    def _load_style_guide(self) -> Dict[str, Any]:
        """ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ë¡œë“œ"""
        return {
            "max_line_length": 88,
            "max_function_length": 50,
            "max_complexity": 10,
            "naming_convention": "snake_case",
            "docstring_required": True,
            "type_hints_required": True,
        }

    def analyze_code_structure(self, code: str) -> Tuple[ast.AST, List[str]]:
        """ì½”ë“œ êµ¬ì¡° ë¶„ì„"""
        try:
            tree = ast.parse(code)
            errors = []
            return tree, errors
        except SyntaxError as e:
            return None, [f"Syntax error at line {e.lineno}: {e.msg}"]

    def calculate_metrics(self, code: str, tree: Optional[ast.AST]) -> CodeMetrics:
        """ì½”ë“œ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        lines = code.split("\n")
        lines_of_code = len([line for line in lines if line.strip() and not line.strip().startswith("#")])

        if not tree:
            return CodeMetrics(
                lines_of_code=lines_of_code,
                cyclomatic_complexity=0,
                function_count=0,
                class_count=0,
                import_count=0,
                comment_ratio=0.0,
            )

        # í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ ìˆ˜ ê³„ì‚°
        function_count = sum(1 for node in ast.walk(tree) if isinstance(node, ast.FunctionDef))
        class_count = sum(1 for node in ast.walk(tree) if isinstance(node, ast.ClassDef))
        import_count = sum(1 for node in ast.walk(tree) if isinstance(node, (ast.Import, ast.ImportFrom)))

        # ì£¼ì„ ë¹„ìœ¨ ê³„ì‚°
        comment_lines = len([line for line in lines if line.strip().startswith("#")])
        comment_ratio = comment_lines / len(lines) if lines else 0.0

        # ìˆœí™˜ ë³µì¡ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
        complexity = self._calculate_cyclomatic_complexity(tree)

        return CodeMetrics(
            lines_of_code=lines_of_code,
            cyclomatic_complexity=complexity,
            function_count=function_count,
            class_count=class_count,
            import_count=import_count,
            comment_ratio=comment_ratio,
        )

    def _calculate_cyclomatic_complexity(self, tree: ast.AST) -> int:
        """ìˆœí™˜ ë³µì¡ë„ ê³„ì‚°"""
        complexity = 1  # ê¸°ë³¸ ë³µì¡ë„

        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For)):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1

        return complexity

    def check_style_issues(self, code: str, tree: Optional[ast.AST]) -> List[CodeIssue]:
        """ìŠ¤íƒ€ì¼ ì´ìŠˆ ê²€ì‚¬"""
        issues = []
        lines = code.split("\n")

        # ë¼ì¸ ê¸¸ì´ ê²€ì‚¬
        for i, line in enumerate(lines, 1):
            if len(line) > self.style_guide["max_line_length"]:
                issues.append(
                    CodeIssue(
                        line=i,
                        column=self.style_guide["max_line_length"],
                        severity=IssueSeverity.STYLE,
                        category=IssueCategory.STYLE,
                        message=f"Line too long ({len(line)} > {self.style_guide['max_line_length']})",
                        suggestion="Break this line into multiple lines",
                    )
                )

        if tree:
            # í•¨ìˆ˜ ê¸¸ì´ ê²€ì‚¬
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    func_lines = node.end_lineno - node.lineno + 1
                    if func_lines > self.style_guide["max_function_length"]:
                        issues.append(
                            CodeIssue(
                                line=node.lineno,
                                column=0,
                                severity=IssueSeverity.WARNING,
                                category=IssueCategory.MAINTAINABILITY,
                                message=f"Function '{node.name}' is too long ({func_lines} lines)",
                                suggestion="Consider breaking this function into smaller functions",
                            )
                        )

                    # ë…ìŠ¤íŠ¸ë§ ê²€ì‚¬
                    if self.style_guide["docstring_required"]:
                        docstring = ast.get_docstring(node)
                        if not docstring:
                            issues.append(
                                CodeIssue(
                                    line=node.lineno,
                                    column=0,
                                    severity=IssueSeverity.INFO,
                                    category=IssueCategory.STYLE,
                                    message=f"Function '{node.name}' lacks a docstring",
                                    suggestion="Add a docstring describing the function's purpose",
                                )
                            )

        return issues

    def check_security_issues(self, code: str, tree: Optional[ast.AST]) -> List[CodeIssue]:
        """ë³´ì•ˆ ì´ìŠˆ ê²€ì‚¬"""
        issues = []

        # ìœ„í—˜í•œ í•¨ìˆ˜ ì‚¬ìš© ê²€ì‚¬
        dangerous_functions = {
            "eval": "Avoid using eval() as it can execute arbitrary code",
            "exec": "Avoid using exec() as it can execute arbitrary code",
            "__import__": "Dynamic imports can be a security risk",
            "pickle.loads": "Pickle can execute arbitrary code during deserialization",
        }

        if tree:
            for node in ast.walk(tree):
                if isinstance(node, ast.Call):
                    func_name = self._get_function_name(node)
                    if func_name in dangerous_functions:
                        issues.append(
                            CodeIssue(
                                line=node.lineno,
                                column=node.col_offset,
                                severity=IssueSeverity.WARNING,
                                category=IssueCategory.SECURITY,
                                message=dangerous_functions[func_name],
                                suggestion="Consider using a safer alternative",
                            )
                        )

        # í•˜ë“œì½”ë”©ëœ ë¹„ë°€ë²ˆí˜¸ ê²€ì‚¬
        secret_patterns = [
            (r'password\s*=\s*["\'].*["\']', "Hardcoded password detected"),
            (r'api_key\s*=\s*["\'].*["\']', "Hardcoded API key detected"),
            (r'secret\s*=\s*["\'].*["\']', "Hardcoded secret detected"),
        ]

        lines = code.split("\n")
        for i, line in enumerate(lines, 1):
            for pattern, message in secret_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    issues.append(
                        CodeIssue(
                            line=i,
                            column=0,
                            severity=IssueSeverity.ERROR,
                            category=IssueCategory.SECURITY,
                            message=message,
                            suggestion="Use environment variables or secure configuration files",
                        )
                    )

        return issues

    def _get_function_name(self, node: ast.Call) -> str:
        """í•¨ìˆ˜ ì´ë¦„ ì¶”ì¶œ"""
        if isinstance(node.func, ast.Name):
            return node.func.id
        elif isinstance(node.func, ast.Attribute):
            # valueê°€ Nameì¸ ê²½ìš° ì§ì ‘ idë¥¼ ê°€ì ¸ì˜´
            if isinstance(node.func.value, ast.Name):
                return f"{node.func.value.id}.{node.func.attr}"
            # valueê°€ ë‹¤ë¥¸ Attributeì¸ ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬
            elif isinstance(node.func.value, ast.Attribute):
                base = self._get_attribute_chain(node.func.value)
                return f"{base}.{node.func.attr}"
        return ""

    def _get_attribute_chain(self, node: ast.Attribute) -> str:
        """ì¤‘ì²©ëœ attribute ì²´ì¸ ì¶”ì¶œ"""
        if isinstance(node.value, ast.Name):
            return f"{node.value.id}.{node.attr}"
        elif isinstance(node.value, ast.Attribute):
            return f"{self._get_attribute_chain(node.value)}.{node.attr}"
        return node.attr

    def check_performance_issues(self, code: str, tree: Optional[ast.AST]) -> List[CodeIssue]:
        """ì„±ëŠ¥ ì´ìŠˆ ê²€ì‚¬"""
        issues = []

        if tree:
            # ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ vs ë£¨í”„
            for node in ast.walk(tree):
                if isinstance(node, ast.For):
                    # ë‹¨ìˆœ append íŒ¨í„´ ê²€ì‚¬
                    if self._is_simple_append_loop(node):
                        issues.append(
                            CodeIssue(
                                line=node.lineno,
                                column=0,
                                severity=IssueSeverity.INFO,
                                category=IssueCategory.PERFORMANCE,
                                message="Consider using list comprehension for better performance",
                                suggestion="Replace loop with list comprehension",
                            )
                        )

        return issues

    def _is_simple_append_loop(self, node: ast.For) -> bool:
        """ë‹¨ìˆœ append ë£¨í”„ì¸ì§€ í™•ì¸"""
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±
        if len(node.body) == 1 and isinstance(node.body[0], ast.Expr):
            expr = node.body[0].value
            if isinstance(expr, ast.Call) and isinstance(expr.func, ast.Attribute):
                return expr.func.attr == "append"
        return False

    def ai_review(self, code: str, context: str = "") -> Dict[str, Any]:
        """AI ê¸°ë°˜ ì½”ë“œ ë¦¬ë·°"""
        # ìºì‹œ í™•ì¸ (ìºì‹œ ê¸°ëŠ¥ì€ í˜„ì¬ ë¹„í™œì„±í™”)
        # cache_key = f"ai_review_{hash(code)}"
        # cached = self.cache.get(cache_key)
        # if cached:
        #     return cached

        prompt = f"""ë‹¤ìŒ Python ì½”ë“œë¥¼ ë¦¬ë·°í•˜ê³  ê°œì„  ì œì•ˆì„ ì œê³µí•˜ì„¸ìš”:

```python
{code[:2000]}  # í† í° ì œí•œ
```

{f"ì»¨í…ìŠ¤íŠ¸: {context}" if context else ""}

ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”:
1. ì½”ë“œ í’ˆì§ˆê³¼ ê°€ë…ì„±
2. ì ì¬ì  ë²„ê·¸ë‚˜ ì˜¤ë¥˜
3. ì„±ëŠ¥ ìµœì í™” ê¸°íšŒ
4. ë³´ì•ˆ ì·¨ì•½ì 
5. ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ì¤€ìˆ˜

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "summary": "ì „ì²´ í‰ê°€ ìš”ì•½",
    "score": 0-100 ì ìˆ˜,
    "issues": [
        {{
            "type": "bug|performance|security|style",
            "severity": "high|medium|low",
            "description": "ì´ìŠˆ ì„¤ëª…",
            "suggestion": "ê°œì„  ì œì•ˆ"
        }}
    ],
    "improvements": ["ê°œì„  ì œì•ˆ 1", "ê°œì„  ì œì•ˆ 2", ...]
}}"""

        reply = self.llm.ask(prompt)

        # JSON íŒŒì‹±
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ
            json_match = re.search(r"\{.*\}", reply.text, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
            else:
                result = {"summary": reply.text, "score": 70, "issues": [], "improvements": []}
        except json.JSONDecodeError:
            result = {"summary": "AI ë¦¬ë·° íŒŒì‹± ì‹¤íŒ¨", "score": 0, "issues": [], "improvements": []}

        # ìºì‹œ ì €ì¥ (ìºì‹œ ê¸°ëŠ¥ì€ í˜„ì¬ ë¹„í™œì„±í™”)
        # self.cache.set(cache_key, result)

        return result

    def review_file(self, file_path: str, context: str = "") -> ReviewResult:
        """íŒŒì¼ ë¦¬ë·°"""
        path = Path(file_path)

        if not path.exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")

        if path.suffix != ".py":
            raise ValueError("Python íŒŒì¼ë§Œ ì§€ì›ë©ë‹ˆë‹¤ (.py)")

        with open(file_path, "r", encoding="utf-8") as f:
            code = f.read()

        return self.review_code(code, str(file_path), context)

    def review_code(self, code: str, file_name: str = "code.py", context: str = "") -> ReviewResult:
        """ì½”ë“œ ë¦¬ë·° ë©”ì¸ í•¨ìˆ˜"""
        print(f"ğŸ” ì½”ë“œ ë¦¬ë·° ì‹œì‘: {file_name}")

        # ì½”ë“œ êµ¬ì¡° ë¶„ì„
        tree, syntax_errors = self.analyze_code_structure(code)

        # ê²°ê³¼ ì´ˆê¸°í™”
        result = ReviewResult(file_path=file_name)

        # ë¬¸ë²• ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        for error in syntax_errors:
            result.issues.append(
                CodeIssue(line=1, column=0, severity=IssueSeverity.ERROR, category=IssueCategory.BUG, message=error)
            )

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        result.metrics = self.calculate_metrics(code, tree)
        print(f"  ğŸ“Š ë©”íŠ¸ë¦­: {result.metrics.lines_of_code} LOC, ë³µì¡ë„ {result.metrics.cyclomatic_complexity}")

        # ê°ì¢… ê²€ì‚¬ ìˆ˜í–‰
        if tree:
            result.issues.extend(self.check_style_issues(code, tree))
            result.issues.extend(self.check_security_issues(code, tree))
            result.issues.extend(self.check_performance_issues(code, tree))

        # AI ë¦¬ë·°
        print("  ğŸ¤– AI ë¶„ì„ ì¤‘...")
        ai_result = self.ai_review(code, context)

        # AI ê²°ê³¼ í†µí•©
        result.summary = ai_result.get("summary", "")
        result.score = ai_result.get("score", 0)
        result.improvements = ai_result.get("improvements", [])

        # AI ì´ìŠˆë¥¼ CodeIssueë¡œ ë³€í™˜
        for ai_issue in ai_result.get("issues", []):
            severity_map = {"high": IssueSeverity.ERROR, "medium": IssueSeverity.WARNING, "low": IssueSeverity.INFO}
            category_map = {
                "bug": IssueCategory.BUG,
                "performance": IssueCategory.PERFORMANCE,
                "security": IssueCategory.SECURITY,
                "style": IssueCategory.STYLE,
            }

            result.issues.append(
                CodeIssue(
                    line=0,  # AIëŠ” íŠ¹ì • ë¼ì¸ì„ ì§€ì •í•˜ì§€ ì•ŠìŒ
                    column=0,
                    severity=severity_map.get(ai_issue.get("severity", "low"), IssueSeverity.INFO),
                    category=category_map.get(ai_issue.get("type", "style"), IssueCategory.BEST_PRACTICE),
                    message=ai_issue.get("description", ""),
                    suggestion=ai_issue.get("suggestion", ""),
                )
            )

        print(f"  âœ… ë¦¬ë·° ì™„ë£Œ: {len(result.issues)}ê°œ ì´ìŠˆ ë°œê²¬")

        return result

    def generate_report(self, result: ReviewResult, format: str = "text") -> str:
        """ë¦¬ë·° ë³´ê³ ì„œ ìƒì„±"""
        if format == "text":
            return self._generate_text_report(result)
        elif format == "markdown":
            return self._generate_markdown_report(result)
        elif format == "json":
            return self._generate_json_report(result)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {format}")

    def _generate_text_report(self, result: ReviewResult) -> str:
        """í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±"""
        lines = []
        lines.append(f"ì½”ë“œ ë¦¬ë·° ë³´ê³ ì„œ: {result.file_path}")
        lines.append("=" * 50)
        lines.append(f"ì ìˆ˜: {result.score}/100")
        lines.append(f"ì´ìŠˆ: {len(result.issues)}ê°œ")
        lines.append("")

        if result.summary:
            lines.append("ìš”ì•½:")
            lines.append(result.summary)
            lines.append("")

        if result.metrics:
            lines.append("ë©”íŠ¸ë¦­:")
            lines.append(f"  - ì½”ë“œ ë¼ì¸: {result.metrics.lines_of_code}")
            lines.append(f"  - ë³µì¡ë„: {result.metrics.cyclomatic_complexity}")
            lines.append(f"  - í•¨ìˆ˜ ìˆ˜: {result.metrics.function_count}")
            lines.append(f"  - í´ë˜ìŠ¤ ìˆ˜: {result.metrics.class_count}")
            lines.append("")

        if result.issues:
            lines.append("ì´ìŠˆ:")
            for issue in sorted(result.issues, key=lambda x: (x.severity.value, x.line)):
                lines.append(f"  [{issue.severity.value.upper()}] Line {issue.line}: {issue.message}")
                if issue.suggestion:
                    lines.append(f"    ì œì•ˆ: {issue.suggestion}")
            lines.append("")

        if result.improvements:
            lines.append("ê°œì„  ì œì•ˆ:")
            for i, improvement in enumerate(result.improvements, 1):
                lines.append(f"  {i}. {improvement}")

        return "\n".join(lines)

    def _generate_markdown_report(self, result: ReviewResult) -> str:
        """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±"""
        lines = []
        lines.append(f"# ì½”ë“œ ë¦¬ë·° ë³´ê³ ì„œ: `{result.file_path}`")
        lines.append("")
        lines.append(f"**ì ìˆ˜**: {result.score}/100 {'â­' * (result.score // 20)}")
        lines.append("")

        if result.summary:
            lines.append("## ìš”ì•½")
            lines.append(result.summary)
            lines.append("")

        if result.metrics:
            lines.append("## ë©”íŠ¸ë¦­")
            lines.append(f"- **ì½”ë“œ ë¼ì¸**: {result.metrics.lines_of_code}")
            lines.append(f"- **ìˆœí™˜ ë³µì¡ë„**: {result.metrics.cyclomatic_complexity}")
            lines.append(f"- **í•¨ìˆ˜ ìˆ˜**: {result.metrics.function_count}")
            lines.append(f"- **í´ë˜ìŠ¤ ìˆ˜**: {result.metrics.class_count}")
            lines.append("")

        if result.issues:
            lines.append("## ì´ìŠˆ")

            # ì‹¬ê°ë„ë³„ ê·¸ë£¹í™”
            by_severity = {}
            for issue in result.issues:
                if issue.severity not in by_severity:
                    by_severity[issue.severity] = []
                by_severity[issue.severity].append(issue)

            for severity in [IssueSeverity.ERROR, IssueSeverity.WARNING, IssueSeverity.INFO, IssueSeverity.STYLE]:
                if severity in by_severity:
                    emoji = {"error": "ğŸ”´", "warning": "ğŸŸ¡", "info": "ğŸ”µ", "style": "âšª"}
                    lines.append(f"### {emoji[severity.value]} {severity.value.capitalize()}")
                    for issue in by_severity[severity]:
                        lines.append(f"- **Line {issue.line}**: {issue.message}")
                        if issue.suggestion:
                            lines.append(f"  - ğŸ’¡ {issue.suggestion}")
                    lines.append("")

        if result.improvements:
            lines.append("## ê°œì„  ì œì•ˆ")
            for improvement in result.improvements:
                lines.append(f"- {improvement}")

        return "\n".join(lines)

    def _generate_json_report(self, result: ReviewResult) -> str:
        """JSON ë³´ê³ ì„œ ìƒì„±"""
        data = {
            "file_path": result.file_path,
            "score": result.score,
            "summary": result.summary,
            "metrics": (
                {
                    "lines_of_code": result.metrics.lines_of_code,
                    "cyclomatic_complexity": result.metrics.cyclomatic_complexity,
                    "function_count": result.metrics.function_count,
                    "class_count": result.metrics.class_count,
                    "import_count": result.metrics.import_count,
                    "comment_ratio": result.metrics.comment_ratio,
                }
                if result.metrics
                else None
            ),
            "issues": [
                {
                    "line": issue.line,
                    "column": issue.column,
                    "severity": issue.severity.value,
                    "category": issue.category.value,
                    "message": issue.message,
                    "suggestion": issue.suggestion,
                }
                for issue in result.issues
            ],
            "improvements": result.improvements,
        }

        return json.dumps(data, ensure_ascii=False, indent=2)


def example_simple_review():
    """ê°„ë‹¨í•œ ì½”ë“œ ë¦¬ë·° ì˜ˆì œ"""
    print("\nğŸ“ ê°„ë‹¨í•œ ì½”ë“œ ë¦¬ë·°")
    print("-" * 50)

    sample_code = """
def calculate_average(numbers):
    total = 0
    for n in numbers:
        total = total + n
    average = total / len(numbers)
    return average

# í…ŒìŠ¤íŠ¸
nums = [1, 2, 3, 4, 5]
result = calculate_average(nums)
print("Average:", result)

password = "12345"  # í•˜ë“œì½”ë”©ëœ ë¹„ë°€ë²ˆí˜¸
"""

    reviewer = CodeReviewer()
    result = reviewer.review_code(sample_code, "example.py")

    # ë³´ê³ ì„œ ì¶œë ¥
    print("\n" + reviewer.generate_report(result, format="text"))


def example_file_review():
    """íŒŒì¼ ë¦¬ë·° ì˜ˆì œ"""
    print("\nğŸ“ íŒŒì¼ ë¦¬ë·°")
    print("-" * 50)

    # ì˜ˆì œ íŒŒì¼ ìƒì„±
    sample_code = '''
import os
import sys

class DataProcessor:
    def __init__(self):
        self.data = []
    
    def process_data(self, input_data):
        """ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜"""
        result = []
        for item in input_data:
            if item > 0:
                result.append(item * 2)
        
        # ë§¤ìš° ê¸´ ë¼ì¸ìœ¼ë¡œ ìŠ¤íƒ€ì¼ ì´ìŠˆ ìƒì„±
        very_long_variable_name = "This is a very long string that exceeds the maximum line length recommended by PEP8"
        
        return result
    
    def risky_operation(self, user_input):
        # ë³´ì•ˆ ì´ìŠˆ: eval ì‚¬ìš©
        return eval(user_input)

def main():
    processor = DataProcessor()
    data = [1, 2, 3, 4, 5]
    result = processor.process_data(data)
    print(result)

if __name__ == "__main__":
    main()
'''

    import tempfile

    with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
        f.write(sample_code)
        temp_path = f.name

    try:
        reviewer = CodeReviewer()
        result = reviewer.review_file(temp_path, context="ë°ì´í„° ì²˜ë¦¬ ëª¨ë“ˆ")

        # ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ
        print("\n" + reviewer.generate_report(result, format="markdown"))

    finally:
        os.unlink(temp_path)


def example_comparative_review():
    """ë¹„êµ ë¦¬ë·° ì˜ˆì œ"""
    print("\nğŸ”„ ì½”ë“œ ê°œì„  ì „í›„ ë¹„êµ")
    print("-" * 50)

    # ê°œì„  ì „ ì½”ë“œ
    code_before = """
def find_max(lst):
    max_val = lst[0]
    for i in range(len(lst)):
        if lst[i] > max_val:
            max_val = lst[i]
    return max_val
"""

    # ê°œì„  í›„ ì½”ë“œ
    code_after = '''
def find_max(lst: list[float]) -> float:
    """ë¦¬ìŠ¤íŠ¸ì—ì„œ ìµœëŒ“ê°’ì„ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        lst: ìˆ«ì ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ìµœëŒ“ê°’
        
    Raises:
        ValueError: ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
    """
    if not lst:
        raise ValueError("ë¹ˆ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤")
    
    return max(lst)
'''

    reviewer = CodeReviewer()

    print("ê°œì„  ì „:")
    result_before = reviewer.review_code(code_before, "before.py")
    print(f"  ì ìˆ˜: {result_before.score}/100")
    print(f"  ì´ìŠˆ: {len(result_before.issues)}ê°œ")

    print("\nê°œì„  í›„:")
    result_after = reviewer.review_code(code_after, "after.py")
    print(f"  ì ìˆ˜: {result_after.score}/100")
    print(f"  ì´ìŠˆ: {len(result_after.issues)}ê°œ")

    print(f"\nê°œì„  íš¨ê³¼: +{result_after.score - result_before.score}ì ")


def main():
    """ì½”ë“œ ë¦¬ë·°ì–´ ì˜ˆì œ ë©”ì¸ í•¨ìˆ˜"""

    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

    print("ğŸ” AI ì½”ë“œ ë¦¬ë·°ì–´ ì˜ˆì œ")
    print("=" * 50)

    try:
        # 1. ê°„ë‹¨í•œ ë¦¬ë·°
        example_simple_review()

        # 2. íŒŒì¼ ë¦¬ë·°
        example_file_review()

        # 3. ë¹„êµ ë¦¬ë·°
        example_comparative_review()

        print("\nâœ… ëª¨ë“  ì½”ë“œ ë¦¬ë·° ì˜ˆì œ ì™„ë£Œ!")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
