"""
FastAPI + pyhub-llm ê³ ê¸‰ í†µí•© ì˜ˆì œ

ì´ íŒŒì¼ì€ ì¸ì¦, Rate Limiting, ê³ ê¸‰ ì„œë¹„ìŠ¤ ë“±ì„ í¬í•¨í•œ
ì™„ì „í•œ í”„ë¡œë•ì…˜ ë ˆë²¨ì˜ FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì˜ˆì œì…ë‹ˆë‹¤.
"""

import os
import asyncio
from typing import List, Optional, Dict, Any
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from services.translation import (
    TranslationService, 
    TranslationRequest, 
    TranslationResponse,
    SummarizeRequest,
    SummarizeResponse,
    translation_service
)
from services.chat import ChatService, chat_service
from middleware.auth import api_key_auth, optional_api_key_auth
from middleware.rate_limit import RateLimitMiddleware
from main import ChatRequest, ChatResponse, BatchRequest, BatchResponse


# =============================================================================
# ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
# =============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    print("ğŸš€ ê³ ê¸‰ FastAPI + pyhub-llm ì„œë¹„ìŠ¤ ì‹œì‘")
    print("ğŸ” ì¸ì¦ ë° ë³´ì•ˆ ê¸°ëŠ¥ í™œì„±í™”")
    print("âš¡ Rate Limiting í™œì„±í™”")
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    try:
        # ê¸°ë³¸ ëª¨ë¸ë“¤ ë¯¸ë¦¬ ë¡œë“œ
        await asyncio.create_task(preload_models())
        print("âœ… ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
    
    yield
    
    print("ğŸ›‘ ê³ ê¸‰ FastAPI + pyhub-llm ì„œë¹„ìŠ¤ ì¢…ë£Œ")
    chat_service.clear_cache()


async def preload_models():
    """ìì£¼ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ë“¤ì„ ë¯¸ë¦¬ ë¡œë“œ"""
    models = ["gpt-4o-mini", "gpt-4o"]
    for model in models:
        try:
            chat_service.get_llm(model)
            print(f"âœ… {model} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ {model} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="pyhub-llm Advanced FastAPI Integration",
    description="ì¸ì¦, Rate Limiting, ê³ ê¸‰ ì„œë¹„ìŠ¤ë¥¼ í¬í•¨í•œ ì™„ì „í•œ FastAPI ì—°ë™ ì˜ˆì œ",
    version="2.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” êµ¬ì²´ì ì¸ ë„ë©”ì¸ ì§€ì •
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Rate Limiting ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
rate_limit_per_minute = int(os.getenv("RATE_LIMIT_REQUESTS", "100"))
app.add_middleware(
    RateLimitMiddleware,
    requests_per_minute=rate_limit_per_minute
)


# =============================================================================
# ë³´ì•ˆì´ ì ìš©ëœ API ì—”ë“œí¬ì¸íŠ¸
# =============================================================================

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "service": "pyhub-llm Advanced FastAPI Integration",
        "version": "2.0.0",
        "features": [
            "API Key Authentication",
            "Rate Limiting", 
            "Translation Service",
            "Summarization Service",
            "Batch Processing",
            "Session Management"
        ],
        "endpoints": {
            "protected": {
                "/api/chat": "ì¸ì¦ì´ í•„ìš”í•œ ì±„íŒ…",
                "/api/batch": "ì¸ì¦ì´ í•„ìš”í•œ ë°°ì¹˜ ì²˜ë¦¬",
                "/api/translate": "ë²ˆì—­ ì„œë¹„ìŠ¤",
                "/api/summarize": "ìš”ì•½ ì„œë¹„ìŠ¤"
            },
            "public": {
                "/health": "í—¬ìŠ¤ì²´í¬",
                "/docs": "API ë¬¸ì„œ",
                "/redoc": "ëŒ€í™”í˜• API ë¬¸ì„œ"
            }
        }
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ (ì¸ì¦ ë¶ˆí•„ìš”)"""
    return {
        "status": "healthy",
        "service": "pyhub-llm Advanced FastAPI",
        "rate_limit": f"{rate_limit_per_minute} requests/minute"
    }


# =============================================================================
# ì¸ì¦ì´ í•„ìš”í•œ API ì—”ë“œí¬ì¸íŠ¸
# =============================================================================

@app.post("/api/chat", response_model=ChatResponse)
async def protected_chat(
    request: ChatRequest,
    api_key: str = Depends(api_key_auth)
):
    """
    ë³´í˜¸ëœ ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸
    
    API í‚¤ ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.
    """
    try:
        response = await chat_service.process_message(
            message=request.message,
            model=request.model,
            system_prompt=request.system_prompt,
            temperature=request.temperature,
            max_tokens=request.max_tokens
        )
        
        return ChatResponse(
            response=response.text,
            model=request.model,
            usage=response.usage.__dict__ if response.usage else None
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@app.post("/api/batch", response_model=BatchResponse)
async def protected_batch(
    request: BatchRequest,
    background_tasks: BackgroundTasks,
    api_key: str = Depends(api_key_auth)
):
    """
    ë³´í˜¸ëœ ë°°ì¹˜ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸
    
    API í‚¤ ì¸ì¦ì´ í•„ìš”í•˜ë©°, ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¡œê¹…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    import time
    start_time = time.time()
    
    try:
        llm = chat_service.get_llm(request.model)
        
        responses = await llm.batch(
            prompts=request.messages,
            system_prompt=request.system_prompt,
            max_parallel=request.max_parallel,
            history_mode=request.history_mode
        )
        
        # ì‘ë‹µ ì²˜ë¦¬
        chat_responses = []
        success_count = 0
        
        for response in responses:
            if "Error processing prompt" not in response.text:
                success_count += 1
            
            chat_responses.append(ChatResponse(
                response=response.text,
                model=request.model,
                usage=response.usage.__dict__ if response.usage else None
            ))
        
        execution_time = time.time() - start_time
        
        # ë°±ê·¸ë¼ìš´ë“œ ë¡œê¹… ì¶”ê°€
        background_tasks.add_task(
            log_batch_request,
            api_key=api_key,
            message_count=len(request.messages),
            success_count=success_count,
            execution_time=execution_time
        )
        
        return BatchResponse(
            responses=chat_responses,
            total_count=len(request.messages),
            success_count=success_count,
            execution_time=execution_time
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@app.post("/api/stream")
async def protected_stream(
    request: ChatRequest,
    api_key: str = Depends(api_key_auth)
):
    """
    ë³´í˜¸ëœ ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        async def generate_stream():
            try:
                async for chunk in chat_service.process_stream(
                    message=request.message,
                    model=request.model,
                    system_prompt=request.system_prompt,
                    temperature=request.temperature,
                    max_tokens=request.max_tokens
                ):
                    if chunk.text:
                        yield f"data: {chunk.text}\n\n"
                
                yield f"data: [DONE]\n\n"
                
            except Exception as e:
                yield f"data: ERROR: {str(e)}\n\n"
        
        return StreamingResponse(
            generate_stream(),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache"}
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error during streaming: {str(e)}"
        )


# =============================================================================
# ê³ ê¸‰ ì„œë¹„ìŠ¤ ì—”ë“œí¬ì¸íŠ¸
# =============================================================================

@app.post("/api/translate", response_model=TranslationResponse)
async def translate_text(
    request: TranslationRequest,
    api_key: str = Depends(api_key_auth)
):
    """
    í…ìŠ¤íŠ¸ ë²ˆì—­ ì„œë¹„ìŠ¤
    
    ë‹¤ì–‘í•œ ì–¸ì–´ ê°„ ë²ˆì—­ì„ ì§€ì›í•©ë‹ˆë‹¤.
    """
    try:
        return await translation_service.translate(request)
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error during translation: {str(e)}"
        )


@app.post("/api/summarize", response_model=SummarizeResponse)
async def summarize_text(
    request: SummarizeRequest,
    api_key: str = Depends(api_key_auth)
):
    """
    í…ìŠ¤íŠ¸ ìš”ì•½ ì„œë¹„ìŠ¤
    
    ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ê¸¸ì´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    """
    try:
        return await translation_service.summarize(request)
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error during summarization: {str(e)}"
        )


@app.get("/api/supported-languages")
async def get_supported_languages(
    api_key: str = Depends(optional_api_key_auth)
):
    """
    ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡ ì¡°íšŒ
    
    ì„ íƒì  ì¸ì¦ (API í‚¤ê°€ ìˆìœ¼ë©´ ë” ìì„¸í•œ ì •ë³´ ì œê³µ)
    """
    basic_languages = {
        "ko": "í•œêµ­ì–´",
        "en": "English", 
        "ja": "æ—¥æœ¬èª",
        "zh": "ä¸­æ–‡"
    }
    
    if api_key:
        # ì¸ì¦ëœ ì‚¬ìš©ìì—ê²ŒëŠ” ë” ë§ì€ ì–¸ì–´ ì œê³µ
        return {
            "languages": translation_service.LANGUAGE_CODES,
            "total_count": len(translation_service.LANGUAGE_CODES),
            "premium_user": True
        }
    else:
        # ë¹„ì¸ì¦ ì‚¬ìš©ìì—ê²ŒëŠ” ê¸°ë³¸ ì–¸ì–´ë§Œ ì œê³µ
        return {
            "languages": basic_languages,
            "total_count": len(basic_languages),
            "premium_user": False,
            "note": "API í‚¤ë¥¼ ì œê³µí•˜ë©´ ë” ë§ì€ ì–¸ì–´ë¥¼ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }


# =============================================================================
# ê´€ë¦¬ì ì—”ë“œí¬ì¸íŠ¸
# =============================================================================

@app.get("/admin/stats")
async def get_service_stats(
    api_key: str = Depends(api_key_auth)
):
    """
    ì„œë¹„ìŠ¤ í†µê³„ ì¡°íšŒ
    
    ê´€ë¦¬ììš© ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.
    """
    # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê¶Œí•œ ì²´í¬ê°€ í•„ìš”
    admin_keys = os.getenv("ADMIN_API_KEYS", "").split(",")
    if api_key not in admin_keys:
        raise HTTPException(
            status_code=403,
            detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
        )
    
    return {
        "service_status": "running",
        "loaded_models": list(chat_service._llm_cache.keys()),
        "supported_languages": len(translation_service.LANGUAGE_CODES),
        "rate_limit": f"{rate_limit_per_minute} requests/minute"
    }


# =============================================================================
# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
# =============================================================================

async def log_batch_request(
    api_key: str,
    message_count: int,
    success_count: int,
    execution_time: float
):
    """ë°°ì¹˜ ìš”ì²­ ë¡œê¹… (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)"""
    # ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë¡œê¹… ì‹œìŠ¤í…œì— ì €ì¥
    print(f"ğŸ“Š ë°°ì¹˜ ìš”ì²­ ë¡œê·¸:")
    print(f"   - API Key: {api_key[:8]}...")
    print(f"   - ë©”ì‹œì§€ ìˆ˜: {message_count}")
    print(f"   - ì„±ê³µ ìˆ˜: {success_count}")
    print(f"   - ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ")


# =============================================================================
# ë©”ì¸ ì‹¤í–‰ë¶€
# =============================================================================

if __name__ == "__main__":
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    required_env_vars = ["OPENAI_API_KEY"]
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"âš ï¸ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {missing_vars}")
        print("ğŸ’¡ .env íŒŒì¼ì„ ìƒì„±í•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    # API í‚¤ ì •ë³´ ì¶œë ¥
    api_keys_env = os.getenv("ALLOWED_API_KEYS", "")
    if not api_keys_env:
        default_key = os.getenv("API_SECRET_KEY", "demo-key-12345")
        print(f"ğŸ”‘ ê°œë°œìš© API í‚¤: {default_key}")
        print(f"ğŸ’¡ ì‚¬ìš©ë²•: curl -H 'Authorization: Bearer {default_key}' ...")
    
    print("ğŸŒŸ ê³ ê¸‰ FastAPI + pyhub-llm ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:8000/docs")
    print("ğŸ” ëŒ€í™”í˜• API: http://localhost:8000/redoc")
    print(f"ğŸš¦ Rate Limit: {rate_limit_per_minute} requests/minute")
    
    uvicorn.run(
        "advanced:app",
        host=os.getenv("FASTAPI_HOST", "0.0.0.0"),
        port=int(os.getenv("FASTAPI_PORT", "8000")),
        reload=os.getenv("FASTAPI_RELOAD", "true").lower() == "true",
        log_level=os.getenv("LOG_LEVEL", "info")
    )